{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyP1NgGmtFupecW5A0BhVOlM"
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "widgets": {
      "application/vnd.jupyter.widget-state+json": {
        "0626e18ba6264a1a922833e1f521084f": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_1e7518ac023d48bc873f5c9ff38a37bf",
              "IPY_MODEL_9798ee00c24c43cda71f53c6466f6d27",
              "IPY_MODEL_acca271c54024434b693702f32332e5b"
            ],
            "layout": "IPY_MODEL_f0e8f44f39594c95a9c72083aa987864"
          }
        },
        "1e7518ac023d48bc873f5c9ff38a37bf": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_540520692dfb4232b72ff4417e670ff1",
            "placeholder": "​",
            "style": "IPY_MODEL_1f5ca29eb077429caf66d219e0e84a8b",
            "value": "Downloading: 100%"
          }
        },
        "9798ee00c24c43cda71f53c6466f6d27": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_19038f3c176841e7bff61b23678e13d0",
            "max": 517,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_444effaea56a4c22bd1dd20c180e16e1",
            "value": 517
          }
        },
        "acca271c54024434b693702f32332e5b": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_8626095ff8554897b47bc0fe8b323041",
            "placeholder": "​",
            "style": "IPY_MODEL_36d04d5baa9049fd9077a57b032f2a68",
            "value": " 517/517 [00:00&lt;00:00, 13.1kB/s]"
          }
        },
        "f0e8f44f39594c95a9c72083aa987864": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "540520692dfb4232b72ff4417e670ff1": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "1f5ca29eb077429caf66d219e0e84a8b": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "19038f3c176841e7bff61b23678e13d0": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "444effaea56a4c22bd1dd20c180e16e1": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "8626095ff8554897b47bc0fe8b323041": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "36d04d5baa9049fd9077a57b032f2a68": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "10585fe4bd314ce9856d32147bee0979": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_c6b0320306954162b74569b298eb4e09",
              "IPY_MODEL_733df63441b14da2976133c174459b40",
              "IPY_MODEL_e481d90a3ef8403b87622a0b683f0fbf"
            ],
            "layout": "IPY_MODEL_3d6bca7d7fc049728ac8d8f70b3a8b1b"
          }
        },
        "c6b0320306954162b74569b298eb4e09": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_008b00c60fdb4519abf38b304a6a5791",
            "placeholder": "​",
            "style": "IPY_MODEL_d80e2df9e6b44175a70455624e0b1885",
            "value": "Downloading: 100%"
          }
        },
        "733df63441b14da2976133c174459b40": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_29638a224bbb4cf4b1afce71fdf49844",
            "max": 442543047,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_9d7fffe8812145e7b76f142e55a2c30a",
            "value": 442543047
          }
        },
        "e481d90a3ef8403b87622a0b683f0fbf": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_22cb93a71bc84689810d56f386a1b345",
            "placeholder": "​",
            "style": "IPY_MODEL_80d967516400419f84a738edd6a024a5",
            "value": " 443M/443M [00:10&lt;00:00, 41.9MB/s]"
          }
        },
        "3d6bca7d7fc049728ac8d8f70b3a8b1b": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "008b00c60fdb4519abf38b304a6a5791": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "d80e2df9e6b44175a70455624e0b1885": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "29638a224bbb4cf4b1afce71fdf49844": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "9d7fffe8812145e7b76f142e55a2c30a": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "22cb93a71bc84689810d56f386a1b345": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "80d967516400419f84a738edd6a024a5": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "2226b23486f84b10ac9f58695c43e84b": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_33eb933d60214becb346a91e69b4e13b",
              "IPY_MODEL_e789a3bcfd0e4cb8a2def23f2a33df77",
              "IPY_MODEL_c7a49b84767a4f229a5c3c19e1cc52fc"
            ],
            "layout": "IPY_MODEL_71dd4a8e2d3f48479ab78aead1dabb1b"
          }
        },
        "33eb933d60214becb346a91e69b4e13b": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_981a598c15194b5099b8e6c0ea3459cb",
            "placeholder": "​",
            "style": "IPY_MODEL_aa297f42ce614c168eec074b45088186",
            "value": "Downloading: 100%"
          }
        },
        "e789a3bcfd0e4cb8a2def23f2a33df77": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_e71ba7419f5f464d8d5ad71abeb70bbf",
            "max": 810912,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_8ad72882b79644cd8533215439c196f4",
            "value": 810912
          }
        },
        "c7a49b84767a4f229a5c3c19e1cc52fc": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_242d4fb1b2c1475180eea97fe9f5dc2d",
            "placeholder": "​",
            "style": "IPY_MODEL_2ae61196f96e4179af90152c72383388",
            "value": " 811k/811k [00:00&lt;00:00, 1.96MB/s]"
          }
        },
        "71dd4a8e2d3f48479ab78aead1dabb1b": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "981a598c15194b5099b8e6c0ea3459cb": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "aa297f42ce614c168eec074b45088186": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "e71ba7419f5f464d8d5ad71abeb70bbf": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "8ad72882b79644cd8533215439c196f4": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "242d4fb1b2c1475180eea97fe9f5dc2d": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "2ae61196f96e4179af90152c72383388": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "a815c7f9465b443fb60ac1cd26dad933": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_cc089174bbce43b1afb354a606d0a835",
              "IPY_MODEL_5b9b1445b72846c7a1a6db9288910b0e",
              "IPY_MODEL_0230d6a1849a4464b47537a5eb9a05c0"
            ],
            "layout": "IPY_MODEL_df8be0f47a9b46428c6a8a6a2eee77d2"
          }
        },
        "cc089174bbce43b1afb354a606d0a835": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_d4a11ba54e154331a5a235701192b91b",
            "placeholder": "​",
            "style": "IPY_MODEL_5d6ddced82f44805a2c16bb6200c9cdb",
            "value": "Downloading: 100%"
          }
        },
        "5b9b1445b72846c7a1a6db9288910b0e": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_6dfc9c3deed04ce19b559ccc4f1ecc12",
            "max": 210,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_e7681899d5fd49e5968b1fb7f56c5657",
            "value": 210
          }
        },
        "0230d6a1849a4464b47537a5eb9a05c0": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_114d90319fc44171bd01487c125b31e7",
            "placeholder": "​",
            "style": "IPY_MODEL_96cce063558644d98a0c2c74642ff049",
            "value": " 210/210 [00:00&lt;00:00, 3.85kB/s]"
          }
        },
        "df8be0f47a9b46428c6a8a6a2eee77d2": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "d4a11ba54e154331a5a235701192b91b": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "5d6ddced82f44805a2c16bb6200c9cdb": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "6dfc9c3deed04ce19b559ccc4f1ecc12": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "e7681899d5fd49e5968b1fb7f56c5657": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "114d90319fc44171bd01487c125b31e7": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "96cce063558644d98a0c2c74642ff049": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "8bc45c630ec94d00be358ff9eb992914": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_06758bb2ed6d4aec898ff75a693570f2",
              "IPY_MODEL_67c4c1f45ea64cc08bae98f3b0b0679b",
              "IPY_MODEL_2a4bcf18c3a14d6098ae8f905d51d75f"
            ],
            "layout": "IPY_MODEL_68137bc7d87946af8eccba3fa3762603"
          }
        },
        "06758bb2ed6d4aec898ff75a693570f2": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_6ca1869c54214b86924711697ed51982",
            "placeholder": "​",
            "style": "IPY_MODEL_757a6423bb1240aaa34468e502d22d4c",
            "value": "Downloading: 100%"
          }
        },
        "67c4c1f45ea64cc08bae98f3b0b0679b": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_b89e0526ebc945e19669463fd779ac63",
            "max": 23,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_62641b69b5e043a58b9e553ea14ae983",
            "value": 23
          }
        },
        "2a4bcf18c3a14d6098ae8f905d51d75f": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_bfe36b05914242eda9d4a25c72b5bc35",
            "placeholder": "​",
            "style": "IPY_MODEL_ced198a524844fabac5bf63c75c98ee8",
            "value": " 23.0/23.0 [00:00&lt;00:00, 417B/s]"
          }
        },
        "68137bc7d87946af8eccba3fa3762603": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "6ca1869c54214b86924711697ed51982": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "757a6423bb1240aaa34468e502d22d4c": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "b89e0526ebc945e19669463fd779ac63": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "62641b69b5e043a58b9e553ea14ae983": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "bfe36b05914242eda9d4a25c72b5bc35": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "ced198a524844fabac5bf63c75c98ee8": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        }
      }
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "# **Modele camemBERT ** \n",
        "**Réponse aux questions avec un BERT français**\n",
        "\n",
        "Représentations d'encodeurs bidirectionnels à partir de transformateurs\n",
        "\n",
        "Au lieu de regarder les mots isolément, BERT, un modèle basé sur un transformateur, tente d'utiliser le contexte des mots pour obtenir des incorporations. BERT utilise plusieurs concepts d'apprentissage en profondeur pour proposer un modèle qui examine le contexte de manière bidirectionnelle, en tirant parti des informations de l'ensemble des phrases dans leur ensemble grâce à l'attention personnelle.\n",
        "\n",
        "https://github.com/youssefassis/CamemBERTQA/blob/master/CamemBERT%20Final.ipynb"
      ],
      "metadata": {
        "id": "YgCWfa36gasN"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "quFBHONy-OG4",
        "outputId": "fa23f82f-efcb-44ab-9cd1-5f2ff3c4c60b"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n",
            "Collecting transformers==3.1.0\n",
            "  Downloading transformers-3.1.0-py3-none-any.whl (884 kB)\n",
            "\u001b[K     |████████████████████████████████| 884 kB 7.2 MB/s \n",
            "\u001b[?25hRequirement already satisfied: filelock in /usr/local/lib/python3.7/dist-packages (from transformers==3.1.0) (3.8.0)\n",
            "Requirement already satisfied: packaging in /usr/local/lib/python3.7/dist-packages (from transformers==3.1.0) (21.3)\n",
            "Requirement already satisfied: tqdm>=4.27 in /usr/local/lib/python3.7/dist-packages (from transformers==3.1.0) (4.64.1)\n",
            "Collecting tokenizers==0.8.1.rc2\n",
            "  Downloading tokenizers-0.8.1rc2-cp37-cp37m-manylinux1_x86_64.whl (3.0 MB)\n",
            "\u001b[K     |████████████████████████████████| 3.0 MB 37.9 MB/s \n",
            "\u001b[?25hCollecting sacremoses\n",
            "  Downloading sacremoses-0.0.53.tar.gz (880 kB)\n",
            "\u001b[K     |████████████████████████████████| 880 kB 47.9 MB/s \n",
            "\u001b[?25hRequirement already satisfied: numpy in /usr/local/lib/python3.7/dist-packages (from transformers==3.1.0) (1.21.6)\n",
            "Collecting sentencepiece!=0.1.92\n",
            "  Downloading sentencepiece-0.1.97-cp37-cp37m-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (1.3 MB)\n",
            "\u001b[K     |████████████████████████████████| 1.3 MB 52.6 MB/s \n",
            "\u001b[?25hRequirement already satisfied: regex!=2019.12.17 in /usr/local/lib/python3.7/dist-packages (from transformers==3.1.0) (2022.6.2)\n",
            "Requirement already satisfied: requests in /usr/local/lib/python3.7/dist-packages (from transformers==3.1.0) (2.23.0)\n",
            "Requirement already satisfied: pyparsing!=3.0.5,>=2.0.2 in /usr/local/lib/python3.7/dist-packages (from packaging->transformers==3.1.0) (3.0.9)\n",
            "Requirement already satisfied: chardet<4,>=3.0.2 in /usr/local/lib/python3.7/dist-packages (from requests->transformers==3.1.0) (3.0.4)\n",
            "Requirement already satisfied: idna<3,>=2.5 in /usr/local/lib/python3.7/dist-packages (from requests->transformers==3.1.0) (2.10)\n",
            "Requirement already satisfied: urllib3!=1.25.0,!=1.25.1,<1.26,>=1.21.1 in /usr/local/lib/python3.7/dist-packages (from requests->transformers==3.1.0) (1.24.3)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.7/dist-packages (from requests->transformers==3.1.0) (2022.9.24)\n",
            "Requirement already satisfied: six in /usr/local/lib/python3.7/dist-packages (from sacremoses->transformers==3.1.0) (1.15.0)\n",
            "Requirement already satisfied: click in /usr/local/lib/python3.7/dist-packages (from sacremoses->transformers==3.1.0) (7.1.2)\n",
            "Requirement already satisfied: joblib in /usr/local/lib/python3.7/dist-packages (from sacremoses->transformers==3.1.0) (1.2.0)\n",
            "Building wheels for collected packages: sacremoses\n",
            "  Building wheel for sacremoses (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for sacremoses: filename=sacremoses-0.0.53-py3-none-any.whl size=895259 sha256=1529833e3ff331a371065dc038b653e3d6d5a76fd915850319f36048b60b279d\n",
            "  Stored in directory: /root/.cache/pip/wheels/87/39/dd/a83eeef36d0bf98e7a4d1933a4ad2d660295a40613079bafc9\n",
            "Successfully built sacremoses\n",
            "Installing collected packages: tokenizers, sentencepiece, sacremoses, transformers\n",
            "Successfully installed sacremoses-0.0.53 sentencepiece-0.1.97 tokenizers-0.8.1rc2 transformers-3.1.0\n"
          ]
        }
      ],
      "source": [
        "!pip install transformers==3.1.0"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Télechagement d'un modèle BERT pré-entrainé. Celui-ci est issue de la base de données SQUAD. \n",
        "uncased= pas de différence entre miniscule et majuscule"
      ],
      "metadata": {
        "id": "z4_6ixUGhMbC"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "import torch\n",
        "from transformers.modeling_camembert import CamembertForQuestionAnswering\n",
        "model_path = 'fmikaelian/camembert-base-fquad'\n",
        "model = CamembertForQuestionAnswering.from_pretrained(model_path)\n",
        "\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 81,
          "referenced_widgets": [
            "0626e18ba6264a1a922833e1f521084f",
            "1e7518ac023d48bc873f5c9ff38a37bf",
            "9798ee00c24c43cda71f53c6466f6d27",
            "acca271c54024434b693702f32332e5b",
            "f0e8f44f39594c95a9c72083aa987864",
            "540520692dfb4232b72ff4417e670ff1",
            "1f5ca29eb077429caf66d219e0e84a8b",
            "19038f3c176841e7bff61b23678e13d0",
            "444effaea56a4c22bd1dd20c180e16e1",
            "8626095ff8554897b47bc0fe8b323041",
            "36d04d5baa9049fd9077a57b032f2a68",
            "10585fe4bd314ce9856d32147bee0979",
            "c6b0320306954162b74569b298eb4e09",
            "733df63441b14da2976133c174459b40",
            "e481d90a3ef8403b87622a0b683f0fbf",
            "3d6bca7d7fc049728ac8d8f70b3a8b1b",
            "008b00c60fdb4519abf38b304a6a5791",
            "d80e2df9e6b44175a70455624e0b1885",
            "29638a224bbb4cf4b1afce71fdf49844",
            "9d7fffe8812145e7b76f142e55a2c30a",
            "22cb93a71bc84689810d56f386a1b345",
            "80d967516400419f84a738edd6a024a5"
          ]
        },
        "id": "o5MkcjhP-gEr",
        "outputId": "43767450-6072-4127-a40d-835bf16feaf1"
      },
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "Downloading:   0%|          | 0.00/517 [00:00<?, ?B/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "0626e18ba6264a1a922833e1f521084f"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "Downloading:   0%|          | 0.00/443M [00:00<?, ?B/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "10585fe4bd314ce9856d32147bee0979"
            }
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from transformers.tokenization_camembert import CamembertTokenizer\n",
        "tokenizer = CamembertTokenizer.from_pretrained(model_path, do_lower_case=True)\n",
        "# Téléchargement d'un tokenizer préentrainé"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 113,
          "referenced_widgets": [
            "2226b23486f84b10ac9f58695c43e84b",
            "33eb933d60214becb346a91e69b4e13b",
            "e789a3bcfd0e4cb8a2def23f2a33df77",
            "c7a49b84767a4f229a5c3c19e1cc52fc",
            "71dd4a8e2d3f48479ab78aead1dabb1b",
            "981a598c15194b5099b8e6c0ea3459cb",
            "aa297f42ce614c168eec074b45088186",
            "e71ba7419f5f464d8d5ad71abeb70bbf",
            "8ad72882b79644cd8533215439c196f4",
            "242d4fb1b2c1475180eea97fe9f5dc2d",
            "2ae61196f96e4179af90152c72383388",
            "a815c7f9465b443fb60ac1cd26dad933",
            "cc089174bbce43b1afb354a606d0a835",
            "5b9b1445b72846c7a1a6db9288910b0e",
            "0230d6a1849a4464b47537a5eb9a05c0",
            "df8be0f47a9b46428c6a8a6a2eee77d2",
            "d4a11ba54e154331a5a235701192b91b",
            "5d6ddced82f44805a2c16bb6200c9cdb",
            "6dfc9c3deed04ce19b559ccc4f1ecc12",
            "e7681899d5fd49e5968b1fb7f56c5657",
            "114d90319fc44171bd01487c125b31e7",
            "96cce063558644d98a0c2c74642ff049",
            "8bc45c630ec94d00be358ff9eb992914",
            "06758bb2ed6d4aec898ff75a693570f2",
            "67c4c1f45ea64cc08bae98f3b0b0679b",
            "2a4bcf18c3a14d6098ae8f905d51d75f",
            "68137bc7d87946af8eccba3fa3762603",
            "6ca1869c54214b86924711697ed51982",
            "757a6423bb1240aaa34468e502d22d4c",
            "b89e0526ebc945e19669463fd779ac63",
            "62641b69b5e043a58b9e553ea14ae983",
            "bfe36b05914242eda9d4a25c72b5bc35",
            "ced198a524844fabac5bf63c75c98ee8"
          ]
        },
        "id": "AZx3nbNZ-gG6",
        "outputId": "fbe2f06c-cb29-463d-f0d4-406758e29e2d"
      },
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "Downloading:   0%|          | 0.00/811k [00:00<?, ?B/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "2226b23486f84b10ac9f58695c43e84b"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "Downloading:   0%|          | 0.00/210 [00:00<?, ?B/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "a815c7f9465b443fb60ac1cd26dad933"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "Downloading:   0%|          | 0.00/23.0 [00:00<?, ?B/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "8bc45c630ec94d00be358ff9eb992914"
            }
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "pip install nltk"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "XTWMUhJF-7wz",
        "outputId": "98d424a9-0705-4410-8023-b51077fb700f"
      },
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n",
            "Requirement already satisfied: nltk in /usr/local/lib/python3.7/dist-packages (3.7)\n",
            "Requirement already satisfied: click in /usr/local/lib/python3.7/dist-packages (from nltk) (7.1.2)\n",
            "Requirement already satisfied: tqdm in /usr/local/lib/python3.7/dist-packages (from nltk) (4.64.1)\n",
            "Requirement already satisfied: regex>=2021.8.3 in /usr/local/lib/python3.7/dist-packages (from nltk) (2022.6.2)\n",
            "Requirement already satisfied: joblib in /usr/local/lib/python3.7/dist-packages (from nltk) (1.2.0)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Création d'une variable pdf_txt qui contient un texte. Nous pouvons aussi extraire le texte directement d'un pdf comme pour le modele word2vec avec les commandes suivantes: \n",
        "\n",
        "'import pdfplumber\n",
        "\n",
        "pdf = pdfplumber.open('lic_policy.pdf')\n",
        "\n",
        "page = pdf.pages[0]\n",
        "\n",
        "page1 = pdf.pages[1]\n",
        "\n",
        "pdf_txt = page.extract_text() + page1.extract_text()\n",
        "\n",
        "pdf.close()'"
      ],
      "metadata": {
        "id": "iMH1v9_oiKN3"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "pdf_txt= \"\"\" Un chatbot est une application qui peut imiter une vraie conversation avec un utilisateur dans sa langue naturelle. \n",
        "Les chatbots permettent la communication via texte ou audio sur des sites Web, des applications de messagerie, des applications mobiles ou par téléphone.\n",
        " Avec SendPulse, vous pouvez facilement créer un robot conversationnel sans connaissances en programmation et gratuitement.\n",
        " Les chatbots utilisent l'apprentissage machine pour identifier les modèles de communication. \n",
        " Au cours des interactions continues avec les humains, ils apprennent à imiter des conversations réelles et à réagir aux demandes verbales ou écrites, à leur tour, en fournissant un service particulier. \n",
        " Comme les chatbots utilisent l'IA, ils comprennent le langage, pas seulement les commandes. \n",
        " Ainsi, au fur et à mesure qu’ils ont plus de conversations avec les utilisateurs ils deviennent plus intelligents. \n",
        " Il est important de noter qu'en dehors des chatbots basés sur l'IA, il existe des chatbots qui utilisent des scripts à choix multiples; en substance, l'option X mène au chemin Y et ainsi de suite.\n",
        " \"\"\"\n",
        "import nltk\n",
        "nltk.download('punkt')\n",
        "tokens = nltk.sent_tokenize(pdf_txt)\n",
        "for t in tokens:\n",
        "    print(t, \"\\n\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Lw-5_1n0OMT6",
        "outputId": "504893f7-97a9-4870-9edc-ae85ab98ed10"
      },
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[nltk_data] Downloading package punkt to /root/nltk_data...\n",
            "[nltk_data]   Unzipping tokenizers/punkt.zip.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            " Un chatbot est une application qui peut imiter une vraie conversation avec un utilisateur dans sa langue naturelle. \n",
            "\n",
            "Les chatbots permettent la communication via texte ou audio sur des sites Web, des applications de messagerie, des applications mobiles ou par téléphone. \n",
            "\n",
            "Avec SendPulse, vous pouvez facilement créer un robot conversationnel sans connaissances en programmation et gratuitement. \n",
            "\n",
            "Les chatbots utilisent l'apprentissage machine pour identifier les modèles de communication. \n",
            "\n",
            "Au cours des interactions continues avec les humains, ils apprennent à imiter des conversations réelles et à réagir aux demandes verbales ou écrites, à leur tour, en fournissant un service particulier. \n",
            "\n",
            "Comme les chatbots utilisent l'IA, ils comprennent le langage, pas seulement les commandes. \n",
            "\n",
            "Ainsi, au fur et à mesure qu’ils ont plus de conversations avec les utilisateurs ils deviennent plus intelligents. \n",
            "\n",
            "Il est important de noter qu'en dehors des chatbots basés sur l'IA, il existe des chatbots qui utilisent des scripts à choix multiples; en substance, l'option X mène au chemin Y et ainsi de suite. \n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "question = \" Comment s'effectue la communication avec un chatbot ?\""
      ],
      "metadata": {
        "id": "S_SbEyeB-gLS"
      },
      "execution_count": 6,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Tokenisation du texte"
      ],
      "metadata": {
        "id": "qFWz20ULjcX4"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "input_ids = tokenizer.encode(question, pdf_txt, max_length=512, truncation=True)\n",
        "print('The input has a total of {:} tokens.'.format(len(input_ids)))\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "zKzladEf-gNz",
        "outputId": "a8ee862e-d1d1-4029-d798-d125dfb95a0b"
      },
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "The input has a total of 230 tokens.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "Impression des jetons avec et de leurs identifiants pour voir exactement ce que fait le tokenizer"
      ],
      "metadata": {
        "id": "VhC3uQVvjpt1"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "tokens = tokenizer.convert_ids_to_tokens(input_ids)\n",
        "for token, id in zip(tokens, input_ids):\n",
        "    if id == tokenizer.sep_token_id:\n",
        "        print('')\n",
        "    print('{:<12} {:>6,}'.format(token, id))\n",
        "\n",
        "    if id == tokenizer.sep_token_id:\n",
        "        print('')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "7Vzj7DY5-gPq",
        "outputId": "fec17288-bc0f-415a-b6c8-3841a6ce3c5c"
      },
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "<s>               5\n",
            "▁comment        404\n",
            "▁s               52\n",
            "'                11\n",
            "effectue     10,170\n",
            "▁la              13\n",
            "▁communication  1,006\n",
            "▁avec            42\n",
            "▁un              23\n",
            "▁chat         1,234\n",
            "bot           8,674\n",
            "▁?              106\n",
            "\n",
            "</s>              6\n",
            "\n",
            "\n",
            "</s>              6\n",
            "\n",
            "▁un              23\n",
            "▁chat         1,234\n",
            "bot           8,674\n",
            "▁est             30\n",
            "▁une             28\n",
            "▁application  1,773\n",
            "▁qui             31\n",
            "▁peut           104\n",
            "▁im           4,129\n",
            "iter          8,332\n",
            "▁une             28\n",
            "▁vraie        2,278\n",
            "▁conversation  4,987\n",
            "▁avec            42\n",
            "▁un              23\n",
            "▁utilisateur  5,398\n",
            "▁dans            29\n",
            "▁sa              77\n",
            "▁langue       1,209\n",
            "▁naturelle    2,588\n",
            ".                 9\n",
            "▁les             19\n",
            "▁chat         1,234\n",
            "bot           8,674\n",
            "s                10\n",
            "▁permettent   1,270\n",
            "▁la              13\n",
            "▁communication  1,006\n",
            "▁via            996\n",
            "▁texte          930\n",
            "▁ou              47\n",
            "▁audio        4,465\n",
            "▁sur             32\n",
            "▁des             20\n",
            "▁sites          596\n",
            "▁web            939\n",
            ",                 7\n",
            "▁des             20\n",
            "▁applications  2,592\n",
            "▁de               8\n",
            "▁messagerie   8,804\n",
            ",                 7\n",
            "▁des             20\n",
            "▁applications  2,592\n",
            "▁mobiles      5,044\n",
            "▁ou              47\n",
            "▁par             37\n",
            "▁téléphone    1,116\n",
            ".                 9\n",
            "▁avec            42\n",
            "▁s               52\n",
            "end             904\n",
            "pulse        17,554\n",
            ",                 7\n",
            "▁vous            39\n",
            "▁pouvez         294\n",
            "▁facilement   1,036\n",
            "▁créer          739\n",
            "▁un              23\n",
            "▁robot        6,430\n",
            "▁conversation  4,987\n",
            "nel           2,378\n",
            "▁sans           112\n",
            "▁connaissances  2,107\n",
            "▁en              22\n",
            "▁programmation  4,732\n",
            "▁et              14\n",
            "▁gratuitement  1,903\n",
            ".                 9\n",
            "▁les             19\n",
            "▁chat         1,234\n",
            "bot           8,674\n",
            "s                10\n",
            "▁utilisent    5,496\n",
            "▁l               17\n",
            "'                11\n",
            "apprentissage  3,215\n",
            "▁machine      1,530\n",
            "▁pour            24\n",
            "▁identifier   6,739\n",
            "▁les             19\n",
            "▁modèles      1,501\n",
            "▁de               8\n",
            "▁communication  1,006\n",
            ".                 9\n",
            "▁au              36\n",
            "▁cours          307\n",
            "▁des             20\n",
            "▁interactions 13,087\n",
            "▁continue     1,439\n",
            "s                10\n",
            "▁avec            42\n",
            "▁les             19\n",
            "▁humains      2,520\n",
            ",                 7\n",
            "▁ils            220\n",
            "▁apprennent  18,984\n",
            "▁à               15\n",
            "▁im           4,129\n",
            "iter          8,332\n",
            "▁des             20\n",
            "▁conversations 14,232\n",
            "▁réelles     10,244\n",
            "▁et              14\n",
            "▁à               15\n",
            "▁réagir       6,152\n",
            "▁aux             68\n",
            "▁demandes     3,083\n",
            "▁verbale     17,963\n",
            "s                10\n",
            "▁ou              47\n",
            "▁écrites     15,266\n",
            ",                 7\n",
            "▁à               15\n",
            "▁leur            97\n",
            "▁tour           508\n",
            ",                 7\n",
            "▁en              22\n",
            "▁fournissant 21,270\n",
            "▁un              23\n",
            "▁service        366\n",
            "▁particulier    770\n",
            ".                 9\n",
            "▁comme           79\n",
            "▁les             19\n",
            "▁chat         1,234\n",
            "bot           8,674\n",
            "s                10\n",
            "▁utilisent    5,496\n",
            "▁l               17\n",
            "'                11\n",
            "ia            1,035\n",
            ",                 7\n",
            "▁ils            220\n",
            "▁comprennent  6,758\n",
            "▁le              16\n",
            "▁langage      3,015\n",
            ",                 7\n",
            "▁pas             34\n",
            "▁seulement      446\n",
            "▁les             19\n",
            "▁commandes    3,963\n",
            ".                 9\n",
            "▁ainsi          163\n",
            ",                 7\n",
            "▁au              36\n",
            "▁fur          4,148\n",
            "▁et              14\n",
            "▁à               15\n",
            "▁mesure         586\n",
            "▁qu              46\n",
            "’                12\n",
            "ils             240\n",
            "▁ont             96\n",
            "▁plus            40\n",
            "▁de               8\n",
            "▁conversations 14,232\n",
            "▁avec            42\n",
            "▁les             19\n",
            "▁utilisateurs  1,827\n",
            "▁ils            220\n",
            "▁deviennent   4,968\n",
            "▁plus            40\n",
            "▁intelligents 18,447\n",
            ".                 9\n",
            "▁il              51\n",
            "▁est             30\n",
            "▁important      693\n",
            "▁de               8\n",
            "▁noter        2,287\n",
            "▁qu              46\n",
            "'                11\n",
            "en               90\n",
            "▁dehors       2,058\n",
            "▁des             20\n",
            "▁chat         1,234\n",
            "bot           8,674\n",
            "s                10\n",
            "▁basés       17,966\n",
            "▁sur             32\n",
            "▁l               17\n",
            "'                11\n",
            "ia            1,035\n",
            ",                 7\n",
            "▁il              51\n",
            "▁existe         947\n",
            "▁des             20\n",
            "▁chat         1,234\n",
            "bot           8,674\n",
            "s                10\n",
            "▁qui             31\n",
            "▁utilisent    5,496\n",
            "▁des             20\n",
            "▁script      10,936\n",
            "s                10\n",
            "▁à               15\n",
            "▁choix          414\n",
            "▁multiples    2,523\n",
            ";               154\n",
            "▁en              22\n",
            "▁substance    9,152\n",
            ",                 7\n",
            "▁l               17\n",
            "'                11\n",
            "option        4,932\n",
            "▁x              758\n",
            "▁mène         5,242\n",
            "▁au              36\n",
            "▁chemin       1,111\n",
            "▁y              102\n",
            "▁et              14\n",
            "▁ainsi          163\n",
            "▁de               8\n",
            "▁suite          282\n",
            ".                 9\n",
            "\n",
            "</s>              6\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "La question et pdf_txt ( le texte) peuvent être concatener ensemble, mais BERT a toujours besoin d'un moyen de les distinguer. BERT a deux encastrements spéciaux \"Segment\", un pour le segment \"A\" et un pour le segment \"B\". Avant que les intégrations de mots n'entrent dans les couches BERT, l'intégration du segment A doit être ajoutée aux jetons de question, et l'intégration du segment B doit être ajoutée à chacun des jetons answer_text.\n",
        "Celles-ci sont gérées par la bibliothèque de transformateurs et tout ce que nous avons à faire est de spécifier '0' et '1' pour le jeton."
      ],
      "metadata": {
        "id": "PKM1QqEqkMnb"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "sep_index = input_ids.index(tokenizer.sep_token_id)\n",
        "num_seg_a = sep_index + 1\n",
        "num_seg_b = len(input_ids) - num_seg_a\n",
        "#Here We Construct the list of 0s and 1s.\n",
        "segment_ids = [0]*num_seg_a + [1]*num_seg_b\n",
        "# There should be a segment_id for every input token.\n",
        "assert len(segment_ids) == len(input_ids)"
      ],
      "metadata": {
        "id": "rXRziKnT_R63"
      },
      "execution_count": 9,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Ici, nous alimentons pdf_txt et la question dans le modèle"
      ],
      "metadata": {
        "id": "jwNaIzvHkh48"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "start_scores, end_scores = model(torch.tensor([input_ids]))\n",
        "#start_scores, end_scores = model(torch.tensor([input_ids]), token_type_ids=torch.tensor([segment_ids]))"
      ],
      "metadata": {
        "id": "c8G6BYtQ_R9O"
      },
      "execution_count": 12,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Ici, nous trouvons les scores 'début' et 'fin' les plus élevés et combinons les jetons dans la réponse et imprimons la réponse"
      ],
      "metadata": {
        "id": "ZL7v2T5ekuNJ"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "answer_start = torch.argmax(start_scores)\n",
        "answer_end = torch.argmax(end_scores)\n",
        "\n",
        "answer = ' '.join(tokens[answer_start:answer_end+1])\n",
        "print ('Question \"' + question + '\"' )\n",
        "print('Answer: \"' + answer + '\"')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "orl2LjX-_R_v",
        "outputId": "a5ea7f59-bd4e-4925-8f77-dd5a51bf424e"
      },
      "execution_count": 13,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Question \" Comment s'effectue la communication avec un chatbot ?\"\n",
            "Answer: \"▁via ▁texte ▁ou ▁audio ▁sur ▁des ▁sites ▁web , ▁des ▁applications ▁de ▁messagerie , ▁des ▁applications ▁mobiles ▁ou ▁par ▁téléphone\"\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Nous pouvons reconstruire tous les mots qui ont été décomposés en sous-mots."
      ],
      "metadata": {
        "id": "HMlmuXm-k39L"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "answer = tokens[answer_start]\n",
        "answer = tokens[answer_start]\n",
        "\n",
        "# Select the remaining answer tokens and join them with whitespace.\n",
        "for i in range(answer_start + 1, answer_end + 1):\n",
        "  # If it's a subword token, then recombine it with the previous token.\n",
        "    if tokens[i][0:2] == '##':\n",
        "        answer += tokens[i][2:]\n",
        "        # Otherwise, add a space then the token.\n",
        "    else:\n",
        "        answer += ' ' + tokens[i]\n",
        "print('Answer: \"' + answer + '\"')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Dakizn0cBWiP",
        "outputId": "4ada761a-4d8a-45b6-fef6-ecdf08e8e83a"
      },
      "execution_count": 14,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Answer: \"▁via ▁texte ▁ou ▁audio ▁sur ▁des ▁sites ▁web , ▁des ▁applications ▁de ▁messagerie , ▁des ▁applications ▁mobiles ▁ou ▁par ▁téléphone\"\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Cette partie est une fonction regroupant les commandes précédentes"
      ],
      "metadata": {
        "id": "flrSsB41lDDY"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def answer_question(question, pdf_txt):\n",
        "\n",
        "    input_ids = tokenizer.encode(question, pdf_txt, max_length=512, truncation=True)\n",
        "\n",
        "    print('Query has {:,} tokens.\\n'.format(len(input_ids)))\n",
        "\n",
        "    sep_index = input_ids.index(tokenizer.sep_token_id)\n",
        "\n",
        "    num_seg_a = sep_index + 1\n",
        "\n",
        "    num_seg_b = len(input_ids) - num_seg_a\n",
        "\n",
        "    segment_ids = [0]*num_seg_a + [1]*num_seg_b\n",
        "\n",
        "    assert len(segment_ids) == len(input_ids)\n",
        "\n",
        "    start_scores, end_scores = model(torch.tensor([input_ids]), token_type_ids=torch.tensor([segment_ids]))\n",
        "\n",
        "    all_tokens = tokenizer.convert_ids_to_tokens(input_ids)\n",
        "\n",
        "    #print(' '.join(all_tokens[torch.argmax(start_scores) : torch.argmax(end_scores)+1]))\n",
        "    #print(f'score: {torch.max(start_scores)}')\n",
        "    score = float(torch.max(start_scores))\n",
        "    answer_start = torch.argmax(start_scores)\n",
        "    answer_end = torch.argmax(end_scores)\n",
        "    tokens = tokenizer.convert_ids_to_tokens(input_ids)\n",
        "    answer = tokens[answer_start]\n",
        "\n",
        "    for i in range(answer_start + 1, answer_end + 1):\n",
        "\n",
        "        if tokens[i][0:2] == ' ':\n",
        "            answer += tokens[i][2:]\n",
        "\n",
        "        else:\n",
        "            answer += ' ' + tokens[i]\n",
        "    return answer, score\n",
        "    print('Answer: \"' + answer + '\"')"
      ],
      "metadata": {
        "id": "qyQJ5SrL_SEJ"
      },
      "execution_count": 15,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "answer_question(question, pdf_txt)\n",
        "# On applique la fonction sur la question et le texte pour obtenir une réponse"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 363
        },
        "id": "quWSkKNX_byx",
        "outputId": "342a7dca-1d84-48ac-8cc1-74397176a744"
      },
      "execution_count": 16,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Query has 230 tokens.\n",
            "\n"
          ]
        },
        {
          "output_type": "error",
          "ename": "IndexError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mIndexError\u001b[0m                                Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-16-17c8c891cc19>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0manswer_question\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mquestion\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mpdf_txt\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      2\u001b[0m \u001b[0;31m# On applique la fonction sur la question et le texte pour obtenir une réponse\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m<ipython-input-15-45d13885f70d>\u001b[0m in \u001b[0;36manswer_question\u001b[0;34m(question, pdf_txt)\u001b[0m\n\u001b[1;32m     15\u001b[0m     \u001b[0;32massert\u001b[0m \u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msegment_ids\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minput_ids\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     16\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 17\u001b[0;31m     \u001b[0mstart_scores\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mend_scores\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtensor\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0minput_ids\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtoken_type_ids\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtensor\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0msegment_ids\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     18\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     19\u001b[0m     \u001b[0mall_tokens\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtokenizer\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mconvert_ids_to_tokens\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minput_ids\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_call_impl\u001b[0;34m(self, *input, **kwargs)\u001b[0m\n\u001b[1;32m   1128\u001b[0m         if not (self._backward_hooks or self._forward_hooks or self._forward_pre_hooks or _global_backward_hooks\n\u001b[1;32m   1129\u001b[0m                 or _global_forward_hooks or _global_forward_pre_hooks):\n\u001b[0;32m-> 1130\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mforward_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1131\u001b[0m         \u001b[0;31m# Do not call functions when jit is used\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1132\u001b[0m         \u001b[0mfull_backward_hooks\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnon_full_backward_hooks\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/transformers/modeling_roberta.py\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, input_ids, attention_mask, token_type_ids, position_ids, head_mask, inputs_embeds, start_positions, end_positions, output_attentions, output_hidden_states, return_dict)\u001b[0m\n\u001b[1;32m    763\u001b[0m             \u001b[0moutput_attentions\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0moutput_attentions\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    764\u001b[0m             \u001b[0moutput_hidden_states\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0moutput_hidden_states\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 765\u001b[0;31m             \u001b[0mreturn_dict\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mreturn_dict\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    766\u001b[0m         )\n\u001b[1;32m    767\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_call_impl\u001b[0;34m(self, *input, **kwargs)\u001b[0m\n\u001b[1;32m   1128\u001b[0m         if not (self._backward_hooks or self._forward_hooks or self._forward_pre_hooks or _global_backward_hooks\n\u001b[1;32m   1129\u001b[0m                 or _global_forward_hooks or _global_forward_pre_hooks):\n\u001b[0;32m-> 1130\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mforward_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1131\u001b[0m         \u001b[0;31m# Do not call functions when jit is used\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1132\u001b[0m         \u001b[0mfull_backward_hooks\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnon_full_backward_hooks\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/transformers/modeling_bert.py\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, input_ids, attention_mask, token_type_ids, position_ids, head_mask, inputs_embeds, encoder_hidden_states, encoder_attention_mask, output_attentions, output_hidden_states, return_dict)\u001b[0m\n\u001b[1;32m    823\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    824\u001b[0m         embedding_output = self.embeddings(\n\u001b[0;32m--> 825\u001b[0;31m             \u001b[0minput_ids\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0minput_ids\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mposition_ids\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mposition_ids\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtoken_type_ids\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mtoken_type_ids\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minputs_embeds\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0minputs_embeds\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    826\u001b[0m         )\n\u001b[1;32m    827\u001b[0m         encoder_outputs = self.encoder(\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_call_impl\u001b[0;34m(self, *input, **kwargs)\u001b[0m\n\u001b[1;32m   1128\u001b[0m         if not (self._backward_hooks or self._forward_hooks or self._forward_pre_hooks or _global_backward_hooks\n\u001b[1;32m   1129\u001b[0m                 or _global_forward_hooks or _global_forward_pre_hooks):\n\u001b[0;32m-> 1130\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mforward_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1131\u001b[0m         \u001b[0;31m# Do not call functions when jit is used\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1132\u001b[0m         \u001b[0mfull_backward_hooks\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnon_full_backward_hooks\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/transformers/modeling_roberta.py\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, input_ids, token_type_ids, position_ids, inputs_embeds)\u001b[0m\n\u001b[1;32m     80\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     81\u001b[0m         return super().forward(\n\u001b[0;32m---> 82\u001b[0;31m             \u001b[0minput_ids\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtoken_type_ids\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mtoken_type_ids\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mposition_ids\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mposition_ids\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minputs_embeds\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0minputs_embeds\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     83\u001b[0m         )\n\u001b[1;32m     84\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/transformers/modeling_bert.py\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, input_ids, token_type_ids, position_ids, inputs_embeds)\u001b[0m\n\u001b[1;32m    207\u001b[0m             \u001b[0minputs_embeds\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mword_embeddings\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minput_ids\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    208\u001b[0m         \u001b[0mposition_embeddings\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mposition_embeddings\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mposition_ids\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 209\u001b[0;31m         \u001b[0mtoken_type_embeddings\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtoken_type_embeddings\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtoken_type_ids\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    210\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    211\u001b[0m         \u001b[0membeddings\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0minputs_embeds\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0mposition_embeddings\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0mtoken_type_embeddings\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_call_impl\u001b[0;34m(self, *input, **kwargs)\u001b[0m\n\u001b[1;32m   1128\u001b[0m         if not (self._backward_hooks or self._forward_hooks or self._forward_pre_hooks or _global_backward_hooks\n\u001b[1;32m   1129\u001b[0m                 or _global_forward_hooks or _global_forward_pre_hooks):\n\u001b[0;32m-> 1130\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mforward_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1131\u001b[0m         \u001b[0;31m# Do not call functions when jit is used\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1132\u001b[0m         \u001b[0mfull_backward_hooks\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnon_full_backward_hooks\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/torch/nn/modules/sparse.py\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, input)\u001b[0m\n\u001b[1;32m    158\u001b[0m         return F.embedding(\n\u001b[1;32m    159\u001b[0m             \u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mweight\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpadding_idx\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmax_norm\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 160\u001b[0;31m             self.norm_type, self.scale_grad_by_freq, self.sparse)\n\u001b[0m\u001b[1;32m    161\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    162\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mextra_repr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m->\u001b[0m \u001b[0mstr\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/torch/nn/functional.py\u001b[0m in \u001b[0;36membedding\u001b[0;34m(input, weight, padding_idx, max_norm, norm_type, scale_grad_by_freq, sparse)\u001b[0m\n\u001b[1;32m   2197\u001b[0m         \u001b[0;31m# remove once script supports set_grad_enabled\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2198\u001b[0m         \u001b[0m_no_grad_embedding_renorm_\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mweight\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmax_norm\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnorm_type\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 2199\u001b[0;31m     \u001b[0;32mreturn\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0membedding\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mweight\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mpadding_idx\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mscale_grad_by_freq\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msparse\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   2200\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2201\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mIndexError\u001b[0m: index out of range in self"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "* Ici, nous utilisons la méthode tokenizers encode_plus pour créer nos jetons à partir de la chaîne de texte\n",
        "* add_special_tokens=True ajoute des jetons BERT spéciaux comme [CLS], [SEP] et [PAD] à nos nouveaux encodages \"tokénisés\"\n",
        "* max_length=512 indique à l'encodeur la longueur cible de nos encodages\n",
        "* truncation=True garantit que nous coupons toutes les séquences qui sont plus longues que le\n",
        "max_length spécifié.\n",
        "* padding=\"max_length\" indique à l'encodeur de remplir toutes les séquences plus courtes que le max_length avec des jetons de remplissage."
      ],
      "metadata": {
        "id": "bJGcCShXlfw0"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "tokens = tokenizer.encode_plus(question, pdf_txt, add_special_tokens=True, max_length=512, truncation=True, padding=\"max_length\")\n",
        "tokens"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "HzYIVilC_b1h",
        "outputId": "53fe58d6-91ca-45eb-fcd3-923e12540e4f"
      },
      "execution_count": 17,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "{'input_ids': [5, 404, 52, 11, 10170, 13, 1006, 42, 23, 1234, 8674, 106, 6, 6, 23, 1234, 8674, 30, 28, 1773, 31, 104, 4129, 8332, 28, 2278, 4987, 42, 23, 5398, 29, 77, 1209, 2588, 9, 19, 1234, 8674, 10, 1270, 13, 1006, 996, 930, 47, 4465, 32, 20, 596, 939, 7, 20, 2592, 8, 8804, 7, 20, 2592, 5044, 47, 37, 1116, 9, 42, 52, 904, 17554, 7, 39, 294, 1036, 739, 23, 6430, 4987, 2378, 112, 2107, 22, 4732, 14, 1903, 9, 19, 1234, 8674, 10, 5496, 17, 11, 3215, 1530, 24, 6739, 19, 1501, 8, 1006, 9, 36, 307, 20, 13087, 1439, 10, 42, 19, 2520, 7, 220, 18984, 15, 4129, 8332, 20, 14232, 10244, 14, 15, 6152, 68, 3083, 17963, 10, 47, 15266, 7, 15, 97, 508, 7, 22, 21270, 23, 366, 770, 9, 79, 19, 1234, 8674, 10, 5496, 17, 11, 1035, 7, 220, 6758, 16, 3015, 7, 34, 446, 19, 3963, 9, 163, 7, 36, 4148, 14, 15, 586, 46, 12, 240, 96, 40, 8, 14232, 42, 19, 1827, 220, 4968, 40, 18447, 9, 51, 30, 693, 8, 2287, 46, 11, 90, 2058, 20, 1234, 8674, 10, 17966, 32, 17, 11, 1035, 7, 51, 947, 20, 1234, 8674, 10, 31, 5496, 20, 10936, 10, 15, 414, 2523, 154, 22, 9152, 7, 17, 11, 4932, 758, 5242, 36, 1111, 102, 14, 163, 8, 282, 9, 6, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1], 'attention_mask': [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]}"
            ]
          },
          "metadata": {},
          "execution_count": 17
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Il renvoie un dictionnaire contenant trois paires clé-valeur, input_ids,\n",
        "token_type_ids et attention_mask .\n",
        "Nous avons également ajouté return_tensors='pt' pour renvoyer les tenseurs PyTorch du\n",
        "tokenizer (plutôt que des listes Python)."
      ],
      "metadata": {
        "id": "oX3FZNVrlx5j"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "tokens = tokenizer.encode_plus(pdf_txt, add_special_tokens=False, return_tensors='pt')\n",
        "tokens"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "X3ae8IAkFVBF",
        "outputId": "ef135fc2-4058-41e0-e90b-70887bff7771"
      },
      "execution_count": 18,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "{'input_ids': tensor([[   23,  1234,  8674,    30,    28,  1773,    31,   104,  4129,  8332,\n",
              "            28,  2278,  4987,    42,    23,  5398,    29,    77,  1209,  2588,\n",
              "             9,    19,  1234,  8674,    10,  1270,    13,  1006,   996,   930,\n",
              "            47,  4465,    32,    20,   596,   939,     7,    20,  2592,     8,\n",
              "          8804,     7,    20,  2592,  5044,    47,    37,  1116,     9,    42,\n",
              "            52,   904, 17554,     7,    39,   294,  1036,   739,    23,  6430,\n",
              "          4987,  2378,   112,  2107,    22,  4732,    14,  1903,     9,    19,\n",
              "          1234,  8674,    10,  5496,    17,    11,  3215,  1530,    24,  6739,\n",
              "            19,  1501,     8,  1006,     9,    36,   307,    20, 13087,  1439,\n",
              "            10,    42,    19,  2520,     7,   220, 18984,    15,  4129,  8332,\n",
              "            20, 14232, 10244,    14,    15,  6152,    68,  3083, 17963,    10,\n",
              "            47, 15266,     7,    15,    97,   508,     7,    22, 21270,    23,\n",
              "           366,   770,     9,    79,    19,  1234,  8674,    10,  5496,    17,\n",
              "            11,  1035,     7,   220,  6758,    16,  3015,     7,    34,   446,\n",
              "            19,  3963,     9,   163,     7,    36,  4148,    14,    15,   586,\n",
              "            46,    12,   240,    96,    40,     8, 14232,    42,    19,  1827,\n",
              "           220,  4968,    40, 18447,     9,    51,    30,   693,     8,  2287,\n",
              "            46,    11,    90,  2058,    20,  1234,  8674,    10, 17966,    32,\n",
              "            17,    11,  1035,     7,    51,   947,    20,  1234,  8674,    10,\n",
              "            31,  5496,    20, 10936,    10,    15,   414,  2523,   154,    22,\n",
              "          9152,     7,    17,    11,  4932,   758,  5242,    36,  1111,   102,\n",
              "            14,   163,     8,   282,     9]]), 'attention_mask': tensor([[1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
              "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
              "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
              "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
              "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
              "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
              "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
              "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
              "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1]])}"
            ]
          },
          "metadata": {},
          "execution_count": 18
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "input_id_chunks = tokens['input_ids'][0].split(510)\n",
        "mask_chunks = tokens['attention_mask'][0].split(510)\n",
        "\n",
        "for tensor in input_id_chunks:\n",
        "  print(len(tensor))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "qGjPLBWz_b4S",
        "outputId": "beb17d4f-596a-4cb6-8d51-ca1a15537a63"
      },
      "execution_count": 19,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "215\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "a = torch.arange(10)\n",
        "a"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "jcFJOS2V_b6p",
        "outputId": "9825ec44-a3b1-4b86-e718-cb2e6b9fcbb9"
      },
      "execution_count": 20,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "tensor([0, 1, 2, 3, 4, 5, 6, 7, 8, 9])"
            ]
          },
          "metadata": {},
          "execution_count": 20
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "torch.cat(\n",
        "    [torch.Tensor([101]), a, torch.Tensor([102])]\n",
        ")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "44yegsjJ_b9J",
        "outputId": "191d8e14-507e-46ba-a232-fd32ac0a0efc"
      },
      "execution_count": 21,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "tensor([101.,   0.,   1.,   2.,   3.,   4.,   5.,   6.,   7.,   8.,   9., 102.])"
            ]
          },
          "metadata": {},
          "execution_count": 21
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "***Préparer les morceaux***\n",
        "\n",
        "Nous avons maintenant notre tenseur tokenisé ; nous devons le diviser en morceaux ne dépassant pas 510 jetons. Nous choisissons 510 plutôt que 512 pour laisser deux places libres pour ajouter nos jetons [CLS] et [SEP].\n",
        "\n",
        "***Diviser***\n",
        "\n",
        "\n",
        "Nous appliquons la méthode de fractionnement à la fois à nos ID d'entrée et aux tenseurs de masque d'attention (nous\n",
        "n'ont pas besoin des ID de type de jeton et peuvent les supprimer). Nous avons maintenant trois morceaux pour chaque ensemble de tenseurs. Notez que nous devrons ajouter un rembourrage au dernier morceau car il ne satisfera pas la taille de tenseur de 512 requise par BERT.\n",
        "\n",
        "\n",
        "***CLS et SEP***\n",
        "\n",
        "\n",
        "Ensuite, nous ajoutons les jetons de début de séquence [CLS] et de séparateur [SEP]. Pour cela, nous pouvons utiliser la fonction torch.cat, qui concatène une liste de tenseurs.\n",
        "Nos jetons sont déjà au format d'identification de jeton, nous pouvons donc nous référer aux jetons spéciaux\n",
        "tableau ci-dessus pour créer les versions d'ID de jeton de nos jetons [CLS] et [SEP].\n",
        "Parce que nous faisons cela pour plusieurs tenseurs, nous plaçons la fonction torch.cat dans\n",
        "une boucle for et effectuer la concaténation pour chacun de nos morceaux individuellement.\n",
        "De plus, nos blocs de masque d'attention sont concaténés avec des 1 au lieu de 101\n",
        "et 102. Nous faisons cela parce que le masque d'attention ne contient pas d'ID de jeton mais\n",
        "à la place un ensemble de 1 et de 0.\n",
        "Les zéros dans le masque d'attention représentent l'emplacement des jetons de remplissage (que nous allons\n",
        "add next), et comme [CLS] et [SEP] ne sont pas des jetons de remplissage, ils sont représentés\n",
        "avec 1s.\n",
        "\n",
        "***Rembourrage***\n",
        "\n",
        "\n",
        "Nous devons ajouter un rembourrage à nos morceaux de tenseur pour nous assurer qu'ils satisfont à la longueur de tenseur de 512 requise par BERT. Nos deux premiers morceaux ne nécessitent aucun rembourrage car ils satisfont déjà à cette exigence de longueur, mais les derniers morceaux le font.\n",
        "Pour vérifier si un morceau nécessite un remplissage, nous ajoutons une instruction if qui vérifie la longueur du tenseur. Si le tenseur est plus court que 512 jetons, nous ajoutons un rembourrage à l'aide de la fonction torch.cat. Nous devrions ajouter cette déclaration à la même boucle for où nous ajoutons nos jetons [CLS] et [SEP] - si vous avez besoin d'aide, j'ai inclus les scripts complets à la fin de l'article."
      ],
      "metadata": {
        "id": "-NLeJsganP-Z"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "chunksize = 512\n",
        "\n",
        "input_id_chunks = list(tokens['input_ids'][0].split(chunksize - 2))\n",
        "mask_chunks = list(tokens['attention_mask'][0].split(chunksize - 2))\n",
        "\n",
        "for i in range(len(input_id_chunks)):\n",
        "    input_id_chunks[i] = torch.cat([\n",
        "        torch.tensor([101]), input_id_chunks[i], torch.tensor([102])\n",
        "    ])\n",
        "    mask_chunks[i] = torch.cat([\n",
        "        torch.tensor([1]), mask_chunks[i], torch.tensor([1])\n",
        "    ])\n",
        "\n",
        "    pad_len = chunksize - input_id_chunks[i].shape[0]\n",
        "    if pad_len > 0:\n",
        "        input_id_chunks[i] = torch.cat([\n",
        "            input_id_chunks[i], torch.Tensor([0] * pad_len)\n",
        "        ])\n",
        "        mask_chunks[i] = torch.cat([\n",
        "            mask_chunks[i], torch.Tensor([0] * pad_len)\n",
        "        ])\n",
        "\n",
        "for chunk in input_id_chunks:\n",
        "    print(chunk)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "JSG7d6xs_cAJ",
        "outputId": "baaf1006-2bb9-4c20-f8bb-c67b365b21c5"
      },
      "execution_count": 22,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "tensor([1.0100e+02, 2.3000e+01, 1.2340e+03, 8.6740e+03, 3.0000e+01, 2.8000e+01,\n",
            "        1.7730e+03, 3.1000e+01, 1.0400e+02, 4.1290e+03, 8.3320e+03, 2.8000e+01,\n",
            "        2.2780e+03, 4.9870e+03, 4.2000e+01, 2.3000e+01, 5.3980e+03, 2.9000e+01,\n",
            "        7.7000e+01, 1.2090e+03, 2.5880e+03, 9.0000e+00, 1.9000e+01, 1.2340e+03,\n",
            "        8.6740e+03, 1.0000e+01, 1.2700e+03, 1.3000e+01, 1.0060e+03, 9.9600e+02,\n",
            "        9.3000e+02, 4.7000e+01, 4.4650e+03, 3.2000e+01, 2.0000e+01, 5.9600e+02,\n",
            "        9.3900e+02, 7.0000e+00, 2.0000e+01, 2.5920e+03, 8.0000e+00, 8.8040e+03,\n",
            "        7.0000e+00, 2.0000e+01, 2.5920e+03, 5.0440e+03, 4.7000e+01, 3.7000e+01,\n",
            "        1.1160e+03, 9.0000e+00, 4.2000e+01, 5.2000e+01, 9.0400e+02, 1.7554e+04,\n",
            "        7.0000e+00, 3.9000e+01, 2.9400e+02, 1.0360e+03, 7.3900e+02, 2.3000e+01,\n",
            "        6.4300e+03, 4.9870e+03, 2.3780e+03, 1.1200e+02, 2.1070e+03, 2.2000e+01,\n",
            "        4.7320e+03, 1.4000e+01, 1.9030e+03, 9.0000e+00, 1.9000e+01, 1.2340e+03,\n",
            "        8.6740e+03, 1.0000e+01, 5.4960e+03, 1.7000e+01, 1.1000e+01, 3.2150e+03,\n",
            "        1.5300e+03, 2.4000e+01, 6.7390e+03, 1.9000e+01, 1.5010e+03, 8.0000e+00,\n",
            "        1.0060e+03, 9.0000e+00, 3.6000e+01, 3.0700e+02, 2.0000e+01, 1.3087e+04,\n",
            "        1.4390e+03, 1.0000e+01, 4.2000e+01, 1.9000e+01, 2.5200e+03, 7.0000e+00,\n",
            "        2.2000e+02, 1.8984e+04, 1.5000e+01, 4.1290e+03, 8.3320e+03, 2.0000e+01,\n",
            "        1.4232e+04, 1.0244e+04, 1.4000e+01, 1.5000e+01, 6.1520e+03, 6.8000e+01,\n",
            "        3.0830e+03, 1.7963e+04, 1.0000e+01, 4.7000e+01, 1.5266e+04, 7.0000e+00,\n",
            "        1.5000e+01, 9.7000e+01, 5.0800e+02, 7.0000e+00, 2.2000e+01, 2.1270e+04,\n",
            "        2.3000e+01, 3.6600e+02, 7.7000e+02, 9.0000e+00, 7.9000e+01, 1.9000e+01,\n",
            "        1.2340e+03, 8.6740e+03, 1.0000e+01, 5.4960e+03, 1.7000e+01, 1.1000e+01,\n",
            "        1.0350e+03, 7.0000e+00, 2.2000e+02, 6.7580e+03, 1.6000e+01, 3.0150e+03,\n",
            "        7.0000e+00, 3.4000e+01, 4.4600e+02, 1.9000e+01, 3.9630e+03, 9.0000e+00,\n",
            "        1.6300e+02, 7.0000e+00, 3.6000e+01, 4.1480e+03, 1.4000e+01, 1.5000e+01,\n",
            "        5.8600e+02, 4.6000e+01, 1.2000e+01, 2.4000e+02, 9.6000e+01, 4.0000e+01,\n",
            "        8.0000e+00, 1.4232e+04, 4.2000e+01, 1.9000e+01, 1.8270e+03, 2.2000e+02,\n",
            "        4.9680e+03, 4.0000e+01, 1.8447e+04, 9.0000e+00, 5.1000e+01, 3.0000e+01,\n",
            "        6.9300e+02, 8.0000e+00, 2.2870e+03, 4.6000e+01, 1.1000e+01, 9.0000e+01,\n",
            "        2.0580e+03, 2.0000e+01, 1.2340e+03, 8.6740e+03, 1.0000e+01, 1.7966e+04,\n",
            "        3.2000e+01, 1.7000e+01, 1.1000e+01, 1.0350e+03, 7.0000e+00, 5.1000e+01,\n",
            "        9.4700e+02, 2.0000e+01, 1.2340e+03, 8.6740e+03, 1.0000e+01, 3.1000e+01,\n",
            "        5.4960e+03, 2.0000e+01, 1.0936e+04, 1.0000e+01, 1.5000e+01, 4.1400e+02,\n",
            "        2.5230e+03, 1.5400e+02, 2.2000e+01, 9.1520e+03, 7.0000e+00, 1.7000e+01,\n",
            "        1.1000e+01, 4.9320e+03, 7.5800e+02, 5.2420e+03, 3.6000e+01, 1.1110e+03,\n",
            "        1.0200e+02, 1.4000e+01, 1.6300e+02, 8.0000e+00, 2.8200e+02, 9.0000e+00,\n",
            "        1.0200e+02, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00,\n",
            "        0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00,\n",
            "        0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00,\n",
            "        0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00,\n",
            "        0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00,\n",
            "        0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00,\n",
            "        0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00,\n",
            "        0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00,\n",
            "        0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00,\n",
            "        0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00,\n",
            "        0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00,\n",
            "        0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00,\n",
            "        0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00,\n",
            "        0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00,\n",
            "        0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00,\n",
            "        0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00,\n",
            "        0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00,\n",
            "        0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00,\n",
            "        0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00,\n",
            "        0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00,\n",
            "        0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00,\n",
            "        0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00,\n",
            "        0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00,\n",
            "        0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00,\n",
            "        0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00,\n",
            "        0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00,\n",
            "        0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00,\n",
            "        0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00,\n",
            "        0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00,\n",
            "        0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00,\n",
            "        0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00,\n",
            "        0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00,\n",
            "        0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00,\n",
            "        0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00,\n",
            "        0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00,\n",
            "        0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00,\n",
            "        0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00,\n",
            "        0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00,\n",
            "        0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00,\n",
            "        0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00,\n",
            "        0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00,\n",
            "        0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00,\n",
            "        0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00,\n",
            "        0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00,\n",
            "        0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00,\n",
            "        0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00,\n",
            "        0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00,\n",
            "        0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00,\n",
            "        0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00,\n",
            "        0.0000e+00, 0.0000e+00])\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "for tensor in range(len(input_id_chunks)):\n",
        "  ans = answer_question(question, ' '.join(tokenizer.convert_ids_to_tokens(input_id_chunks[tensor])))\n",
        "  print(ans)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 380
        },
        "id": "lx5Ydiwz_cG5",
        "outputId": "73be82c0-5082-494a-a903-4c76da1b04c3"
      },
      "execution_count": 23,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Query has 512 tokens.\n",
            "\n"
          ]
        },
        {
          "output_type": "error",
          "ename": "IndexError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mIndexError\u001b[0m                                Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-23-e21fbf35de72>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mtensor\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mrange\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minput_id_chunks\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 2\u001b[0;31m   \u001b[0mans\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0manswer_question\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mquestion\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m' '\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mjoin\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtokenizer\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mconvert_ids_to_tokens\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minput_id_chunks\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mtensor\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      3\u001b[0m   \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mans\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m<ipython-input-15-45d13885f70d>\u001b[0m in \u001b[0;36manswer_question\u001b[0;34m(question, pdf_txt)\u001b[0m\n\u001b[1;32m     15\u001b[0m     \u001b[0;32massert\u001b[0m \u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msegment_ids\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minput_ids\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     16\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 17\u001b[0;31m     \u001b[0mstart_scores\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mend_scores\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtensor\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0minput_ids\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtoken_type_ids\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtensor\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0msegment_ids\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     18\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     19\u001b[0m     \u001b[0mall_tokens\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtokenizer\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mconvert_ids_to_tokens\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minput_ids\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_call_impl\u001b[0;34m(self, *input, **kwargs)\u001b[0m\n\u001b[1;32m   1128\u001b[0m         if not (self._backward_hooks or self._forward_hooks or self._forward_pre_hooks or _global_backward_hooks\n\u001b[1;32m   1129\u001b[0m                 or _global_forward_hooks or _global_forward_pre_hooks):\n\u001b[0;32m-> 1130\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mforward_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1131\u001b[0m         \u001b[0;31m# Do not call functions when jit is used\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1132\u001b[0m         \u001b[0mfull_backward_hooks\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnon_full_backward_hooks\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/transformers/modeling_roberta.py\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, input_ids, attention_mask, token_type_ids, position_ids, head_mask, inputs_embeds, start_positions, end_positions, output_attentions, output_hidden_states, return_dict)\u001b[0m\n\u001b[1;32m    763\u001b[0m             \u001b[0moutput_attentions\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0moutput_attentions\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    764\u001b[0m             \u001b[0moutput_hidden_states\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0moutput_hidden_states\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 765\u001b[0;31m             \u001b[0mreturn_dict\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mreturn_dict\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    766\u001b[0m         )\n\u001b[1;32m    767\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_call_impl\u001b[0;34m(self, *input, **kwargs)\u001b[0m\n\u001b[1;32m   1128\u001b[0m         if not (self._backward_hooks or self._forward_hooks or self._forward_pre_hooks or _global_backward_hooks\n\u001b[1;32m   1129\u001b[0m                 or _global_forward_hooks or _global_forward_pre_hooks):\n\u001b[0;32m-> 1130\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mforward_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1131\u001b[0m         \u001b[0;31m# Do not call functions when jit is used\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1132\u001b[0m         \u001b[0mfull_backward_hooks\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnon_full_backward_hooks\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/transformers/modeling_bert.py\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, input_ids, attention_mask, token_type_ids, position_ids, head_mask, inputs_embeds, encoder_hidden_states, encoder_attention_mask, output_attentions, output_hidden_states, return_dict)\u001b[0m\n\u001b[1;32m    823\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    824\u001b[0m         embedding_output = self.embeddings(\n\u001b[0;32m--> 825\u001b[0;31m             \u001b[0minput_ids\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0minput_ids\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mposition_ids\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mposition_ids\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtoken_type_ids\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mtoken_type_ids\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minputs_embeds\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0minputs_embeds\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    826\u001b[0m         )\n\u001b[1;32m    827\u001b[0m         encoder_outputs = self.encoder(\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_call_impl\u001b[0;34m(self, *input, **kwargs)\u001b[0m\n\u001b[1;32m   1128\u001b[0m         if not (self._backward_hooks or self._forward_hooks or self._forward_pre_hooks or _global_backward_hooks\n\u001b[1;32m   1129\u001b[0m                 or _global_forward_hooks or _global_forward_pre_hooks):\n\u001b[0;32m-> 1130\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mforward_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1131\u001b[0m         \u001b[0;31m# Do not call functions when jit is used\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1132\u001b[0m         \u001b[0mfull_backward_hooks\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnon_full_backward_hooks\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/transformers/modeling_roberta.py\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, input_ids, token_type_ids, position_ids, inputs_embeds)\u001b[0m\n\u001b[1;32m     80\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     81\u001b[0m         return super().forward(\n\u001b[0;32m---> 82\u001b[0;31m             \u001b[0minput_ids\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtoken_type_ids\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mtoken_type_ids\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mposition_ids\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mposition_ids\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minputs_embeds\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0minputs_embeds\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     83\u001b[0m         )\n\u001b[1;32m     84\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/transformers/modeling_bert.py\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, input_ids, token_type_ids, position_ids, inputs_embeds)\u001b[0m\n\u001b[1;32m    207\u001b[0m             \u001b[0minputs_embeds\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mword_embeddings\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minput_ids\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    208\u001b[0m         \u001b[0mposition_embeddings\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mposition_embeddings\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mposition_ids\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 209\u001b[0;31m         \u001b[0mtoken_type_embeddings\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtoken_type_embeddings\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtoken_type_ids\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    210\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    211\u001b[0m         \u001b[0membeddings\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0minputs_embeds\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0mposition_embeddings\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0mtoken_type_embeddings\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_call_impl\u001b[0;34m(self, *input, **kwargs)\u001b[0m\n\u001b[1;32m   1128\u001b[0m         if not (self._backward_hooks or self._forward_hooks or self._forward_pre_hooks or _global_backward_hooks\n\u001b[1;32m   1129\u001b[0m                 or _global_forward_hooks or _global_forward_pre_hooks):\n\u001b[0;32m-> 1130\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mforward_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1131\u001b[0m         \u001b[0;31m# Do not call functions when jit is used\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1132\u001b[0m         \u001b[0mfull_backward_hooks\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnon_full_backward_hooks\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/torch/nn/modules/sparse.py\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, input)\u001b[0m\n\u001b[1;32m    158\u001b[0m         return F.embedding(\n\u001b[1;32m    159\u001b[0m             \u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mweight\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpadding_idx\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmax_norm\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 160\u001b[0;31m             self.norm_type, self.scale_grad_by_freq, self.sparse)\n\u001b[0m\u001b[1;32m    161\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    162\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mextra_repr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m->\u001b[0m \u001b[0mstr\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/torch/nn/functional.py\u001b[0m in \u001b[0;36membedding\u001b[0;34m(input, weight, padding_idx, max_norm, norm_type, scale_grad_by_freq, sparse)\u001b[0m\n\u001b[1;32m   2197\u001b[0m         \u001b[0;31m# remove once script supports set_grad_enabled\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2198\u001b[0m         \u001b[0m_no_grad_embedding_renorm_\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mweight\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmax_norm\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnorm_type\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 2199\u001b[0;31m     \u001b[0;32mreturn\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0membedding\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mweight\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mpadding_idx\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mscale_grad_by_freq\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msparse\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   2200\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2201\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mIndexError\u001b[0m: index out of range in self"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "def expand_split_sentences(pdf_txt):\n",
        "  import nltk\n",
        "  nltk.download('punkt')\n",
        "  new_chunks = nltk.sent_tokenize(pdf_txt)\n",
        "  length = len(new_chunks)\n",
        "  #for i in range(length):\n",
        "    #tmp_token = tokenizer.encode(new_chunks[i])\n",
        "    #print('The input has a total of {:} tokens.'.format(len(tmp_token)))\n",
        "\n",
        "  new_df = [];\n",
        "  for i in range(length):\n",
        "    paragraph = \"\"\n",
        "    for j in range(i, length):\n",
        "      #tmp_str = paragraph + new_chunks[j]\n",
        "      tmp_token = tokenizer.encode(paragraph + new_chunks[j])\n",
        "      length_token = len(tmp_token)\n",
        "      if length_token < 510:\n",
        "        #print(length_token)\n",
        "        paragraph = paragraph + new_chunks[j]\n",
        "      else:\n",
        "        #print(length_token)\n",
        "        break;\n",
        "    #print(len(tokenizer.encode(paragraph)))\n",
        "    new_df.append(paragraph)\n",
        "  return new_df\n",
        "  #for i in new_df:\n",
        "    #print(i)"
      ],
      "metadata": {
        "id": "7ahE9X5AEydV"
      },
      "execution_count": 24,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "max_score = 0;\n",
        "final_answer = \"\"\n",
        "new_df = expand_split_sentences(pdf_txt)\n",
        "for new_context in new_df:\n",
        "  #new_paragrapgh = new_paragrapgh + answer_question(question, answer_text)\n",
        "  ans, score = answer_question(question, new_context)\n",
        "  if score > max_score:\n",
        "    max_score = score\n",
        "    final_answer = ans\n",
        "print(question)\n",
        "print(final_answer)\n",
        "print(max_score)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 450
        },
        "id": "zf-Jx4ttEyfs",
        "outputId": "d0b7aa1c-3b40-48d1-e3dd-4812aba6ce9c"
      },
      "execution_count": 25,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Query has 230 tokens.\n",
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[nltk_data] Downloading package punkt to /root/nltk_data...\n",
            "[nltk_data]   Package punkt is already up-to-date!\n"
          ]
        },
        {
          "output_type": "error",
          "ename": "IndexError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mIndexError\u001b[0m                                Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-25-1f3551961eaf>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mnew_context\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mnew_df\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m   \u001b[0;31m#new_paragrapgh = new_paragrapgh + answer_question(question, answer_text)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 6\u001b[0;31m   \u001b[0mans\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mscore\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0manswer_question\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mquestion\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnew_context\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      7\u001b[0m   \u001b[0;32mif\u001b[0m \u001b[0mscore\u001b[0m \u001b[0;34m>\u001b[0m \u001b[0mmax_score\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      8\u001b[0m     \u001b[0mmax_score\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mscore\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m<ipython-input-15-45d13885f70d>\u001b[0m in \u001b[0;36manswer_question\u001b[0;34m(question, pdf_txt)\u001b[0m\n\u001b[1;32m     15\u001b[0m     \u001b[0;32massert\u001b[0m \u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msegment_ids\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minput_ids\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     16\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 17\u001b[0;31m     \u001b[0mstart_scores\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mend_scores\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtensor\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0minput_ids\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtoken_type_ids\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtensor\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0msegment_ids\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     18\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     19\u001b[0m     \u001b[0mall_tokens\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtokenizer\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mconvert_ids_to_tokens\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minput_ids\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_call_impl\u001b[0;34m(self, *input, **kwargs)\u001b[0m\n\u001b[1;32m   1128\u001b[0m         if not (self._backward_hooks or self._forward_hooks or self._forward_pre_hooks or _global_backward_hooks\n\u001b[1;32m   1129\u001b[0m                 or _global_forward_hooks or _global_forward_pre_hooks):\n\u001b[0;32m-> 1130\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mforward_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1131\u001b[0m         \u001b[0;31m# Do not call functions when jit is used\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1132\u001b[0m         \u001b[0mfull_backward_hooks\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnon_full_backward_hooks\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/transformers/modeling_roberta.py\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, input_ids, attention_mask, token_type_ids, position_ids, head_mask, inputs_embeds, start_positions, end_positions, output_attentions, output_hidden_states, return_dict)\u001b[0m\n\u001b[1;32m    763\u001b[0m             \u001b[0moutput_attentions\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0moutput_attentions\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    764\u001b[0m             \u001b[0moutput_hidden_states\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0moutput_hidden_states\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 765\u001b[0;31m             \u001b[0mreturn_dict\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mreturn_dict\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    766\u001b[0m         )\n\u001b[1;32m    767\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_call_impl\u001b[0;34m(self, *input, **kwargs)\u001b[0m\n\u001b[1;32m   1128\u001b[0m         if not (self._backward_hooks or self._forward_hooks or self._forward_pre_hooks or _global_backward_hooks\n\u001b[1;32m   1129\u001b[0m                 or _global_forward_hooks or _global_forward_pre_hooks):\n\u001b[0;32m-> 1130\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mforward_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1131\u001b[0m         \u001b[0;31m# Do not call functions when jit is used\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1132\u001b[0m         \u001b[0mfull_backward_hooks\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnon_full_backward_hooks\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/transformers/modeling_bert.py\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, input_ids, attention_mask, token_type_ids, position_ids, head_mask, inputs_embeds, encoder_hidden_states, encoder_attention_mask, output_attentions, output_hidden_states, return_dict)\u001b[0m\n\u001b[1;32m    823\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    824\u001b[0m         embedding_output = self.embeddings(\n\u001b[0;32m--> 825\u001b[0;31m             \u001b[0minput_ids\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0minput_ids\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mposition_ids\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mposition_ids\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtoken_type_ids\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mtoken_type_ids\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minputs_embeds\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0minputs_embeds\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    826\u001b[0m         )\n\u001b[1;32m    827\u001b[0m         encoder_outputs = self.encoder(\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_call_impl\u001b[0;34m(self, *input, **kwargs)\u001b[0m\n\u001b[1;32m   1128\u001b[0m         if not (self._backward_hooks or self._forward_hooks or self._forward_pre_hooks or _global_backward_hooks\n\u001b[1;32m   1129\u001b[0m                 or _global_forward_hooks or _global_forward_pre_hooks):\n\u001b[0;32m-> 1130\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mforward_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1131\u001b[0m         \u001b[0;31m# Do not call functions when jit is used\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1132\u001b[0m         \u001b[0mfull_backward_hooks\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnon_full_backward_hooks\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/transformers/modeling_roberta.py\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, input_ids, token_type_ids, position_ids, inputs_embeds)\u001b[0m\n\u001b[1;32m     80\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     81\u001b[0m         return super().forward(\n\u001b[0;32m---> 82\u001b[0;31m             \u001b[0minput_ids\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtoken_type_ids\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mtoken_type_ids\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mposition_ids\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mposition_ids\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minputs_embeds\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0minputs_embeds\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     83\u001b[0m         )\n\u001b[1;32m     84\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/transformers/modeling_bert.py\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, input_ids, token_type_ids, position_ids, inputs_embeds)\u001b[0m\n\u001b[1;32m    207\u001b[0m             \u001b[0minputs_embeds\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mword_embeddings\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minput_ids\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    208\u001b[0m         \u001b[0mposition_embeddings\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mposition_embeddings\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mposition_ids\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 209\u001b[0;31m         \u001b[0mtoken_type_embeddings\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtoken_type_embeddings\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtoken_type_ids\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    210\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    211\u001b[0m         \u001b[0membeddings\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0minputs_embeds\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0mposition_embeddings\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0mtoken_type_embeddings\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_call_impl\u001b[0;34m(self, *input, **kwargs)\u001b[0m\n\u001b[1;32m   1128\u001b[0m         if not (self._backward_hooks or self._forward_hooks or self._forward_pre_hooks or _global_backward_hooks\n\u001b[1;32m   1129\u001b[0m                 or _global_forward_hooks or _global_forward_pre_hooks):\n\u001b[0;32m-> 1130\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mforward_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1131\u001b[0m         \u001b[0;31m# Do not call functions when jit is used\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1132\u001b[0m         \u001b[0mfull_backward_hooks\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnon_full_backward_hooks\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/torch/nn/modules/sparse.py\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, input)\u001b[0m\n\u001b[1;32m    158\u001b[0m         return F.embedding(\n\u001b[1;32m    159\u001b[0m             \u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mweight\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpadding_idx\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmax_norm\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 160\u001b[0;31m             self.norm_type, self.scale_grad_by_freq, self.sparse)\n\u001b[0m\u001b[1;32m    161\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    162\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mextra_repr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m->\u001b[0m \u001b[0mstr\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/torch/nn/functional.py\u001b[0m in \u001b[0;36membedding\u001b[0;34m(input, weight, padding_idx, max_norm, norm_type, scale_grad_by_freq, sparse)\u001b[0m\n\u001b[1;32m   2197\u001b[0m         \u001b[0;31m# remove once script supports set_grad_enabled\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2198\u001b[0m         \u001b[0m_no_grad_embedding_renorm_\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mweight\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmax_norm\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnorm_type\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 2199\u001b[0;31m     \u001b[0;32mreturn\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0membedding\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mweight\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mpadding_idx\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mscale_grad_by_freq\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msparse\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   2200\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2201\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mIndexError\u001b[0m: index out of range in self"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [],
      "metadata": {
        "id": "e6DuanlvmxWK"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Nous pouvons voir que nous obtenons un ensemble de trois valeurs d'activation pour chaque morceau.\n",
        "Ces valeurs d'activation ne sont pas encore nos probabilités de sortie. Pour les transformer en\n",
        "probabilités de sortie, nous devons appliquer une fonction softmax au tenseur de sortie.\n",
        "\n",
        "Enfin, nous prenons la moyenne des valeurs de chaque classe (ou colonne) pour obtenir notre probabilité finale de sentiment positif, négatif ou neutre."
      ],
      "metadata": {
        "id": "0V7UpVJ2muxM"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "input_ids = torch.stack(input_id_chunks)\n",
        "attention_mask = torch.stack(mask_chunks)\n",
        "\n",
        "input_dict = {\n",
        "    'input_ids': input_ids.long(),\n",
        "    'attention_mask': attention_mask.int()\n",
        "}\n",
        "input_dict"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "rowgM6TVEyic",
        "outputId": "f73c7be8-ba63-4290-8586-fb3e4330d11f"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "{'input_ids': tensor([[  101,  2166,  5427,  ...,  1012,  2107,   102],\n",
              "         [  101, 29361,  2024,  ...,  2064,  2022,   102],\n",
              "         [  101,  3876,  2006,  ...,     0,     0,     0]]),\n",
              " 'attention_mask': tensor([[1, 1, 1,  ..., 1, 1, 1],\n",
              "         [1, 1, 1,  ..., 1, 1, 1],\n",
              "         [1, 1, 1,  ..., 0, 0, 0]], dtype=torch.int32)}"
            ]
          },
          "metadata": {},
          "execution_count": 40
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "outputs = model(**input_dict)\n",
        "probs = torch.nn.functional.softmax(outputs[0], dim=-1)\n",
        "probs = probs.mean(dim=0)\n",
        "probs"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "qtlYsktoE8o2",
        "outputId": "934406b3-62c7-4cc8-a00f-5d657bda6bbf"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "tensor([4.2047e-01, 7.3233e-03, 3.8704e-04, 3.7146e-04, 2.4710e-04, 4.9905e-04,\n",
              "        9.1580e-05, 7.2339e-04, 2.8726e-04, 2.7150e-04, 2.2355e-04, 5.9827e-05,\n",
              "        1.0277e-03, 5.1559e-05, 4.3810e-05, 1.1908e-04, 2.0978e-04, 1.3863e-04,\n",
              "        4.2432e-05, 5.6722e-05, 7.6533e-05, 6.9248e-04, 9.3073e-05, 3.7591e-04,\n",
              "        4.3682e-05, 4.0332e-04, 6.2978e-05, 8.4359e-05, 1.1684e-04, 4.9767e-05,\n",
              "        2.4577e-04, 2.9513e-05, 1.8508e-04, 9.6008e-04, 1.3457e-04, 5.4936e-05,\n",
              "        5.5473e-05, 1.6459e-04, 6.7666e-05, 1.0982e-04, 6.5894e-05, 5.0604e-05,\n",
              "        8.9084e-05, 1.5366e-04, 4.3831e-05, 1.7032e-04, 6.9928e-04, 5.5394e-05,\n",
              "        2.6971e-04, 4.2740e-05, 2.9958e-05, 8.3827e-05, 7.3587e-05, 1.0709e-04,\n",
              "        5.4899e-04, 5.5681e-05, 3.9024e-05, 3.3720e-04, 4.9262e-05, 9.6260e-05,\n",
              "        5.3931e-05, 1.5222e-04, 7.0258e-04, 2.5524e-03, 1.5948e-04, 1.0690e-03,\n",
              "        6.7079e-05, 8.0789e-04, 2.0365e-03, 6.5701e-05, 1.2064e-04, 2.8996e-04,\n",
              "        2.1347e-04, 5.6888e-05, 2.1249e-03, 3.9499e-05, 2.1159e-04, 2.6569e-04,\n",
              "        6.2412e-05, 5.1129e-05, 8.9495e-05, 7.2415e-05, 3.5381e-03, 5.4556e-05,\n",
              "        7.1508e-04, 1.4188e-04, 2.4499e-04, 5.9457e-05, 1.1119e-03, 2.0382e-04,\n",
              "        1.4295e-04, 4.3345e-04, 1.3646e-04, 4.1674e-05, 2.0847e-04, 1.7065e-04,\n",
              "        3.8519e-04, 3.8708e-04, 4.1200e-05, 3.0841e-04, 1.2647e-04, 1.3637e-04,\n",
              "        4.6881e-05, 3.1991e-05, 3.2145e-05, 4.4246e-05, 8.7806e-05, 5.6480e-05,\n",
              "        5.8580e-05, 5.6653e-05, 4.8347e-05, 2.4965e-05, 4.6378e-05, 2.6379e-05,\n",
              "        4.8670e-05, 1.6737e-04, 6.4618e-05, 5.6495e-05, 8.1759e-05, 4.4466e-05,\n",
              "        1.0158e-04, 3.5585e-05, 6.0410e-05, 6.3875e-05, 1.7039e-04, 5.0404e-05,\n",
              "        5.7500e-05, 5.5004e-05, 4.6491e-05, 5.0295e-05, 4.5397e-05, 5.2832e-05,\n",
              "        5.3389e-05, 6.3324e-05, 1.3064e-04, 2.5749e-04, 5.2643e-05, 4.6944e-05,\n",
              "        3.7305e-05, 4.8249e-05, 8.0733e-05, 8.4464e-05, 1.0670e-04, 7.3485e-05,\n",
              "        7.4626e-05, 5.2369e-05, 6.9581e-05, 2.5934e-05, 3.6436e-05, 1.8811e-04,\n",
              "        8.0685e-05, 3.2122e-05, 5.3236e-05, 4.0746e-04, 9.3873e-05, 3.9662e-05,\n",
              "        8.7556e-05, 1.4731e-04, 1.3155e-04, 2.4929e-05, 7.9417e-05, 3.0528e-05,\n",
              "        1.0242e-04, 3.5068e-05, 3.4698e-05, 4.1113e-05, 4.6601e-05, 1.1962e-04,\n",
              "        3.4961e-05, 3.7392e-05, 7.1280e-05, 2.1064e-05, 4.6823e-05, 2.8664e-05,\n",
              "        4.4135e-05, 2.2795e-04, 6.4747e-05, 2.8058e-05, 5.6868e-05, 9.5724e-05,\n",
              "        1.1329e-04, 3.4201e-05, 5.0846e-05, 3.1480e-05, 6.0794e-05, 5.2622e-05,\n",
              "        2.9664e-04, 2.6548e-05, 3.1076e-05, 2.2069e-04, 1.8944e-04, 4.1666e-05,\n",
              "        9.3682e-05, 1.0285e-04, 6.4692e-05, 3.3199e-05, 3.2460e-04, 8.5656e-05,\n",
              "        7.1954e-05, 4.7625e-05, 1.1412e-04, 1.2776e-04, 1.0165e-04, 2.7259e-04,\n",
              "        3.9819e-05, 3.7262e-05, 2.3008e-04, 8.0705e-05, 7.4008e-05, 1.0812e-04,\n",
              "        8.5720e-05, 8.4158e-05, 3.3531e-05, 1.0134e-04, 3.8595e-05, 4.5253e-05,\n",
              "        6.6540e-05, 8.9126e-05, 7.6436e-05, 7.7764e-05, 8.5636e-05, 3.5595e-05,\n",
              "        3.2802e-05, 3.5160e-05, 5.9794e-05, 4.3163e-05, 5.5477e-05, 5.5824e-05,\n",
              "        1.3474e-04, 3.5574e-05, 4.1005e-05, 2.7552e-05, 3.3310e-05, 3.7466e-05,\n",
              "        3.1794e-05, 6.9628e-05, 3.5483e-05, 6.0901e-05, 1.4809e-04, 1.5280e-04,\n",
              "        2.0674e-04, 8.9104e-05, 3.1164e-05, 4.7400e-05, 4.0626e-05, 7.1526e-05,\n",
              "        3.5956e-05, 3.9222e-05, 3.7219e-05, 4.4639e-05, 1.0312e-04, 2.9464e-05,\n",
              "        2.4477e-05, 3.3950e-05, 5.8510e-05, 7.1361e-05, 3.4700e-05, 4.5197e-05,\n",
              "        4.2812e-05, 4.8044e-05, 3.1948e-05, 3.0816e-05, 6.2858e-05, 5.7715e-05,\n",
              "        3.5892e-05, 3.9153e-05, 3.8666e-05, 5.6248e-05, 2.2652e-05, 7.0105e-05,\n",
              "        4.9782e-05, 3.5454e-05, 4.0896e-05, 3.4124e-05, 4.9317e-05, 2.8924e-05,\n",
              "        4.0054e-05, 3.9652e-05, 5.1658e-05, 9.8789e-02, 3.5356e-05, 1.5939e-05,\n",
              "        1.7316e-05, 2.0357e-05, 2.4843e-05, 1.9501e-05, 3.3287e-05, 3.2738e-05,\n",
              "        1.4073e-05, 1.5898e-05, 1.8144e-05, 1.4344e-05, 1.5390e-05, 2.0967e-05,\n",
              "        1.8793e-05, 2.4851e-05, 1.5335e-05, 3.0455e-05, 2.7499e-05, 1.8701e-05,\n",
              "        2.5784e-05, 2.9815e-05, 4.0560e-05, 2.9167e-05, 2.1711e-05, 1.9326e-05,\n",
              "        2.2574e-05, 2.0133e-05, 2.3609e-05, 1.9194e-05, 1.6072e-05, 1.5034e-05,\n",
              "        3.8934e-05, 1.6530e-05, 2.1887e-05, 1.7048e-05, 1.8730e-05, 2.6361e-05,\n",
              "        3.6828e-05, 3.3074e-05, 1.9038e-05, 2.5489e-05, 2.4382e-05, 3.3837e-05,\n",
              "        2.4585e-05, 7.0282e-05, 6.9552e-05, 5.9061e-05, 5.0989e-05, 5.3752e-05,\n",
              "        1.5297e-04, 9.9908e-05, 1.9112e-04, 4.5872e-05, 3.1400e-05, 1.9073e-05,\n",
              "        4.9482e-05, 1.0397e-04, 6.5561e-05, 1.1692e-04, 6.9386e-05, 2.2301e-05,\n",
              "        3.3553e-05, 3.3179e-05, 2.2132e-05, 2.5484e-05, 2.5358e-05, 1.9016e-05,\n",
              "        2.2342e-05, 3.0359e-05, 2.5104e-05, 2.0813e-05, 2.2827e-05, 1.7814e-05,\n",
              "        2.5872e-05, 4.0808e-05, 2.3079e-05, 2.4501e-05, 2.0192e-05, 2.7207e-05,\n",
              "        3.6556e-05, 6.1634e-05, 3.0985e-05, 1.4299e-04, 3.3231e-05, 2.9805e-05,\n",
              "        4.4890e-05, 3.6918e-05, 2.5100e-05, 1.8482e-05, 2.7753e-05, 1.9064e-05,\n",
              "        2.5518e-05, 3.3453e-05, 4.1150e-05, 1.8053e-05, 2.1683e-05, 1.7240e-05,\n",
              "        2.1360e-05, 3.2736e-05, 2.0746e-05, 2.7276e-05, 1.8640e-05, 2.2516e-05,\n",
              "        1.9912e-05, 2.7437e-05, 1.6754e-05, 3.9655e-05, 4.4313e-05, 1.6155e-05,\n",
              "        3.4294e-05, 5.0868e-05, 3.5840e-05, 4.2855e-05, 1.3945e-04, 2.0258e-04,\n",
              "        2.4367e-05, 3.2675e-05, 2.2929e-05, 3.4300e-05, 4.2000e-05, 3.4378e-05,\n",
              "        2.3583e-05, 8.6818e-05, 2.5717e-05, 2.4171e-05, 2.9486e-05, 2.4192e-05,\n",
              "        5.4532e-05, 2.9652e-05, 2.3284e-05, 5.6041e-05, 2.6010e-05, 2.5898e-05,\n",
              "        2.5589e-05, 1.9638e-05, 2.5982e-05, 2.2606e-05, 6.2927e-05, 2.6647e-05,\n",
              "        3.1055e-05, 2.5189e-05, 2.0966e-05, 7.5393e-05, 1.8333e-05, 1.9678e-05,\n",
              "        2.8083e-05, 1.5749e-05, 2.1385e-05, 2.1441e-05, 2.4648e-05, 2.5035e-05,\n",
              "        1.9541e-05, 4.0760e-05, 2.2986e-05, 3.7738e-05, 3.1105e-05, 2.7221e-05,\n",
              "        3.3813e-05, 4.3472e-05, 2.7978e-05, 2.3420e-05, 3.4056e-05, 9.8847e-05,\n",
              "        2.5885e-05, 4.9962e-05, 7.6817e-05, 2.4763e-05, 2.6551e-05, 3.4203e-05,\n",
              "        3.8391e-05, 4.1616e-05, 6.4324e-05, 2.1028e-04, 3.3907e-05, 2.9787e-05,\n",
              "        2.4334e-05, 3.2796e-05, 4.8975e-05, 3.9476e-05, 9.2538e-05, 2.9322e-05,\n",
              "        3.0799e-05, 2.7479e-05, 2.6269e-05, 6.6660e-05, 3.5829e-05, 3.3094e-05,\n",
              "        3.8299e-05, 2.2342e-05, 1.7251e-05, 2.6254e-05, 2.7984e-05, 1.2164e-04,\n",
              "        1.9955e-05, 3.0520e-05, 2.3537e-05, 3.3842e-05, 2.5507e-05, 2.4733e-05,\n",
              "        2.1638e-05, 2.5656e-05, 7.0366e-05, 1.9037e-05, 2.3059e-05, 1.8690e-05,\n",
              "        3.8114e-05, 2.8532e-05, 2.7036e-05, 2.3507e-05, 2.6660e-05, 3.6071e-05,\n",
              "        2.6525e-05, 2.1497e-05, 1.9108e-05, 2.7563e-05, 2.2473e-05, 2.9002e-05,\n",
              "        2.2893e-05, 1.8821e-05, 2.0394e-05, 1.9089e-05, 2.3703e-05, 3.6839e-05,\n",
              "        1.9838e-05, 1.7759e-05, 1.9908e-05, 3.5956e-05, 2.4703e-05, 2.0852e-05,\n",
              "        5.0867e-04, 4.2030e-01], grad_fn=<MeanBackward1>)"
            ]
          },
          "metadata": {},
          "execution_count": 41
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "9XlD3zZUE8re"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "u81IKPIW_cJQ"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}