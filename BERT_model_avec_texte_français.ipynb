{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyM/vnO7KEQkG45GNVw8jONB"
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "widgets": {
      "application/vnd.jupyter.widget-state+json": {
        "90d35cec1e414b5193230ff2894e839d": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_5bef52c5a3cf428cb2c1d6fd59c45387",
              "IPY_MODEL_80285a47ba0343e99d9726b11430e5fe",
              "IPY_MODEL_50afbfeb05c146be9278e6617517eda5"
            ],
            "layout": "IPY_MODEL_c999952aeb694535931b78e5792831d5"
          }
        },
        "5bef52c5a3cf428cb2c1d6fd59c45387": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_edf1c4b5af1649f9987a89a2d5c16d6e",
            "placeholder": "​",
            "style": "IPY_MODEL_8ab2b04143224565ad8b9e1c61c431b5",
            "value": "Downloading: 100%"
          }
        },
        "80285a47ba0343e99d9726b11430e5fe": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_574d8fd3cdc94ba78c09967a620b6d2c",
            "max": 443,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_3187f3d9aaba4727b3856786959434d5",
            "value": 443
          }
        },
        "50afbfeb05c146be9278e6617517eda5": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_9ca49d3387454982bd4870e15db56d44",
            "placeholder": "​",
            "style": "IPY_MODEL_5e546817be894831a15cfbeca4fe2539",
            "value": " 443/443 [00:00&lt;00:00, 6.61kB/s]"
          }
        },
        "c999952aeb694535931b78e5792831d5": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "edf1c4b5af1649f9987a89a2d5c16d6e": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "8ab2b04143224565ad8b9e1c61c431b5": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "574d8fd3cdc94ba78c09967a620b6d2c": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "3187f3d9aaba4727b3856786959434d5": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "9ca49d3387454982bd4870e15db56d44": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "5e546817be894831a15cfbeca4fe2539": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "632ccb01ecd44089ba88918626bb65b6": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_9f04f4385dd24c0d86d04b167269d8ba",
              "IPY_MODEL_aff8736edb264d4cb25d9b219ed241b2",
              "IPY_MODEL_43f1ff2621da449f9fd3b75b505483f8"
            ],
            "layout": "IPY_MODEL_153d6580c2c84a76bcce5bb2cbe2946a"
          }
        },
        "9f04f4385dd24c0d86d04b167269d8ba": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_210805b150644fde897d6edbe4e32fe1",
            "placeholder": "​",
            "style": "IPY_MODEL_5c3baf76137a4e199afb7ecfd9f24930",
            "value": "Downloading: 100%"
          }
        },
        "aff8736edb264d4cb25d9b219ed241b2": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_5c616cc5ebfe4ef089d5ab1ff60ef944",
            "max": 1340675298,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_5e5196c3b4a14453908590257aef56d2",
            "value": 1340675298
          }
        },
        "43f1ff2621da449f9fd3b75b505483f8": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_4c3edb9a9f534791aa55feb7d3d85862",
            "placeholder": "​",
            "style": "IPY_MODEL_76dcec7eb82748898cc608945b3b81ba",
            "value": " 1.34G/1.34G [01:57&lt;00:00, 38.4MB/s]"
          }
        },
        "153d6580c2c84a76bcce5bb2cbe2946a": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "210805b150644fde897d6edbe4e32fe1": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "5c3baf76137a4e199afb7ecfd9f24930": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "5c616cc5ebfe4ef089d5ab1ff60ef944": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "5e5196c3b4a14453908590257aef56d2": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "4c3edb9a9f534791aa55feb7d3d85862": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "76dcec7eb82748898cc608945b3b81ba": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "cfd4cfae3ec74cfc8475d8a3cd13fd74": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_b5b4deb206f74a2fb15a025b02b61d97",
              "IPY_MODEL_1949c5d6eb0e40b4a6c6eb310e67f8eb",
              "IPY_MODEL_ab67d7839ffe405294539eae5dd4f64c"
            ],
            "layout": "IPY_MODEL_d66e7a946bab4824aafb52ff885e372a"
          }
        },
        "b5b4deb206f74a2fb15a025b02b61d97": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_7a592d333c6042eeb8939cb039e6252d",
            "placeholder": "​",
            "style": "IPY_MODEL_ac15273a9c7c48b7ac8b0375243606b2",
            "value": "Downloading: 100%"
          }
        },
        "1949c5d6eb0e40b4a6c6eb310e67f8eb": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_a0cf0f1c118843ed88d63988dbe31ff1",
            "max": 231508,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_f05d39f57425468b9d2e2ea2c43dabb6",
            "value": 231508
          }
        },
        "ab67d7839ffe405294539eae5dd4f64c": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_49a9e8200647480c9d321ab97d11d06c",
            "placeholder": "​",
            "style": "IPY_MODEL_5fd27d2a29ee44559b7aef06e49baa17",
            "value": " 232k/232k [00:00&lt;00:00, 424kB/s]"
          }
        },
        "d66e7a946bab4824aafb52ff885e372a": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "7a592d333c6042eeb8939cb039e6252d": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "ac15273a9c7c48b7ac8b0375243606b2": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "a0cf0f1c118843ed88d63988dbe31ff1": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "f05d39f57425468b9d2e2ea2c43dabb6": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "49a9e8200647480c9d321ab97d11d06c": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "5fd27d2a29ee44559b7aef06e49baa17": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        }
      }
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "# **Modele BERT** \n",
        "**Réponse aux questions avec un BERT affiné**\n",
        "\n",
        "Représentations d'encodeurs bidirectionnels à partir de transformateurs\n",
        "\n",
        "Au lieu de regarder les mots isolément, BERT, un modèle basé sur un transformateur, tente d'utiliser le contexte des mots pour obtenir des incorporations. BERT utilise plusieurs concepts d'apprentissage en profondeur pour proposer un modèle qui examine le contexte de manière bidirectionnelle, en tirant parti des informations de l'ensemble des phrases dans leur ensemble grâce à l'attention personnelle."
      ],
      "metadata": {
        "id": "YgCWfa36gasN"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "quFBHONy-OG4",
        "outputId": "7eb2c2d6-c39c-4b78-f1d2-204545299996"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n",
            "Collecting transformers==3.1.0\n",
            "  Downloading transformers-3.1.0-py3-none-any.whl (884 kB)\n",
            "\u001b[K     |████████████████████████████████| 884 kB 8.6 MB/s \n",
            "\u001b[?25hCollecting tokenizers==0.8.1.rc2\n",
            "  Downloading tokenizers-0.8.1rc2-cp37-cp37m-manylinux1_x86_64.whl (3.0 MB)\n",
            "\u001b[K     |████████████████████████████████| 3.0 MB 52.3 MB/s \n",
            "\u001b[?25hRequirement already satisfied: regex!=2019.12.17 in /usr/local/lib/python3.7/dist-packages (from transformers==3.1.0) (2022.6.2)\n",
            "Collecting sentencepiece!=0.1.92\n",
            "  Downloading sentencepiece-0.1.97-cp37-cp37m-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (1.3 MB)\n",
            "\u001b[K     |████████████████████████████████| 1.3 MB 39.3 MB/s \n",
            "\u001b[?25hCollecting sacremoses\n",
            "  Downloading sacremoses-0.0.53.tar.gz (880 kB)\n",
            "\u001b[K     |████████████████████████████████| 880 kB 19.6 MB/s \n",
            "\u001b[?25hRequirement already satisfied: filelock in /usr/local/lib/python3.7/dist-packages (from transformers==3.1.0) (3.8.0)\n",
            "Requirement already satisfied: requests in /usr/local/lib/python3.7/dist-packages (from transformers==3.1.0) (2.23.0)\n",
            "Requirement already satisfied: numpy in /usr/local/lib/python3.7/dist-packages (from transformers==3.1.0) (1.21.6)\n",
            "Requirement already satisfied: tqdm>=4.27 in /usr/local/lib/python3.7/dist-packages (from transformers==3.1.0) (4.64.1)\n",
            "Requirement already satisfied: packaging in /usr/local/lib/python3.7/dist-packages (from transformers==3.1.0) (21.3)\n",
            "Requirement already satisfied: pyparsing!=3.0.5,>=2.0.2 in /usr/local/lib/python3.7/dist-packages (from packaging->transformers==3.1.0) (3.0.9)\n",
            "Requirement already satisfied: urllib3!=1.25.0,!=1.25.1,<1.26,>=1.21.1 in /usr/local/lib/python3.7/dist-packages (from requests->transformers==3.1.0) (1.24.3)\n",
            "Requirement already satisfied: chardet<4,>=3.0.2 in /usr/local/lib/python3.7/dist-packages (from requests->transformers==3.1.0) (3.0.4)\n",
            "Requirement already satisfied: idna<3,>=2.5 in /usr/local/lib/python3.7/dist-packages (from requests->transformers==3.1.0) (2.10)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.7/dist-packages (from requests->transformers==3.1.0) (2022.9.24)\n",
            "Requirement already satisfied: six in /usr/local/lib/python3.7/dist-packages (from sacremoses->transformers==3.1.0) (1.15.0)\n",
            "Requirement already satisfied: click in /usr/local/lib/python3.7/dist-packages (from sacremoses->transformers==3.1.0) (7.1.2)\n",
            "Requirement already satisfied: joblib in /usr/local/lib/python3.7/dist-packages (from sacremoses->transformers==3.1.0) (1.2.0)\n",
            "Building wheels for collected packages: sacremoses\n",
            "  Building wheel for sacremoses (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for sacremoses: filename=sacremoses-0.0.53-py3-none-any.whl size=895259 sha256=1c19f380e6290ef49457f0847baa8402ba92a4660c124fad593ae9534974191e\n",
            "  Stored in directory: /root/.cache/pip/wheels/87/39/dd/a83eeef36d0bf98e7a4d1933a4ad2d660295a40613079bafc9\n",
            "Successfully built sacremoses\n",
            "Installing collected packages: tokenizers, sentencepiece, sacremoses, transformers\n",
            "Successfully installed sacremoses-0.0.53 sentencepiece-0.1.97 tokenizers-0.8.1rc2 transformers-3.1.0\n"
          ]
        }
      ],
      "source": [
        "!pip install transformers==3.1.0"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Télechagement d'un modèle BERT pré-entrainé. Celui-ci est issue de la base de données SQUAD. \n",
        "uncased= pas de différence entre miniscule et majuscule"
      ],
      "metadata": {
        "id": "z4_6ixUGhMbC"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import torch\n",
        "from transformers import BertForQuestionAnswering\n",
        "model = BertForQuestionAnswering.from_pretrained('bert-large-uncased-whole-word-masking-finetuned-squad')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 81,
          "referenced_widgets": [
            "90d35cec1e414b5193230ff2894e839d",
            "5bef52c5a3cf428cb2c1d6fd59c45387",
            "80285a47ba0343e99d9726b11430e5fe",
            "50afbfeb05c146be9278e6617517eda5",
            "c999952aeb694535931b78e5792831d5",
            "edf1c4b5af1649f9987a89a2d5c16d6e",
            "8ab2b04143224565ad8b9e1c61c431b5",
            "574d8fd3cdc94ba78c09967a620b6d2c",
            "3187f3d9aaba4727b3856786959434d5",
            "9ca49d3387454982bd4870e15db56d44",
            "5e546817be894831a15cfbeca4fe2539",
            "632ccb01ecd44089ba88918626bb65b6",
            "9f04f4385dd24c0d86d04b167269d8ba",
            "aff8736edb264d4cb25d9b219ed241b2",
            "43f1ff2621da449f9fd3b75b505483f8",
            "153d6580c2c84a76bcce5bb2cbe2946a",
            "210805b150644fde897d6edbe4e32fe1",
            "5c3baf76137a4e199afb7ecfd9f24930",
            "5c616cc5ebfe4ef089d5ab1ff60ef944",
            "5e5196c3b4a14453908590257aef56d2",
            "4c3edb9a9f534791aa55feb7d3d85862",
            "76dcec7eb82748898cc608945b3b81ba"
          ]
        },
        "id": "o5MkcjhP-gEr",
        "outputId": "350ee7b4-c569-41dd-9481-4a97f437925d"
      },
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "Downloading:   0%|          | 0.00/443 [00:00<?, ?B/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "90d35cec1e414b5193230ff2894e839d"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "Downloading:   0%|          | 0.00/1.34G [00:00<?, ?B/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "632ccb01ecd44089ba88918626bb65b6"
            }
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from transformers import BertTokenizer\n",
        "tokenizer = BertTokenizer.from_pretrained('bert-large-uncased-whole-word-masking-finetuned-squad')\n",
        "# Téléchargement d'un tokenizer préentrainé"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 49,
          "referenced_widgets": [
            "cfd4cfae3ec74cfc8475d8a3cd13fd74",
            "b5b4deb206f74a2fb15a025b02b61d97",
            "1949c5d6eb0e40b4a6c6eb310e67f8eb",
            "ab67d7839ffe405294539eae5dd4f64c",
            "d66e7a946bab4824aafb52ff885e372a",
            "7a592d333c6042eeb8939cb039e6252d",
            "ac15273a9c7c48b7ac8b0375243606b2",
            "a0cf0f1c118843ed88d63988dbe31ff1",
            "f05d39f57425468b9d2e2ea2c43dabb6",
            "49a9e8200647480c9d321ab97d11d06c",
            "5fd27d2a29ee44559b7aef06e49baa17"
          ]
        },
        "id": "AZx3nbNZ-gG6",
        "outputId": "a4f09e39-9c63-4aa2-9c56-61eaf838bc7a"
      },
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "Downloading:   0%|          | 0.00/232k [00:00<?, ?B/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "cfd4cfae3ec74cfc8475d8a3cd13fd74"
            }
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "pip install nltk"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "XTWMUhJF-7wz",
        "outputId": "44119197-00fe-4a53-9a32-8a19bee8d403"
      },
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n",
            "Requirement already satisfied: nltk in /usr/local/lib/python3.7/dist-packages (3.7)\n",
            "Requirement already satisfied: tqdm in /usr/local/lib/python3.7/dist-packages (from nltk) (4.64.1)\n",
            "Requirement already satisfied: joblib in /usr/local/lib/python3.7/dist-packages (from nltk) (1.2.0)\n",
            "Requirement already satisfied: click in /usr/local/lib/python3.7/dist-packages (from nltk) (7.1.2)\n",
            "Requirement already satisfied: regex>=2021.8.3 in /usr/local/lib/python3.7/dist-packages (from nltk) (2022.6.2)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Création d'une variable pdf_txt qui contient un texte. Nous pouvons aussi extraire le texte directement d'un pdf comme pour le modele word2vec avec les commandes suivantes: \n",
        "\n",
        "'import pdfplumber\n",
        "\n",
        "pdf = pdfplumber.open('lic_policy.pdf')\n",
        "\n",
        "page = pdf.pages[0]\n",
        "\n",
        "page1 = pdf.pages[1]\n",
        "\n",
        "pdf_txt = page.extract_text() + page1.extract_text()\n",
        "\n",
        "pdf.close()'"
      ],
      "metadata": {
        "id": "iMH1v9_oiKN3"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "pdf_txt= \"\"\" Un chatbot est une application qui peut imiter une vraie conversation avec un utilisateur dans sa langue naturelle. \n",
        "Les chatbots permettent la communication via texte ou audio sur des sites Web, des applications de messagerie, des applications mobiles ou par téléphone.\n",
        " Avec SendPulse, vous pouvez facilement créer un robot conversationnel sans connaissances en programmation et gratuitement.\n",
        " Les chatbots utilisent l'apprentissage machine pour identifier les modèles de communication. \n",
        " Au cours des interactions continues avec les humains, ils apprennent à imiter des conversations réelles et à réagir aux demandes verbales ou écrites, à leur tour, en fournissant un service particulier. \n",
        " Comme les chatbots utilisent l'IA, ils comprennent le langage, pas seulement les commandes. \n",
        " Ainsi, au fur et à mesure qu’ils ont plus de conversations avec les utilisateurs ils deviennent plus intelligents. \n",
        " Il est important de noter qu'en dehors des chatbots basés sur l'IA, il existe des chatbots qui utilisent des scripts à choix multiples; en substance, l'option X mène au chemin Y et ainsi de suite.\n",
        "\n",
        " \"\"\"\n",
        "import nltk\n",
        "nltk.download('punkt')\n",
        "tokens = nltk.sent_tokenize(pdf_txt)\n",
        "for t in tokens:\n",
        "    print(t, \"\\n\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Lw-5_1n0OMT6",
        "outputId": "34939133-4dac-494a-a1e2-14bd19901d7e"
      },
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[nltk_data] Downloading package punkt to /root/nltk_data...\n",
            "[nltk_data]   Unzipping tokenizers/punkt.zip.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            " Un chatbot est une application qui peut imiter une vraie conversation avec un utilisateur dans sa langue naturelle. \n",
            "\n",
            "Les chatbots permettent la communication via texte ou audio sur des sites Web, des applications de messagerie, des applications mobiles ou par téléphone. \n",
            "\n",
            "Avec SendPulse, vous pouvez facilement créer un robot conversationnel sans connaissances en programmation et gratuitement. \n",
            "\n",
            "Les chatbots utilisent l'apprentissage machine pour identifier les modèles de communication. \n",
            "\n",
            "Au cours des interactions continues avec les humains, ils apprennent à imiter des conversations réelles et à réagir aux demandes verbales ou écrites, à leur tour, en fournissant un service particulier. \n",
            "\n",
            "Comme les chatbots utilisent l'IA, ils comprennent le langage, pas seulement les commandes. \n",
            "\n",
            "Ainsi, au fur et à mesure qu’ils ont plus de conversations avec les utilisateurs ils deviennent plus intelligents. \n",
            "\n",
            "Il est important de noter qu'en dehors des chatbots basés sur l'IA, il existe des chatbots qui utilisent des scripts à choix multiples; en substance, l'option X mène au chemin Y et ainsi de suite. \n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "question = \"Comment s'effectue la communication avec un chatbot ?\""
      ],
      "metadata": {
        "id": "S_SbEyeB-gLS"
      },
      "execution_count": 6,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Tokenisation du texte"
      ],
      "metadata": {
        "id": "qFWz20ULjcX4"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "input_ids = tokenizer.encode(question, pdf_txt, max_length=512, truncation=True)\n",
        "print('The input has a total of {:} tokens.'.format(len(input_ids)))\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "zKzladEf-gNz",
        "outputId": "19b0c543-52ab-40c5-dcb5-7eba8a31e2e0"
      },
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "The input has a total of 314 tokens.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Impression des jetons avec et de leurs identifiants pour voir exactement ce que fait le tokenizer"
      ],
      "metadata": {
        "id": "gg0YmxpDsD0w"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "tokens = tokenizer.convert_ids_to_tokens(input_ids)\n",
        "for token, id in zip(tokens, input_ids):\n",
        "    if id == tokenizer.sep_token_id:\n",
        "        print('')\n",
        "    print('{:<12} {:>6,}'.format(token, id))\n",
        "\n",
        "    if id == tokenizer.sep_token_id:\n",
        "        print('')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "7Vzj7DY5-gPq",
        "outputId": "1bfaeb7d-8d68-4031-e13c-366896b26d63"
      },
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[CLS]           101\n",
            "comment       7,615\n",
            "s             1,055\n",
            "'             1,005\n",
            "effect        3,466\n",
            "##ue          5,657\n",
            "la            2,474\n",
            "communication  4,807\n",
            "ave          13,642\n",
            "##c           2,278\n",
            "un            4,895\n",
            "chat         11,834\n",
            "##bot        18,384\n",
            "?             1,029\n",
            "\n",
            "[SEP]           102\n",
            "\n",
            "un            4,895\n",
            "chat         11,834\n",
            "##bot        18,384\n",
            "est           9,765\n",
            "une          16,655\n",
            "application   4,646\n",
            "qui          21,864\n",
            "pe           21,877\n",
            "##ut          4,904\n",
            "im           10,047\n",
            "##iter       21,646\n",
            "une          16,655\n",
            "vr           27,830\n",
            "##ai          4,886\n",
            "##e           2,063\n",
            "conversation  4,512\n",
            "ave          13,642\n",
            "##c           2,278\n",
            "un            4,895\n",
            "ut           21,183\n",
            "##ilis       24,411\n",
            "##ate         3,686\n",
            "##ur          3,126\n",
            "dans         18,033\n",
            "sa            7,842\n",
            "lang         11,374\n",
            "##ue          5,657\n",
            "nature        3,267\n",
            "##lle         6,216\n",
            ".             1,012\n",
            "les           4,649\n",
            "chat         11,834\n",
            "##bots       27,014\n",
            "per           2,566\n",
            "##met        11,368\n",
            "##ten         6,528\n",
            "##t           2,102\n",
            "la            2,474\n",
            "communication  4,807\n",
            "via           3,081\n",
            "text          3,793\n",
            "##e           2,063\n",
            "ou           15,068\n",
            "audio         5,746\n",
            "sur           7,505\n",
            "des           4,078\n",
            "sites         4,573\n",
            "web           4,773\n",
            ",             1,010\n",
            "des           4,078\n",
            "applications  5,097\n",
            "de            2,139\n",
            "message       4,471\n",
            "##rie         7,373\n",
            ",             1,010\n",
            "des           4,078\n",
            "applications  5,097\n",
            "mobile        4,684\n",
            "##s           2,015\n",
            "ou           15,068\n",
            "par          11,968\n",
            "telephone     7,026\n",
            ".             1,012\n",
            "ave          13,642\n",
            "##c           2,278\n",
            "send          4,604\n",
            "##pu         14,289\n",
            "##ls          4,877\n",
            "##e           2,063\n",
            ",             1,010\n",
            "vo           29,536\n",
            "##us          2,271\n",
            "po           13,433\n",
            "##uve        22,909\n",
            "##z           2,480\n",
            "fa            6,904\n",
            "##ci          6,895\n",
            "##lem        16,930\n",
            "##ent         4,765\n",
            "cree         27,831\n",
            "##r           2,099\n",
            "un            4,895\n",
            "robot         8,957\n",
            "conversation  4,512\n",
            "##nel        11,877\n",
            "sans         20,344\n",
            "con           9,530\n",
            "##nais       28,020\n",
            "##san         8,791\n",
            "##ces         9,623\n",
            "en            4,372\n",
            "program       2,565\n",
            "##mation     28,649\n",
            "et            3,802\n",
            "gr           24,665\n",
            "##at          4,017\n",
            "##uit        14,663\n",
            "##ement      13,665\n",
            ".             1,012\n",
            "les           4,649\n",
            "chat         11,834\n",
            "##bots       27,014\n",
            "ut           21,183\n",
            "##ilis       24,411\n",
            "##ent         4,765\n",
            "l             1,048\n",
            "'             1,005\n",
            "app          10,439\n",
            "##rent       22,787\n",
            "##issa       21,205\n",
            "##ge          3,351\n",
            "machine       3,698\n",
            "pour         10,364\n",
            "id            8,909\n",
            "##ent         4,765\n",
            "##ifier      18,095\n",
            "les           4,649\n",
            "model         2,944\n",
            "##es          2,229\n",
            "de            2,139\n",
            "communication  4,807\n",
            ".             1,012\n",
            "au            8,740\n",
            "co            2,522\n",
            "##urs         9,236\n",
            "des           4,078\n",
            "interactions 10,266\n",
            "continues     4,247\n",
            "ave          13,642\n",
            "##c           2,278\n",
            "les           4,649\n",
            "hum          14,910\n",
            "##ains       28,247\n",
            ",             1,010\n",
            "il            6,335\n",
            "##s           2,015\n",
            "app          10,439\n",
            "##ren         7,389\n",
            "##nent       21,576\n",
            "a             1,037\n",
            "im           10,047\n",
            "##iter       21,646\n",
            "des           4,078\n",
            "conversations 11,450\n",
            "reel         15,934\n",
            "##les         4,244\n",
            "et            3,802\n",
            "a             1,037\n",
            "re            2,128\n",
            "##agi        22,974\n",
            "##r           2,099\n",
            "aux          19,554\n",
            "demand        5,157\n",
            "##es          2,229\n",
            "verbal       12,064\n",
            "##es          2,229\n",
            "ou           15,068\n",
            "ec           14,925\n",
            "##rites      28,884\n",
            ",             1,010\n",
            "a             1,037\n",
            "le            3,393\n",
            "##ur          3,126\n",
            "tour          2,778\n",
            ",             1,010\n",
            "en            4,372\n",
            "four          2,176\n",
            "##nis         8,977\n",
            "##sant       22,341\n",
            "un            4,895\n",
            "service       2,326\n",
            "part          2,112\n",
            "##ic          2,594\n",
            "##uli        15,859\n",
            "##er          2,121\n",
            ".             1,012\n",
            "com           4,012\n",
            "##me          4,168\n",
            "les           4,649\n",
            "chat         11,834\n",
            "##bots       27,014\n",
            "ut           21,183\n",
            "##ilis       24,411\n",
            "##ent         4,765\n",
            "l             1,048\n",
            "'             1,005\n",
            "ia           24,264\n",
            ",             1,010\n",
            "il            6,335\n",
            "##s           2,015\n",
            "com           4,012\n",
            "##pre        28,139\n",
            "##nne        10,087\n",
            "##nt          3,372\n",
            "le            3,393\n",
            "lang         11,374\n",
            "##age         4,270\n",
            ",             1,010\n",
            "pas          14,674\n",
            "se            7,367\n",
            "##ule         9,307\n",
            "##ment        3,672\n",
            "les           4,649\n",
            "command       3,094\n",
            "##es          2,229\n",
            ".             1,012\n",
            "ain           7,110\n",
            "##si          5,332\n",
            ",             1,010\n",
            "au            8,740\n",
            "fur           6,519\n",
            "et            3,802\n",
            "a             1,037\n",
            "me            2,033\n",
            "##sure       28,632\n",
            "qu           24,209\n",
            "’             1,521\n",
            "il            6,335\n",
            "##s           2,015\n",
            "on            2,006\n",
            "##t           2,102\n",
            "plus          4,606\n",
            "de            2,139\n",
            "conversations 11,450\n",
            "ave          13,642\n",
            "##c           2,278\n",
            "les           4,649\n",
            "ut           21,183\n",
            "##ilis       24,411\n",
            "##ate         3,686\n",
            "##urs         9,236\n",
            "il            6,335\n",
            "##s           2,015\n",
            "devi         14,386\n",
            "##enne       24,336\n",
            "##nt          3,372\n",
            "plus          4,606\n",
            "intelligent   9,414\n",
            "##s           2,015\n",
            ".             1,012\n",
            "il            6,335\n",
            "est           9,765\n",
            "important     2,590\n",
            "de            2,139\n",
            "note          3,602\n",
            "##r           2,099\n",
            "qu           24,209\n",
            "'             1,005\n",
            "en            4,372\n",
            "de            2,139\n",
            "##hor        16,368\n",
            "##s           2,015\n",
            "des           4,078\n",
            "chat         11,834\n",
            "##bots       27,014\n",
            "bases         7,888\n",
            "sur           7,505\n",
            "l             1,048\n",
            "'             1,005\n",
            "ia           24,264\n",
            ",             1,010\n",
            "il            6,335\n",
            "exist         4,839\n",
            "##e           2,063\n",
            "des           4,078\n",
            "chat         11,834\n",
            "##bots       27,014\n",
            "qui          21,864\n",
            "ut           21,183\n",
            "##ilis       24,411\n",
            "##ent         4,765\n",
            "des           4,078\n",
            "scripts      14,546\n",
            "a             1,037\n",
            "choi         18,151\n",
            "##x           2,595\n",
            "multiple      3,674\n",
            "##s           2,015\n",
            ";             1,025\n",
            "en            4,372\n",
            "substance     9,415\n",
            ",             1,010\n",
            "l             1,048\n",
            "'             1,005\n",
            "option        5,724\n",
            "x             1,060\n",
            "men           2,273\n",
            "##e           2,063\n",
            "au            8,740\n",
            "che          18,178\n",
            "##min        10,020\n",
            "y             1,061\n",
            "et            3,802\n",
            "ain           7,110\n",
            "##si          5,332\n",
            "de            2,139\n",
            "suite         7,621\n",
            ".             1,012\n",
            "\n",
            "[SEP]           102\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "La question et pdf_txt ( le texte) peuvent être concatener ensemble, mais BERT a toujours besoin d'un moyen de les distinguer. BERT a deux encastrements spéciaux \"Segment\", un pour le segment \"A\" et un pour le segment \"B\". Avant que les intégrations de mots n'entrent dans les couches BERT, l'intégration du segment A doit être ajoutée aux jetons de question, et l'intégration du segment B doit être ajoutée à chacun des jetons answer_text.\n",
        "Celles-ci sont gérées par la bibliothèque de transformateurs et tout ce que nous avons à faire est de spécifier '0' et '1' pour le jeton."
      ],
      "metadata": {
        "id": "PKM1QqEqkMnb"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "sep_index = input_ids.index(tokenizer.sep_token_id)\n",
        "num_seg_a = sep_index + 1\n",
        "num_seg_b = len(input_ids) - num_seg_a\n",
        "#Here We Construct the list of 0s and 1s.\n",
        "segment_ids = [0]*num_seg_a + [1]*num_seg_b\n",
        "# There should be a segment_id for every input token.\n",
        "assert len(segment_ids) == len(input_ids)"
      ],
      "metadata": {
        "id": "rXRziKnT_R63"
      },
      "execution_count": 10,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Ici, nous alimentons pdf_txt et la question dans le modèle"
      ],
      "metadata": {
        "id": "jwNaIzvHkh48"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "start_scores, end_scores = model(torch.tensor([input_ids]), token_type_ids=torch.tensor([segment_ids]))"
      ],
      "metadata": {
        "id": "c8G6BYtQ_R9O"
      },
      "execution_count": 11,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Ici, nous trouvons les scores 'début' et 'fin' les plus élevés et combinons les jetons dans la réponse et imprimons la réponse"
      ],
      "metadata": {
        "id": "ZL7v2T5ekuNJ"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "answer_start = torch.argmax(start_scores)\n",
        "answer_end = torch.argmax(end_scores)\n",
        "\n",
        "answer = ' '.join(tokens[answer_start:answer_end+1])\n",
        "print ('Question \"' + question + '\"' )\n",
        "print('Answer: \"' + answer + '\"')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "orl2LjX-_R_v",
        "outputId": "5f462122-c480-46c9-af13-5fa5b6c10c29"
      },
      "execution_count": 12,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Question \"Comment s'effectue la communication avec un chatbot ?\"\n",
            "Answer: \"les chat ##bots\"\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Nous pouvons reconstruire tous les mots qui ont été décomposés en sous-mots."
      ],
      "metadata": {
        "id": "HMlmuXm-k39L"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "answer = tokens[answer_start]\n",
        "answer = tokens[answer_start]\n",
        "\n",
        "# Select the remaining answer tokens and join them with whitespace.\n",
        "for i in range(answer_start + 1, answer_end + 1):\n",
        "  # If it's a subword token, then recombine it with the previous token.\n",
        "    if tokens[i][0:2] == '##':\n",
        "        answer += tokens[i][2:]\n",
        "        # Otherwise, add a space then the token.\n",
        "    else:\n",
        "        answer += ' ' + tokens[i]\n",
        "print('Answer: \"' + answer + '\"')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Dakizn0cBWiP",
        "outputId": "8d653e2b-686b-4e8d-eeac-3a271e705321"
      },
      "execution_count": 13,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Answer: \"les chatbots\"\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Cette partie est une fonction regroupant les commandes précédentes"
      ],
      "metadata": {
        "id": "flrSsB41lDDY"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def answer_question(question, pdf_txt):\n",
        "\n",
        "    input_ids = tokenizer.encode(question, pdf_txt, max_length=512, truncation=True)\n",
        "\n",
        "    print('Query has {:,} tokens.\\n'.format(len(input_ids)))\n",
        "\n",
        "    sep_index = input_ids.index(tokenizer.sep_token_id)\n",
        "\n",
        "    num_seg_a = sep_index + 1\n",
        "\n",
        "    num_seg_b = len(input_ids) - num_seg_a\n",
        "\n",
        "    segment_ids = [0]*num_seg_a + [1]*num_seg_b\n",
        "\n",
        "    assert len(segment_ids) == len(input_ids)\n",
        "\n",
        "    start_scores, end_scores = model(torch.tensor([input_ids]), token_type_ids=torch.tensor([segment_ids]))\n",
        "\n",
        "    all_tokens = tokenizer.convert_ids_to_tokens(input_ids)\n",
        "\n",
        "    #print(' '.join(all_tokens[torch.argmax(start_scores) : torch.argmax(end_scores)+1]))\n",
        "    #print(f'score: {torch.max(start_scores)}')\n",
        "    score = float(torch.max(start_scores))\n",
        "    answer_start = torch.argmax(start_scores)\n",
        "    answer_end = torch.argmax(end_scores)\n",
        "    tokens = tokenizer.convert_ids_to_tokens(input_ids)\n",
        "    answer = tokens[answer_start]\n",
        "\n",
        "    for i in range(answer_start + 1, answer_end + 1):\n",
        "\n",
        "        if tokens[i][0:2] == ' ':\n",
        "            answer += tokens[i][2:]\n",
        "\n",
        "        else:\n",
        "            answer += ' ' + tokens[i]\n",
        "    return answer, score\n",
        "    print('Answer: \"' + answer + '\"')"
      ],
      "metadata": {
        "id": "qyQJ5SrL_SEJ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "answer_question(question, pdf_txt)\n",
        "# On applique la fonction sur la question et le texte pour obtenir une réponse"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "quWSkKNX_byx",
        "outputId": "827f42c0-ef7e-4742-a6ad-894b5d3a42af"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Query has 459 tokens.\n",
            "\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "('chat ##bots are convenient for providing customer service and support 24 hours a day , 7 days a week . they also free up phone lines and are far less expensive over the long run than hiring people to perform support',\n",
              " 4.012147903442383)"
            ]
          },
          "metadata": {},
          "execution_count": 52
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "* Ici, nous utilisons la méthode tokenizers encode_plus pour créer nos jetons à partir de la chaîne de texte\n",
        "* add_special_tokens=True ajoute des jetons BERT spéciaux comme [CLS], [SEP] et [PAD] à nos nouveaux encodages \"tokénisés\"\n",
        "* max_length=512 indique à l'encodeur la longueur cible de nos encodages\n",
        "* truncation=True garantit que nous coupons toutes les séquences qui sont plus longues que le\n",
        "max_length spécifié.\n",
        "* padding=\"max_length\" indique à l'encodeur de remplir toutes les séquences plus courtes que le max_length avec des jetons de remplissage."
      ],
      "metadata": {
        "id": "bJGcCShXlfw0"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "tokens = tokenizer.encode_plus(question, pdf_txt, add_special_tokens=True, max_length=512, truncation=True, padding=\"max_length\")\n",
        "tokens"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "HzYIVilC_b1h",
        "outputId": "fe67b643-6622-4674-a0ee-70a256bb54b6"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "{'input_ids': [101, 2054, 2024, 12637, 1997, 11834, 18384, 1029, 102, 1037, 11834, 18384, 2003, 1037, 3274, 2565, 2008, 26633, 2015, 2529, 4512, 2083, 2376, 10954, 2030, 3793, 11834, 2015, 2030, 2119, 1012, 11834, 18384, 1010, 2460, 2005, 24691, 18384, 1010, 2003, 2019, 7976, 4454, 1006, 9932, 1007, 3444, 2008, 2064, 2022, 11157, 1998, 2109, 2083, 2151, 2350, 24732, 4646, 1012, 2045, 2024, 1037, 2193, 1997, 10675, 2015, 2005, 11834, 18384, 1010, 2164, 1000, 2831, 18384, 1010, 1000, 1000, 28516, 1010, 1000, 1000, 10047, 28516, 1010, 1000, 1000, 9123, 4005, 1000, 2030, 1000, 7976, 4512, 9178, 1012, 1000, 1996, 6555, 5083, 1997, 2974, 2038, 2464, 2019, 3623, 1999, 5661, 3048, 2013, 3151, 2000, 3617, 7248, 2000, 9099, 18908, 2007, 10390, 1012, 15106, 2083, 2974, 2003, 2108, 3344, 2041, 2011, 5661, 2011, 14972, 9932, 5461, 2006, 2037, 3617, 7248, 1012, 2028, 9932, 6028, 2008, 2003, 3652, 1999, 2049, 4646, 1998, 2224, 2003, 11834, 27014, 1012, 2070, 4973, 1997, 11834, 18384, 2974, 2024, 7484, 16838, 2066, 9733, 1005, 1055, 24969, 1998, 8224, 3353, 1010, 1998, 24732, 18726, 1010, 2107, 2004, 2057, 7507, 2102, 1998, 9130, 1005, 1055, 11981, 1012, 1037, 11834, 18384, 2003, 2019, 12978, 2565, 2008, 11835, 2015, 2007, 6304, 2004, 1037, 2529, 2052, 1998, 5366, 2210, 2000, 2498, 2000, 8526, 2007, 1012, 11834, 27014, 5463, 2000, 6304, 2012, 2035, 2335, 1997, 1996, 2154, 1998, 2733, 1998, 2024, 2025, 3132, 2011, 2051, 2030, 1037, 3558, 3295, 1012, 2023, 3084, 2049, 7375, 16004, 2000, 1037, 2843, 1997, 5661, 2008, 2089, 2025, 2031, 1996, 22039, 2030, 3361, 4219, 2000, 2562, 5126, 2551, 2105, 1996, 5119, 1012, 11834, 27014, 2024, 14057, 2005, 4346, 8013, 2326, 1998, 2490, 2484, 2847, 1037, 2154, 1010, 1021, 2420, 1037, 2733, 1012, 2027, 2036, 2489, 2039, 3042, 3210, 1998, 2024, 2521, 2625, 6450, 2058, 1996, 2146, 2448, 2084, 14763, 2111, 2000, 4685, 2490, 1012, 2478, 9932, 1998, 3019, 2653, 6364, 1010, 11834, 27014, 2024, 3352, 2488, 2012, 4824, 2054, 6304, 2215, 1998, 4346, 1996, 2393, 2027, 2342, 1012, 3316, 2036, 2066, 11834, 27014, 2138, 2027, 2064, 8145, 2951, 2055, 8013, 10861, 5134, 1010, 3433, 2335, 1010, 9967, 1010, 1998, 2061, 2006, 1012, 11834, 27014, 1010, 2174, 1010, 2024, 2145, 3132, 1012, 2130, 2007, 3019, 2653, 6364, 1010, 2027, 2089, 2025, 3929, 22346, 1037, 8013, 1005, 1055, 7953, 1998, 2089, 3073, 4297, 11631, 7869, 3372, 6998, 1012, 2116, 11834, 27014, 2024, 2036, 3132, 1999, 1996, 9531, 1997, 10861, 5134, 2008, 2027, 2024, 2583, 2000, 6869, 2000, 1012, 2023, 2089, 2599, 2000, 9135, 2007, 1037, 3768, 1997, 7603, 1010, 11883, 1010, 1998, 3167, 3989, 2445, 7199, 12391, 12247, 1012, 1999, 2804, 2000, 8013, 28237, 2007, 2025, 4285, 1037, 2529, 2108, 1010, 11834, 27014, 2064, 2022, 6450, 2000, 10408, 1998, 5441, 1010, 2926, 2065, 2027, 2442, 2022, 28749, 1998, 7172, 2411, 1012, 102, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], 'token_type_ids': [0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], 'attention_mask': [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]}"
            ]
          },
          "metadata": {},
          "execution_count": 53
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Il renvoie un dictionnaire contenant trois paires clé-valeur, input_ids,\n",
        "token_type_ids et attention_mask .\n",
        "Nous avons également ajouté return_tensors='pt' pour renvoyer les tenseurs PyTorch du\n",
        "tokenizer (plutôt que des listes Python)."
      ],
      "metadata": {
        "id": "oX3FZNVrlx5j"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "tokens = tokenizer.encode_plus(pdf_txt, add_special_tokens=False, return_tensors='pt')\n",
        "tokens"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "X3ae8IAkFVBF",
        "outputId": "f5991479-cb9d-4e62-ef3a-d2c37c5383fb"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "{'input_ids': tensor([[ 1037, 11834, 18384,  2003,  1037,  3274,  2565,  2008, 26633,  2015,\n",
              "          2529,  4512,  2083,  2376, 10954,  2030,  3793, 11834,  2015,  2030,\n",
              "          2119,  1012, 11834, 18384,  1010,  2460,  2005, 24691, 18384,  1010,\n",
              "          2003,  2019,  7976,  4454,  1006,  9932,  1007,  3444,  2008,  2064,\n",
              "          2022, 11157,  1998,  2109,  2083,  2151,  2350, 24732,  4646,  1012,\n",
              "          2045,  2024,  1037,  2193,  1997, 10675,  2015,  2005, 11834, 18384,\n",
              "          1010,  2164,  1000,  2831, 18384,  1010,  1000,  1000, 28516,  1010,\n",
              "          1000,  1000, 10047, 28516,  1010,  1000,  1000,  9123,  4005,  1000,\n",
              "          2030,  1000,  7976,  4512,  9178,  1012,  1000,  1996,  6555,  5083,\n",
              "          1997,  2974,  2038,  2464,  2019,  3623,  1999,  5661,  3048,  2013,\n",
              "          3151,  2000,  3617,  7248,  2000,  9099, 18908,  2007, 10390,  1012,\n",
              "         15106,  2083,  2974,  2003,  2108,  3344,  2041,  2011,  5661,  2011,\n",
              "         14972,  9932,  5461,  2006,  2037,  3617,  7248,  1012,  2028,  9932,\n",
              "          6028,  2008,  2003,  3652,  1999,  2049,  4646,  1998,  2224,  2003,\n",
              "         11834, 27014,  1012,  2070,  4973,  1997, 11834, 18384,  2974,  2024,\n",
              "          7484, 16838,  2066,  9733,  1005,  1055, 24969,  1998,  8224,  3353,\n",
              "          1010,  1998, 24732, 18726,  1010,  2107,  2004,  2057,  7507,  2102,\n",
              "          1998,  9130,  1005,  1055, 11981,  1012,  1037, 11834, 18384,  2003,\n",
              "          2019, 12978,  2565,  2008, 11835,  2015,  2007,  6304,  2004,  1037,\n",
              "          2529,  2052,  1998,  5366,  2210,  2000,  2498,  2000,  8526,  2007,\n",
              "          1012, 11834, 27014,  5463,  2000,  6304,  2012,  2035,  2335,  1997,\n",
              "          1996,  2154,  1998,  2733,  1998,  2024,  2025,  3132,  2011,  2051,\n",
              "          2030,  1037,  3558,  3295,  1012,  2023,  3084,  2049,  7375, 16004,\n",
              "          2000,  1037,  2843,  1997,  5661,  2008,  2089,  2025,  2031,  1996,\n",
              "         22039,  2030,  3361,  4219,  2000,  2562,  5126,  2551,  2105,  1996,\n",
              "          5119,  1012, 11834, 27014,  2024, 14057,  2005,  4346,  8013,  2326,\n",
              "          1998,  2490,  2484,  2847,  1037,  2154,  1010,  1021,  2420,  1037,\n",
              "          2733,  1012,  2027,  2036,  2489,  2039,  3042,  3210,  1998,  2024,\n",
              "          2521,  2625,  6450,  2058,  1996,  2146,  2448,  2084, 14763,  2111,\n",
              "          2000,  4685,  2490,  1012,  2478,  9932,  1998,  3019,  2653,  6364,\n",
              "          1010, 11834, 27014,  2024,  3352,  2488,  2012,  4824,  2054,  6304,\n",
              "          2215,  1998,  4346,  1996,  2393,  2027,  2342,  1012,  3316,  2036,\n",
              "          2066, 11834, 27014,  2138,  2027,  2064,  8145,  2951,  2055,  8013,\n",
              "         10861,  5134,  1010,  3433,  2335,  1010,  9967,  1010,  1998,  2061,\n",
              "          2006,  1012, 11834, 27014,  1010,  2174,  1010,  2024,  2145,  3132,\n",
              "          1012,  2130,  2007,  3019,  2653,  6364,  1010,  2027,  2089,  2025,\n",
              "          3929, 22346,  1037,  8013,  1005,  1055,  7953,  1998,  2089,  3073,\n",
              "          4297, 11631,  7869,  3372,  6998,  1012,  2116, 11834, 27014,  2024,\n",
              "          2036,  3132,  1999,  1996,  9531,  1997, 10861,  5134,  2008,  2027,\n",
              "          2024,  2583,  2000,  6869,  2000,  1012,  2023,  2089,  2599,  2000,\n",
              "          9135,  2007,  1037,  3768,  1997,  7603,  1010, 11883,  1010,  1998,\n",
              "          3167,  3989,  2445,  7199, 12391, 12247,  1012,  1999,  2804,  2000,\n",
              "          8013, 28237,  2007,  2025,  4285,  1037,  2529,  2108,  1010, 11834,\n",
              "         27014,  2064,  2022,  6450,  2000, 10408,  1998,  5441,  1010,  2926,\n",
              "          2065,  2027,  2442,  2022, 28749,  1998,  7172,  2411,  1012]]), 'token_type_ids': tensor([[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
              "         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
              "         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
              "         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
              "         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
              "         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
              "         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
              "         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
              "         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
              "         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
              "         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
              "         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
              "         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
              "         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
              "         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
              "         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
              "         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
              "         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
              "         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]]), 'attention_mask': tensor([[1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
              "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
              "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
              "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
              "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
              "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
              "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
              "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
              "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
              "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
              "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
              "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
              "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
              "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
              "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
              "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
              "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
              "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
              "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1]])}"
            ]
          },
          "metadata": {},
          "execution_count": 54
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "input_id_chunks = tokens['input_ids'][0].split(510)\n",
        "mask_chunks = tokens['attention_mask'][0].split(510)\n",
        "\n",
        "for tensor in input_id_chunks:\n",
        "  print(len(tensor))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "qGjPLBWz_b4S",
        "outputId": "1d4021d5-e229-4d22-bdcc-54c90c167ade"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "449\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "a = torch.arange(10)\n",
        "a"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "jcFJOS2V_b6p",
        "outputId": "b68e3448-24d7-45ca-aedc-35914b3bbf69"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "tensor([0, 1, 2, 3, 4, 5, 6, 7, 8, 9])"
            ]
          },
          "metadata": {},
          "execution_count": 56
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "torch.cat(\n",
        "    [torch.Tensor([101]), a, torch.Tensor([102])]\n",
        ")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "44yegsjJ_b9J",
        "outputId": "cc56ceb4-9dce-483a-c602-fdf918656377"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "tensor([101.,   0.,   1.,   2.,   3.,   4.,   5.,   6.,   7.,   8.,   9., 102.])"
            ]
          },
          "metadata": {},
          "execution_count": 57
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "***Préparer les morceaux***\n",
        "\n",
        "Nous avons maintenant notre tenseur tokenisé ; nous devons le diviser en morceaux ne dépassant pas 510 jetons. Nous choisissons 510 plutôt que 512 pour laisser deux places libres pour ajouter nos jetons [CLS] et [SEP].\n",
        "\n",
        "***Diviser***\n",
        "\n",
        "\n",
        "Nous appliquons la méthode de fractionnement à la fois à nos ID d'entrée et aux tenseurs de masque d'attention (nous\n",
        "n'ont pas besoin des ID de type de jeton et peuvent les supprimer). Nous avons maintenant trois morceaux pour chaque ensemble de tenseurs. Notez que nous devrons ajouter un rembourrage au dernier morceau car il ne satisfera pas la taille de tenseur de 512 requise par BERT.\n",
        "\n",
        "\n",
        "***CLS et SEP***\n",
        "\n",
        "\n",
        "Ensuite, nous ajoutons les jetons de début de séquence [CLS] et de séparateur [SEP]. Pour cela, nous pouvons utiliser la fonction torch.cat, qui concatène une liste de tenseurs.\n",
        "Nos jetons sont déjà au format d'identification de jeton, nous pouvons donc nous référer aux jetons spéciaux\n",
        "tableau ci-dessus pour créer les versions d'ID de jeton de nos jetons [CLS] et [SEP].\n",
        "Parce que nous faisons cela pour plusieurs tenseurs, nous plaçons la fonction torch.cat dans\n",
        "une boucle for et effectuer la concaténation pour chacun de nos morceaux individuellement.\n",
        "De plus, nos blocs de masque d'attention sont concaténés avec des 1 au lieu de 101\n",
        "et 102. Nous faisons cela parce que le masque d'attention ne contient pas d'ID de jeton mais\n",
        "à la place un ensemble de 1 et de 0.\n",
        "Les zéros dans le masque d'attention représentent l'emplacement des jetons de remplissage (que nous allons\n",
        "add next), et comme [CLS] et [SEP] ne sont pas des jetons de remplissage, ils sont représentés\n",
        "avec 1s.\n",
        "\n",
        "***Rembourrage***\n",
        "\n",
        "\n",
        "Nous devons ajouter un rembourrage à nos morceaux de tenseur pour nous assurer qu'ils satisfont à la longueur de tenseur de 512 requise par BERT. Nos deux premiers morceaux ne nécessitent aucun rembourrage car ils satisfont déjà à cette exigence de longueur, mais les derniers morceaux le font.\n",
        "Pour vérifier si un morceau nécessite un remplissage, nous ajoutons une instruction if qui vérifie la longueur du tenseur. Si le tenseur est plus court que 512 jetons, nous ajoutons un rembourrage à l'aide de la fonction torch.cat. Nous devrions ajouter cette déclaration à la même boucle for où nous ajoutons nos jetons [CLS] et [SEP] - si vous avez besoin d'aide, j'ai inclus les scripts complets à la fin de l'article."
      ],
      "metadata": {
        "id": "-NLeJsganP-Z"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "chunksize = 512\n",
        "\n",
        "input_id_chunks = list(tokens['input_ids'][0].split(chunksize - 2))\n",
        "mask_chunks = list(tokens['attention_mask'][0].split(chunksize - 2))\n",
        "\n",
        "for i in range(len(input_id_chunks)):\n",
        "    input_id_chunks[i] = torch.cat([\n",
        "        torch.tensor([101]), input_id_chunks[i], torch.tensor([102])\n",
        "    ])\n",
        "    mask_chunks[i] = torch.cat([\n",
        "        torch.tensor([1]), mask_chunks[i], torch.tensor([1])\n",
        "    ])\n",
        "\n",
        "    pad_len = chunksize - input_id_chunks[i].shape[0]\n",
        "    if pad_len > 0:\n",
        "        input_id_chunks[i] = torch.cat([\n",
        "            input_id_chunks[i], torch.Tensor([0] * pad_len)\n",
        "        ])\n",
        "        mask_chunks[i] = torch.cat([\n",
        "            mask_chunks[i], torch.Tensor([0] * pad_len)\n",
        "        ])\n",
        "\n",
        "for chunk in input_id_chunks:\n",
        "    print(chunk)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "JSG7d6xs_cAJ",
        "outputId": "dd757780-bb9a-4417-86dd-878bb1d3d09d"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "tensor([  101.,  1037., 11834., 18384.,  2003.,  1037.,  3274.,  2565.,  2008.,\n",
            "        26633.,  2015.,  2529.,  4512.,  2083.,  2376., 10954.,  2030.,  3793.,\n",
            "        11834.,  2015.,  2030.,  2119.,  1012., 11834., 18384.,  1010.,  2460.,\n",
            "         2005., 24691., 18384.,  1010.,  2003.,  2019.,  7976.,  4454.,  1006.,\n",
            "         9932.,  1007.,  3444.,  2008.,  2064.,  2022., 11157.,  1998.,  2109.,\n",
            "         2083.,  2151.,  2350., 24732.,  4646.,  1012.,  2045.,  2024.,  1037.,\n",
            "         2193.,  1997., 10675.,  2015.,  2005., 11834., 18384.,  1010.,  2164.,\n",
            "         1000.,  2831., 18384.,  1010.,  1000.,  1000., 28516.,  1010.,  1000.,\n",
            "         1000., 10047., 28516.,  1010.,  1000.,  1000.,  9123.,  4005.,  1000.,\n",
            "         2030.,  1000.,  7976.,  4512.,  9178.,  1012.,  1000.,  1996.,  6555.,\n",
            "         5083.,  1997.,  2974.,  2038.,  2464.,  2019.,  3623.,  1999.,  5661.,\n",
            "         3048.,  2013.,  3151.,  2000.,  3617.,  7248.,  2000.,  9099., 18908.,\n",
            "         2007., 10390.,  1012., 15106.,  2083.,  2974.,  2003.,  2108.,  3344.,\n",
            "         2041.,  2011.,  5661.,  2011., 14972.,  9932.,  5461.,  2006.,  2037.,\n",
            "         3617.,  7248.,  1012.,  2028.,  9932.,  6028.,  2008.,  2003.,  3652.,\n",
            "         1999.,  2049.,  4646.,  1998.,  2224.,  2003., 11834., 27014.,  1012.,\n",
            "         2070.,  4973.,  1997., 11834., 18384.,  2974.,  2024.,  7484., 16838.,\n",
            "         2066.,  9733.,  1005.,  1055., 24969.,  1998.,  8224.,  3353.,  1010.,\n",
            "         1998., 24732., 18726.,  1010.,  2107.,  2004.,  2057.,  7507.,  2102.,\n",
            "         1998.,  9130.,  1005.,  1055., 11981.,  1012.,  1037., 11834., 18384.,\n",
            "         2003.,  2019., 12978.,  2565.,  2008., 11835.,  2015.,  2007.,  6304.,\n",
            "         2004.,  1037.,  2529.,  2052.,  1998.,  5366.,  2210.,  2000.,  2498.,\n",
            "         2000.,  8526.,  2007.,  1012., 11834., 27014.,  5463.,  2000.,  6304.,\n",
            "         2012.,  2035.,  2335.,  1997.,  1996.,  2154.,  1998.,  2733.,  1998.,\n",
            "         2024.,  2025.,  3132.,  2011.,  2051.,  2030.,  1037.,  3558.,  3295.,\n",
            "         1012.,  2023.,  3084.,  2049.,  7375., 16004.,  2000.,  1037.,  2843.,\n",
            "         1997.,  5661.,  2008.,  2089.,  2025.,  2031.,  1996., 22039.,  2030.,\n",
            "         3361.,  4219.,  2000.,  2562.,  5126.,  2551.,  2105.,  1996.,  5119.,\n",
            "         1012., 11834., 27014.,  2024., 14057.,  2005.,  4346.,  8013.,  2326.,\n",
            "         1998.,  2490.,  2484.,  2847.,  1037.,  2154.,  1010.,  1021.,  2420.,\n",
            "         1037.,  2733.,  1012.,  2027.,  2036.,  2489.,  2039.,  3042.,  3210.,\n",
            "         1998.,  2024.,  2521.,  2625.,  6450.,  2058.,  1996.,  2146.,  2448.,\n",
            "         2084., 14763.,  2111.,  2000.,  4685.,  2490.,  1012.,  2478.,  9932.,\n",
            "         1998.,  3019.,  2653.,  6364.,  1010., 11834., 27014.,  2024.,  3352.,\n",
            "         2488.,  2012.,  4824.,  2054.,  6304.,  2215.,  1998.,  4346.,  1996.,\n",
            "         2393.,  2027.,  2342.,  1012.,  3316.,  2036.,  2066., 11834., 27014.,\n",
            "         2138.,  2027.,  2064.,  8145.,  2951.,  2055.,  8013., 10861.,  5134.,\n",
            "         1010.,  3433.,  2335.,  1010.,  9967.,  1010.,  1998.,  2061.,  2006.,\n",
            "         1012., 11834., 27014.,  1010.,  2174.,  1010.,  2024.,  2145.,  3132.,\n",
            "         1012.,  2130.,  2007.,  3019.,  2653.,  6364.,  1010.,  2027.,  2089.,\n",
            "         2025.,  3929., 22346.,  1037.,  8013.,  1005.,  1055.,  7953.,  1998.,\n",
            "         2089.,  3073.,  4297., 11631.,  7869.,  3372.,  6998.,  1012.,  2116.,\n",
            "        11834., 27014.,  2024.,  2036.,  3132.,  1999.,  1996.,  9531.,  1997.,\n",
            "        10861.,  5134.,  2008.,  2027.,  2024.,  2583.,  2000.,  6869.,  2000.,\n",
            "         1012.,  2023.,  2089.,  2599.,  2000.,  9135.,  2007.,  1037.,  3768.,\n",
            "         1997.,  7603.,  1010., 11883.,  1010.,  1998.,  3167.,  3989.,  2445.,\n",
            "         7199., 12391., 12247.,  1012.,  1999.,  2804.,  2000.,  8013., 28237.,\n",
            "         2007.,  2025.,  4285.,  1037.,  2529.,  2108.,  1010., 11834., 27014.,\n",
            "         2064.,  2022.,  6450.,  2000., 10408.,  1998.,  5441.,  1010.,  2926.,\n",
            "         2065.,  2027.,  2442.,  2022., 28749.,  1998.,  7172.,  2411.,  1012.,\n",
            "          102.,     0.,     0.,     0.,     0.,     0.,     0.,     0.,     0.,\n",
            "            0.,     0.,     0.,     0.,     0.,     0.,     0.,     0.,     0.,\n",
            "            0.,     0.,     0.,     0.,     0.,     0.,     0.,     0.,     0.,\n",
            "            0.,     0.,     0.,     0.,     0.,     0.,     0.,     0.,     0.,\n",
            "            0.,     0.,     0.,     0.,     0.,     0.,     0.,     0.,     0.,\n",
            "            0.,     0.,     0.,     0.,     0.,     0.,     0.,     0.,     0.,\n",
            "            0.,     0.,     0.,     0.,     0.,     0.,     0.,     0.])\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "for tensor in range(len(input_id_chunks)):\n",
        "  ans = answer_question(question, ' '.join(tokenizer.convert_ids_to_tokens(input_id_chunks[tensor])))\n",
        "  print(ans)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "lx5Ydiwz_cG5",
        "outputId": "76092bc7-413c-43d2-d4a0-c49582b7a985"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Query has 512 tokens.\n",
            "\n",
            "('free up phone lines and are far less expensive over the long run than hiring people to perform support', 3.8189876079559326)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "def expand_split_sentences(pdf_txt):\n",
        "  import nltk\n",
        "  nltk.download('punkt')\n",
        "  new_chunks = nltk.sent_tokenize(pdf_txt)\n",
        "  length = len(new_chunks)\n",
        "  #for i in range(length):\n",
        "    #tmp_token = tokenizer.encode(new_chunks[i])\n",
        "    #print('The input has a total of {:} tokens.'.format(len(tmp_token)))\n",
        "\n",
        "  new_df = [];\n",
        "  for i in range(length):\n",
        "    paragraph = \"\"\n",
        "    for j in range(i, length):\n",
        "      #tmp_str = paragraph + new_chunks[j]\n",
        "      tmp_token = tokenizer.encode(paragraph + new_chunks[j])\n",
        "      length_token = len(tmp_token)\n",
        "      if length_token < 510:\n",
        "        #print(length_token)\n",
        "        paragraph = paragraph + new_chunks[j]\n",
        "      else:\n",
        "        #print(length_token)\n",
        "        break;\n",
        "    #print(len(tokenizer.encode(paragraph)))\n",
        "    new_df.append(paragraph)\n",
        "  return new_df\n",
        "  #for i in new_df:\n",
        "    #print(i)"
      ],
      "metadata": {
        "id": "7ahE9X5AEydV"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "max_score = 0;\n",
        "final_answer = \"\"\n",
        "new_df = expand_split_sentences(pdf_txt)\n",
        "for new_context in new_df:\n",
        "  #new_paragrapgh = new_paragrapgh + answer_question(question, answer_text)\n",
        "  ans, score = answer_question(question, new_context)\n",
        "  if score > max_score:\n",
        "    max_score = score\n",
        "    final_answer = ans\n",
        "print(question)\n",
        "print(final_answer)\n",
        "print(max_score)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "zf-Jx4ttEyfs",
        "outputId": "af0e2175-0d22-48b5-d894-c9d530635887"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[nltk_data] Downloading package punkt to /root/nltk_data...\n",
            "[nltk_data]   Package punkt is already up-to-date!\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Query has 459 tokens.\n",
            "\n",
            "Query has 437 tokens.\n",
            "\n",
            "Query has 409 tokens.\n",
            "\n",
            "Query has 372 tokens.\n",
            "\n",
            "Query has 349 tokens.\n",
            "\n",
            "Query has 331 tokens.\n",
            "\n",
            "Query has 316 tokens.\n",
            "\n",
            "Query has 283 tokens.\n",
            "\n",
            "Query has 258 tokens.\n",
            "\n",
            "Query has 234 tokens.\n",
            "\n",
            "Query has 207 tokens.\n",
            "\n",
            "Query has 187 tokens.\n",
            "\n",
            "Query has 165 tokens.\n",
            "\n",
            "Query has 141 tokens.\n",
            "\n",
            "Query has 117 tokens.\n",
            "\n",
            "Query has 108 tokens.\n",
            "\n",
            "Query has 83 tokens.\n",
            "\n",
            "Query has 63 tokens.\n",
            "\n",
            "Query has 42 tokens.\n",
            "\n",
            "free up phone lines and are far less expensive over the long run than hiring people to perform support\n",
            "5.080368995666504\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [],
      "metadata": {
        "id": "e6DuanlvmxWK"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Nous pouvons voir que nous obtenons un ensemble de trois valeurs d'activation pour chaque morceau.\n",
        "Ces valeurs d'activation ne sont pas encore nos probabilités de sortie. Pour les transformer en\n",
        "probabilités de sortie, nous devons appliquer une fonction softmax au tenseur de sortie.\n",
        "\n",
        "Enfin, nous prenons la moyenne des valeurs de chaque classe (ou colonne) pour obtenir notre probabilité finale de sentiment positif, négatif ou neutre."
      ],
      "metadata": {
        "id": "0V7UpVJ2muxM"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "input_ids = torch.stack(input_id_chunks)\n",
        "attention_mask = torch.stack(mask_chunks)\n",
        "\n",
        "input_dict = {\n",
        "    'input_ids': input_ids.long(),\n",
        "    'attention_mask': attention_mask.int()\n",
        "}\n",
        "input_dict"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "rowgM6TVEyic",
        "outputId": "f73c7be8-ba63-4290-8586-fb3e4330d11f"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "{'input_ids': tensor([[  101,  2166,  5427,  ...,  1012,  2107,   102],\n",
              "         [  101, 29361,  2024,  ...,  2064,  2022,   102],\n",
              "         [  101,  3876,  2006,  ...,     0,     0,     0]]),\n",
              " 'attention_mask': tensor([[1, 1, 1,  ..., 1, 1, 1],\n",
              "         [1, 1, 1,  ..., 1, 1, 1],\n",
              "         [1, 1, 1,  ..., 0, 0, 0]], dtype=torch.int32)}"
            ]
          },
          "metadata": {},
          "execution_count": 40
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "outputs = model(**input_dict)\n",
        "probs = torch.nn.functional.softmax(outputs[0], dim=-1)\n",
        "probs = probs.mean(dim=0)\n",
        "probs"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "qtlYsktoE8o2",
        "outputId": "934406b3-62c7-4cc8-a00f-5d657bda6bbf"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "tensor([4.2047e-01, 7.3233e-03, 3.8704e-04, 3.7146e-04, 2.4710e-04, 4.9905e-04,\n",
              "        9.1580e-05, 7.2339e-04, 2.8726e-04, 2.7150e-04, 2.2355e-04, 5.9827e-05,\n",
              "        1.0277e-03, 5.1559e-05, 4.3810e-05, 1.1908e-04, 2.0978e-04, 1.3863e-04,\n",
              "        4.2432e-05, 5.6722e-05, 7.6533e-05, 6.9248e-04, 9.3073e-05, 3.7591e-04,\n",
              "        4.3682e-05, 4.0332e-04, 6.2978e-05, 8.4359e-05, 1.1684e-04, 4.9767e-05,\n",
              "        2.4577e-04, 2.9513e-05, 1.8508e-04, 9.6008e-04, 1.3457e-04, 5.4936e-05,\n",
              "        5.5473e-05, 1.6459e-04, 6.7666e-05, 1.0982e-04, 6.5894e-05, 5.0604e-05,\n",
              "        8.9084e-05, 1.5366e-04, 4.3831e-05, 1.7032e-04, 6.9928e-04, 5.5394e-05,\n",
              "        2.6971e-04, 4.2740e-05, 2.9958e-05, 8.3827e-05, 7.3587e-05, 1.0709e-04,\n",
              "        5.4899e-04, 5.5681e-05, 3.9024e-05, 3.3720e-04, 4.9262e-05, 9.6260e-05,\n",
              "        5.3931e-05, 1.5222e-04, 7.0258e-04, 2.5524e-03, 1.5948e-04, 1.0690e-03,\n",
              "        6.7079e-05, 8.0789e-04, 2.0365e-03, 6.5701e-05, 1.2064e-04, 2.8996e-04,\n",
              "        2.1347e-04, 5.6888e-05, 2.1249e-03, 3.9499e-05, 2.1159e-04, 2.6569e-04,\n",
              "        6.2412e-05, 5.1129e-05, 8.9495e-05, 7.2415e-05, 3.5381e-03, 5.4556e-05,\n",
              "        7.1508e-04, 1.4188e-04, 2.4499e-04, 5.9457e-05, 1.1119e-03, 2.0382e-04,\n",
              "        1.4295e-04, 4.3345e-04, 1.3646e-04, 4.1674e-05, 2.0847e-04, 1.7065e-04,\n",
              "        3.8519e-04, 3.8708e-04, 4.1200e-05, 3.0841e-04, 1.2647e-04, 1.3637e-04,\n",
              "        4.6881e-05, 3.1991e-05, 3.2145e-05, 4.4246e-05, 8.7806e-05, 5.6480e-05,\n",
              "        5.8580e-05, 5.6653e-05, 4.8347e-05, 2.4965e-05, 4.6378e-05, 2.6379e-05,\n",
              "        4.8670e-05, 1.6737e-04, 6.4618e-05, 5.6495e-05, 8.1759e-05, 4.4466e-05,\n",
              "        1.0158e-04, 3.5585e-05, 6.0410e-05, 6.3875e-05, 1.7039e-04, 5.0404e-05,\n",
              "        5.7500e-05, 5.5004e-05, 4.6491e-05, 5.0295e-05, 4.5397e-05, 5.2832e-05,\n",
              "        5.3389e-05, 6.3324e-05, 1.3064e-04, 2.5749e-04, 5.2643e-05, 4.6944e-05,\n",
              "        3.7305e-05, 4.8249e-05, 8.0733e-05, 8.4464e-05, 1.0670e-04, 7.3485e-05,\n",
              "        7.4626e-05, 5.2369e-05, 6.9581e-05, 2.5934e-05, 3.6436e-05, 1.8811e-04,\n",
              "        8.0685e-05, 3.2122e-05, 5.3236e-05, 4.0746e-04, 9.3873e-05, 3.9662e-05,\n",
              "        8.7556e-05, 1.4731e-04, 1.3155e-04, 2.4929e-05, 7.9417e-05, 3.0528e-05,\n",
              "        1.0242e-04, 3.5068e-05, 3.4698e-05, 4.1113e-05, 4.6601e-05, 1.1962e-04,\n",
              "        3.4961e-05, 3.7392e-05, 7.1280e-05, 2.1064e-05, 4.6823e-05, 2.8664e-05,\n",
              "        4.4135e-05, 2.2795e-04, 6.4747e-05, 2.8058e-05, 5.6868e-05, 9.5724e-05,\n",
              "        1.1329e-04, 3.4201e-05, 5.0846e-05, 3.1480e-05, 6.0794e-05, 5.2622e-05,\n",
              "        2.9664e-04, 2.6548e-05, 3.1076e-05, 2.2069e-04, 1.8944e-04, 4.1666e-05,\n",
              "        9.3682e-05, 1.0285e-04, 6.4692e-05, 3.3199e-05, 3.2460e-04, 8.5656e-05,\n",
              "        7.1954e-05, 4.7625e-05, 1.1412e-04, 1.2776e-04, 1.0165e-04, 2.7259e-04,\n",
              "        3.9819e-05, 3.7262e-05, 2.3008e-04, 8.0705e-05, 7.4008e-05, 1.0812e-04,\n",
              "        8.5720e-05, 8.4158e-05, 3.3531e-05, 1.0134e-04, 3.8595e-05, 4.5253e-05,\n",
              "        6.6540e-05, 8.9126e-05, 7.6436e-05, 7.7764e-05, 8.5636e-05, 3.5595e-05,\n",
              "        3.2802e-05, 3.5160e-05, 5.9794e-05, 4.3163e-05, 5.5477e-05, 5.5824e-05,\n",
              "        1.3474e-04, 3.5574e-05, 4.1005e-05, 2.7552e-05, 3.3310e-05, 3.7466e-05,\n",
              "        3.1794e-05, 6.9628e-05, 3.5483e-05, 6.0901e-05, 1.4809e-04, 1.5280e-04,\n",
              "        2.0674e-04, 8.9104e-05, 3.1164e-05, 4.7400e-05, 4.0626e-05, 7.1526e-05,\n",
              "        3.5956e-05, 3.9222e-05, 3.7219e-05, 4.4639e-05, 1.0312e-04, 2.9464e-05,\n",
              "        2.4477e-05, 3.3950e-05, 5.8510e-05, 7.1361e-05, 3.4700e-05, 4.5197e-05,\n",
              "        4.2812e-05, 4.8044e-05, 3.1948e-05, 3.0816e-05, 6.2858e-05, 5.7715e-05,\n",
              "        3.5892e-05, 3.9153e-05, 3.8666e-05, 5.6248e-05, 2.2652e-05, 7.0105e-05,\n",
              "        4.9782e-05, 3.5454e-05, 4.0896e-05, 3.4124e-05, 4.9317e-05, 2.8924e-05,\n",
              "        4.0054e-05, 3.9652e-05, 5.1658e-05, 9.8789e-02, 3.5356e-05, 1.5939e-05,\n",
              "        1.7316e-05, 2.0357e-05, 2.4843e-05, 1.9501e-05, 3.3287e-05, 3.2738e-05,\n",
              "        1.4073e-05, 1.5898e-05, 1.8144e-05, 1.4344e-05, 1.5390e-05, 2.0967e-05,\n",
              "        1.8793e-05, 2.4851e-05, 1.5335e-05, 3.0455e-05, 2.7499e-05, 1.8701e-05,\n",
              "        2.5784e-05, 2.9815e-05, 4.0560e-05, 2.9167e-05, 2.1711e-05, 1.9326e-05,\n",
              "        2.2574e-05, 2.0133e-05, 2.3609e-05, 1.9194e-05, 1.6072e-05, 1.5034e-05,\n",
              "        3.8934e-05, 1.6530e-05, 2.1887e-05, 1.7048e-05, 1.8730e-05, 2.6361e-05,\n",
              "        3.6828e-05, 3.3074e-05, 1.9038e-05, 2.5489e-05, 2.4382e-05, 3.3837e-05,\n",
              "        2.4585e-05, 7.0282e-05, 6.9552e-05, 5.9061e-05, 5.0989e-05, 5.3752e-05,\n",
              "        1.5297e-04, 9.9908e-05, 1.9112e-04, 4.5872e-05, 3.1400e-05, 1.9073e-05,\n",
              "        4.9482e-05, 1.0397e-04, 6.5561e-05, 1.1692e-04, 6.9386e-05, 2.2301e-05,\n",
              "        3.3553e-05, 3.3179e-05, 2.2132e-05, 2.5484e-05, 2.5358e-05, 1.9016e-05,\n",
              "        2.2342e-05, 3.0359e-05, 2.5104e-05, 2.0813e-05, 2.2827e-05, 1.7814e-05,\n",
              "        2.5872e-05, 4.0808e-05, 2.3079e-05, 2.4501e-05, 2.0192e-05, 2.7207e-05,\n",
              "        3.6556e-05, 6.1634e-05, 3.0985e-05, 1.4299e-04, 3.3231e-05, 2.9805e-05,\n",
              "        4.4890e-05, 3.6918e-05, 2.5100e-05, 1.8482e-05, 2.7753e-05, 1.9064e-05,\n",
              "        2.5518e-05, 3.3453e-05, 4.1150e-05, 1.8053e-05, 2.1683e-05, 1.7240e-05,\n",
              "        2.1360e-05, 3.2736e-05, 2.0746e-05, 2.7276e-05, 1.8640e-05, 2.2516e-05,\n",
              "        1.9912e-05, 2.7437e-05, 1.6754e-05, 3.9655e-05, 4.4313e-05, 1.6155e-05,\n",
              "        3.4294e-05, 5.0868e-05, 3.5840e-05, 4.2855e-05, 1.3945e-04, 2.0258e-04,\n",
              "        2.4367e-05, 3.2675e-05, 2.2929e-05, 3.4300e-05, 4.2000e-05, 3.4378e-05,\n",
              "        2.3583e-05, 8.6818e-05, 2.5717e-05, 2.4171e-05, 2.9486e-05, 2.4192e-05,\n",
              "        5.4532e-05, 2.9652e-05, 2.3284e-05, 5.6041e-05, 2.6010e-05, 2.5898e-05,\n",
              "        2.5589e-05, 1.9638e-05, 2.5982e-05, 2.2606e-05, 6.2927e-05, 2.6647e-05,\n",
              "        3.1055e-05, 2.5189e-05, 2.0966e-05, 7.5393e-05, 1.8333e-05, 1.9678e-05,\n",
              "        2.8083e-05, 1.5749e-05, 2.1385e-05, 2.1441e-05, 2.4648e-05, 2.5035e-05,\n",
              "        1.9541e-05, 4.0760e-05, 2.2986e-05, 3.7738e-05, 3.1105e-05, 2.7221e-05,\n",
              "        3.3813e-05, 4.3472e-05, 2.7978e-05, 2.3420e-05, 3.4056e-05, 9.8847e-05,\n",
              "        2.5885e-05, 4.9962e-05, 7.6817e-05, 2.4763e-05, 2.6551e-05, 3.4203e-05,\n",
              "        3.8391e-05, 4.1616e-05, 6.4324e-05, 2.1028e-04, 3.3907e-05, 2.9787e-05,\n",
              "        2.4334e-05, 3.2796e-05, 4.8975e-05, 3.9476e-05, 9.2538e-05, 2.9322e-05,\n",
              "        3.0799e-05, 2.7479e-05, 2.6269e-05, 6.6660e-05, 3.5829e-05, 3.3094e-05,\n",
              "        3.8299e-05, 2.2342e-05, 1.7251e-05, 2.6254e-05, 2.7984e-05, 1.2164e-04,\n",
              "        1.9955e-05, 3.0520e-05, 2.3537e-05, 3.3842e-05, 2.5507e-05, 2.4733e-05,\n",
              "        2.1638e-05, 2.5656e-05, 7.0366e-05, 1.9037e-05, 2.3059e-05, 1.8690e-05,\n",
              "        3.8114e-05, 2.8532e-05, 2.7036e-05, 2.3507e-05, 2.6660e-05, 3.6071e-05,\n",
              "        2.6525e-05, 2.1497e-05, 1.9108e-05, 2.7563e-05, 2.2473e-05, 2.9002e-05,\n",
              "        2.2893e-05, 1.8821e-05, 2.0394e-05, 1.9089e-05, 2.3703e-05, 3.6839e-05,\n",
              "        1.9838e-05, 1.7759e-05, 1.9908e-05, 3.5956e-05, 2.4703e-05, 2.0852e-05,\n",
              "        5.0867e-04, 4.2030e-01], grad_fn=<MeanBackward1>)"
            ]
          },
          "metadata": {},
          "execution_count": 41
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "9XlD3zZUE8re"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "u81IKPIW_cJQ"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}