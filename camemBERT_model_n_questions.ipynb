{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyP69kegTulYNrmAHmd4dh6K"
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "widgets": {
      "application/vnd.jupyter.widget-state+json": {
        "fa2637bad7f3479a8824b4fa8c56eade": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_d9875f17563847a98059dd047b381565",
              "IPY_MODEL_954385ffc41c4acbb72566b54369be93",
              "IPY_MODEL_3f72371b562a419a97edbfc8f63a5bc6"
            ],
            "layout": "IPY_MODEL_477e9d92653a4ce3ab9875408c66f828"
          }
        },
        "d9875f17563847a98059dd047b381565": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_5b12d43ec7ac4555b60d74f973957f48",
            "placeholder": "​",
            "style": "IPY_MODEL_1ecef767849d46c1a35b985d26236bfa",
            "value": "Downloading: 100%"
          }
        },
        "954385ffc41c4acbb72566b54369be93": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_9bfeca7ff1fc45e5ab6d84ab6e681c54",
            "max": 517,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_7d7d03cf17b54731825a26e0256a1d33",
            "value": 517
          }
        },
        "3f72371b562a419a97edbfc8f63a5bc6": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_8fd055e23f524b589fbe4a513b2b7129",
            "placeholder": "​",
            "style": "IPY_MODEL_cda43785c1224443be7dfac09da01621",
            "value": " 517/517 [00:00&lt;00:00, 2.35kB/s]"
          }
        },
        "477e9d92653a4ce3ab9875408c66f828": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "5b12d43ec7ac4555b60d74f973957f48": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "1ecef767849d46c1a35b985d26236bfa": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "9bfeca7ff1fc45e5ab6d84ab6e681c54": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "7d7d03cf17b54731825a26e0256a1d33": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "8fd055e23f524b589fbe4a513b2b7129": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "cda43785c1224443be7dfac09da01621": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "2d32c1f41fa843f4a6755f783f84f91a": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_1e9322147ece4905ad7e56d162cc8482",
              "IPY_MODEL_16f5d3abe17d4311b2b86c334791bbba",
              "IPY_MODEL_80ae24a6863c4e698dc29f717680e6ad"
            ],
            "layout": "IPY_MODEL_dd907b38f2d34a18a018831625af44d2"
          }
        },
        "1e9322147ece4905ad7e56d162cc8482": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_65add8c450c04c269d3c74605f90bc93",
            "placeholder": "​",
            "style": "IPY_MODEL_213b52f5f93046f580864a0949cc8454",
            "value": "Downloading: 100%"
          }
        },
        "16f5d3abe17d4311b2b86c334791bbba": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_186d75b1b3334b2b9f7977c21cf24a77",
            "max": 442543047,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_f1b24e3e2a224abeb454f8fe9f39ac0e",
            "value": 442543047
          }
        },
        "80ae24a6863c4e698dc29f717680e6ad": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_0291729e8a9c4896bea6338590c86d4a",
            "placeholder": "​",
            "style": "IPY_MODEL_dfb23221b5974fe798de3431de3db323",
            "value": " 443M/443M [00:17&lt;00:00, 21.3MB/s]"
          }
        },
        "dd907b38f2d34a18a018831625af44d2": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "65add8c450c04c269d3c74605f90bc93": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "213b52f5f93046f580864a0949cc8454": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "186d75b1b3334b2b9f7977c21cf24a77": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "f1b24e3e2a224abeb454f8fe9f39ac0e": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "0291729e8a9c4896bea6338590c86d4a": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "dfb23221b5974fe798de3431de3db323": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "b0f01fa5a4ea48a38a84f4e0b35965c0": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_a33ae09660044b74a9fc04277e511018",
              "IPY_MODEL_3a3f27af5a044c3d9af78093ed8b793d",
              "IPY_MODEL_25d2dca25aec47a389412c98063479f5"
            ],
            "layout": "IPY_MODEL_f7a81a896c4645f498bffcefd5388adb"
          }
        },
        "a33ae09660044b74a9fc04277e511018": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_d26be6040af64feea417525dd3bd8cf4",
            "placeholder": "​",
            "style": "IPY_MODEL_ae7d569d77f444aeb6559b14bff7ec69",
            "value": "Downloading: 100%"
          }
        },
        "3a3f27af5a044c3d9af78093ed8b793d": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_ea4b328cf9884cbcb2f9ca05a36632c4",
            "max": 810912,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_a9428d5703c44b37a2607094135afd09",
            "value": 810912
          }
        },
        "25d2dca25aec47a389412c98063479f5": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_ea0376e6a4ba4e549989c7d7d3b8f540",
            "placeholder": "​",
            "style": "IPY_MODEL_bb31410a6c134280897a187dd68fb83b",
            "value": " 811k/811k [00:00&lt;00:00, 1.65MB/s]"
          }
        },
        "f7a81a896c4645f498bffcefd5388adb": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "d26be6040af64feea417525dd3bd8cf4": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "ae7d569d77f444aeb6559b14bff7ec69": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "ea4b328cf9884cbcb2f9ca05a36632c4": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "a9428d5703c44b37a2607094135afd09": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "ea0376e6a4ba4e549989c7d7d3b8f540": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "bb31410a6c134280897a187dd68fb83b": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "a879cf391aab4530acc68c1a58d1212f": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_8bf2f44c7afe4932af572eda36dbb8ed",
              "IPY_MODEL_e54b53fa07794ed5b6e4d07f14f9a507",
              "IPY_MODEL_ac7bb5587cae43faa2c63c3dbd5dae79"
            ],
            "layout": "IPY_MODEL_9b3316dad9924233bc276c485217f973"
          }
        },
        "8bf2f44c7afe4932af572eda36dbb8ed": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_1ba203692b5f46409e2c023c889b9563",
            "placeholder": "​",
            "style": "IPY_MODEL_bb893eacf86f4088be19711bcb1ee832",
            "value": "Downloading: 100%"
          }
        },
        "e54b53fa07794ed5b6e4d07f14f9a507": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_692a3c909be4494b93f0372bab17fcd0",
            "max": 210,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_fc313354760c4ad780d27727256db10a",
            "value": 210
          }
        },
        "ac7bb5587cae43faa2c63c3dbd5dae79": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_fcb755f7297846169bc59d02ad1f84f5",
            "placeholder": "​",
            "style": "IPY_MODEL_49dbf1478918462bb6ba42f6f7372f2f",
            "value": " 210/210 [00:00&lt;00:00, 3.69kB/s]"
          }
        },
        "9b3316dad9924233bc276c485217f973": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "1ba203692b5f46409e2c023c889b9563": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "bb893eacf86f4088be19711bcb1ee832": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "692a3c909be4494b93f0372bab17fcd0": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "fc313354760c4ad780d27727256db10a": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "fcb755f7297846169bc59d02ad1f84f5": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "49dbf1478918462bb6ba42f6f7372f2f": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "5f7af8ce436645869ef00f1ddb4f8d68": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_ac39dd1415f04bd88293d16d9063513b",
              "IPY_MODEL_fe35498b5dd844a9b8d364c87718eee0",
              "IPY_MODEL_c94cb8d088cf47bfa62090ae59e7e91a"
            ],
            "layout": "IPY_MODEL_916c7f4053e04f4994fe5c8aad8bf207"
          }
        },
        "ac39dd1415f04bd88293d16d9063513b": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_f74e19311bcd40088d2be00d49574d35",
            "placeholder": "​",
            "style": "IPY_MODEL_65fc4165e68c49138ffbde2cd8212188",
            "value": "Downloading: 100%"
          }
        },
        "fe35498b5dd844a9b8d364c87718eee0": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_ebd7c084f74149e39f42fe75af188721",
            "max": 23,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_f28c921c64da4d3cb9d48d115f14f44f",
            "value": 23
          }
        },
        "c94cb8d088cf47bfa62090ae59e7e91a": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_0a86a3489c0f43389b8bc9624cd7320a",
            "placeholder": "​",
            "style": "IPY_MODEL_f310250a758f4392af50e080b0aef977",
            "value": " 23.0/23.0 [00:00&lt;00:00, 619B/s]"
          }
        },
        "916c7f4053e04f4994fe5c8aad8bf207": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "f74e19311bcd40088d2be00d49574d35": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "65fc4165e68c49138ffbde2cd8212188": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "ebd7c084f74149e39f42fe75af188721": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "f28c921c64da4d3cb9d48d115f14f44f": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "0a86a3489c0f43389b8bc9624cd7320a": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "f310250a758f4392af50e080b0aef977": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        }
      }
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "# **Modele camemBERT ** \n",
        "**Réponse aux questions avec un BERT français**\n",
        "\n",
        "Représentations d'encodeurs bidirectionnels à partir de transformateurs\n",
        "\n",
        "Au lieu de regarder les mots isolément, BERT, un modèle basé sur un transformateur, tente d'utiliser le contexte des mots pour obtenir des incorporations. BERT utilise plusieurs concepts d'apprentissage en profondeur pour proposer un modèle qui examine le contexte de manière bidirectionnelle, en tirant parti des informations de l'ensemble des phrases dans leur ensemble grâce à l'attention personnelle.\n",
        "\n",
        "https://github.com/youssefassis/CamemBERTQA/blob/master/CamemBERT%20Final.ipynb"
      ],
      "metadata": {
        "id": "YgCWfa36gasN"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "quFBHONy-OG4",
        "outputId": "df63b51b-6a64-4c30-9ab2-5ae112ac0b61"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n",
            "Collecting transformers==3.1.0\n",
            "  Downloading transformers-3.1.0-py3-none-any.whl (884 kB)\n",
            "\u001b[K     |████████████████████████████████| 884 kB 5.3 MB/s \n",
            "\u001b[?25hRequirement already satisfied: requests in /usr/local/lib/python3.7/dist-packages (from transformers==3.1.0) (2.23.0)\n",
            "Requirement already satisfied: numpy in /usr/local/lib/python3.7/dist-packages (from transformers==3.1.0) (1.21.6)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.7/dist-packages (from transformers==3.1.0) (3.8.0)\n",
            "Requirement already satisfied: tqdm>=4.27 in /usr/local/lib/python3.7/dist-packages (from transformers==3.1.0) (4.64.1)\n",
            "Requirement already satisfied: regex!=2019.12.17 in /usr/local/lib/python3.7/dist-packages (from transformers==3.1.0) (2022.6.2)\n",
            "Requirement already satisfied: packaging in /usr/local/lib/python3.7/dist-packages (from transformers==3.1.0) (21.3)\n",
            "Collecting tokenizers==0.8.1.rc2\n",
            "  Downloading tokenizers-0.8.1rc2-cp37-cp37m-manylinux1_x86_64.whl (3.0 MB)\n",
            "\u001b[K     |████████████████████████████████| 3.0 MB 51.6 MB/s \n",
            "\u001b[?25hCollecting sacremoses\n",
            "  Downloading sacremoses-0.0.53.tar.gz (880 kB)\n",
            "\u001b[K     |████████████████████████████████| 880 kB 55.7 MB/s \n",
            "\u001b[?25hCollecting sentencepiece!=0.1.92\n",
            "  Downloading sentencepiece-0.1.97-cp37-cp37m-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (1.3 MB)\n",
            "\u001b[K     |████████████████████████████████| 1.3 MB 39.8 MB/s \n",
            "\u001b[?25hRequirement already satisfied: pyparsing!=3.0.5,>=2.0.2 in /usr/local/lib/python3.7/dist-packages (from packaging->transformers==3.1.0) (3.0.9)\n",
            "Requirement already satisfied: urllib3!=1.25.0,!=1.25.1,<1.26,>=1.21.1 in /usr/local/lib/python3.7/dist-packages (from requests->transformers==3.1.0) (1.24.3)\n",
            "Requirement already satisfied: chardet<4,>=3.0.2 in /usr/local/lib/python3.7/dist-packages (from requests->transformers==3.1.0) (3.0.4)\n",
            "Requirement already satisfied: idna<3,>=2.5 in /usr/local/lib/python3.7/dist-packages (from requests->transformers==3.1.0) (2.10)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.7/dist-packages (from requests->transformers==3.1.0) (2022.9.24)\n",
            "Requirement already satisfied: six in /usr/local/lib/python3.7/dist-packages (from sacremoses->transformers==3.1.0) (1.15.0)\n",
            "Requirement already satisfied: click in /usr/local/lib/python3.7/dist-packages (from sacremoses->transformers==3.1.0) (7.1.2)\n",
            "Requirement already satisfied: joblib in /usr/local/lib/python3.7/dist-packages (from sacremoses->transformers==3.1.0) (1.2.0)\n",
            "Building wheels for collected packages: sacremoses\n",
            "  Building wheel for sacremoses (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for sacremoses: filename=sacremoses-0.0.53-py3-none-any.whl size=895259 sha256=c2bcd5e806524642ec0b1669c895ede657a48d3909333d23ec000b14870b0fec\n",
            "  Stored in directory: /root/.cache/pip/wheels/87/39/dd/a83eeef36d0bf98e7a4d1933a4ad2d660295a40613079bafc9\n",
            "Successfully built sacremoses\n",
            "Installing collected packages: tokenizers, sentencepiece, sacremoses, transformers\n",
            "Successfully installed sacremoses-0.0.53 sentencepiece-0.1.97 tokenizers-0.8.1rc2 transformers-3.1.0\n"
          ]
        }
      ],
      "source": [
        "!pip install transformers==3.1.0"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Télechagement d'un modèle BERT pré-entrainé. Celui-ci est issue de la base de données SQUAD. \n",
        "uncased= pas de différence entre miniscule et majuscule"
      ],
      "metadata": {
        "id": "z4_6ixUGhMbC"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "import torch\n",
        "from transformers.modeling_camembert import CamembertForQuestionAnswering\n",
        "model_path = 'fmikaelian/camembert-base-fquad'\n",
        "model = CamembertForQuestionAnswering.from_pretrained(model_path)\n",
        "\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 81,
          "referenced_widgets": [
            "fa2637bad7f3479a8824b4fa8c56eade",
            "d9875f17563847a98059dd047b381565",
            "954385ffc41c4acbb72566b54369be93",
            "3f72371b562a419a97edbfc8f63a5bc6",
            "477e9d92653a4ce3ab9875408c66f828",
            "5b12d43ec7ac4555b60d74f973957f48",
            "1ecef767849d46c1a35b985d26236bfa",
            "9bfeca7ff1fc45e5ab6d84ab6e681c54",
            "7d7d03cf17b54731825a26e0256a1d33",
            "8fd055e23f524b589fbe4a513b2b7129",
            "cda43785c1224443be7dfac09da01621",
            "2d32c1f41fa843f4a6755f783f84f91a",
            "1e9322147ece4905ad7e56d162cc8482",
            "16f5d3abe17d4311b2b86c334791bbba",
            "80ae24a6863c4e698dc29f717680e6ad",
            "dd907b38f2d34a18a018831625af44d2",
            "65add8c450c04c269d3c74605f90bc93",
            "213b52f5f93046f580864a0949cc8454",
            "186d75b1b3334b2b9f7977c21cf24a77",
            "f1b24e3e2a224abeb454f8fe9f39ac0e",
            "0291729e8a9c4896bea6338590c86d4a",
            "dfb23221b5974fe798de3431de3db323"
          ]
        },
        "id": "o5MkcjhP-gEr",
        "outputId": "31a2f15b-7535-4969-a5a5-6e8d26bc4141"
      },
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "Downloading:   0%|          | 0.00/517 [00:00<?, ?B/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "fa2637bad7f3479a8824b4fa8c56eade"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "Downloading:   0%|          | 0.00/443M [00:00<?, ?B/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "2d32c1f41fa843f4a6755f783f84f91a"
            }
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from transformers.tokenization_camembert import CamembertTokenizer\n",
        "tokenizer = CamembertTokenizer.from_pretrained(model_path, do_lower_case=True)\n",
        "# Téléchargement d'un tokenizer préentrainé"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 113,
          "referenced_widgets": [
            "b0f01fa5a4ea48a38a84f4e0b35965c0",
            "a33ae09660044b74a9fc04277e511018",
            "3a3f27af5a044c3d9af78093ed8b793d",
            "25d2dca25aec47a389412c98063479f5",
            "f7a81a896c4645f498bffcefd5388adb",
            "d26be6040af64feea417525dd3bd8cf4",
            "ae7d569d77f444aeb6559b14bff7ec69",
            "ea4b328cf9884cbcb2f9ca05a36632c4",
            "a9428d5703c44b37a2607094135afd09",
            "ea0376e6a4ba4e549989c7d7d3b8f540",
            "bb31410a6c134280897a187dd68fb83b",
            "a879cf391aab4530acc68c1a58d1212f",
            "8bf2f44c7afe4932af572eda36dbb8ed",
            "e54b53fa07794ed5b6e4d07f14f9a507",
            "ac7bb5587cae43faa2c63c3dbd5dae79",
            "9b3316dad9924233bc276c485217f973",
            "1ba203692b5f46409e2c023c889b9563",
            "bb893eacf86f4088be19711bcb1ee832",
            "692a3c909be4494b93f0372bab17fcd0",
            "fc313354760c4ad780d27727256db10a",
            "fcb755f7297846169bc59d02ad1f84f5",
            "49dbf1478918462bb6ba42f6f7372f2f",
            "5f7af8ce436645869ef00f1ddb4f8d68",
            "ac39dd1415f04bd88293d16d9063513b",
            "fe35498b5dd844a9b8d364c87718eee0",
            "c94cb8d088cf47bfa62090ae59e7e91a",
            "916c7f4053e04f4994fe5c8aad8bf207",
            "f74e19311bcd40088d2be00d49574d35",
            "65fc4165e68c49138ffbde2cd8212188",
            "ebd7c084f74149e39f42fe75af188721",
            "f28c921c64da4d3cb9d48d115f14f44f",
            "0a86a3489c0f43389b8bc9624cd7320a",
            "f310250a758f4392af50e080b0aef977"
          ]
        },
        "id": "AZx3nbNZ-gG6",
        "outputId": "2fe0bd38-934a-4968-e614-0ce1381aa599"
      },
      "execution_count": 14,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "Downloading:   0%|          | 0.00/811k [00:00<?, ?B/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "b0f01fa5a4ea48a38a84f4e0b35965c0"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "Downloading:   0%|          | 0.00/210 [00:00<?, ?B/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "a879cf391aab4530acc68c1a58d1212f"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "Downloading:   0%|          | 0.00/23.0 [00:00<?, ?B/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "5f7af8ce436645869ef00f1ddb4f8d68"
            }
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "pip install nltk"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "XTWMUhJF-7wz",
        "outputId": "31cd781a-a64a-4d00-cafd-e3ddf5e96434"
      },
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n",
            "Requirement already satisfied: nltk in /usr/local/lib/python3.7/dist-packages (3.7)\n",
            "Requirement already satisfied: click in /usr/local/lib/python3.7/dist-packages (from nltk) (7.1.2)\n",
            "Requirement already satisfied: tqdm in /usr/local/lib/python3.7/dist-packages (from nltk) (4.64.1)\n",
            "Requirement already satisfied: joblib in /usr/local/lib/python3.7/dist-packages (from nltk) (1.2.0)\n",
            "Requirement already satisfied: regex>=2021.8.3 in /usr/local/lib/python3.7/dist-packages (from nltk) (2022.6.2)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Création d'une variable pdf_txt qui contient un texte. Nous pouvons aussi extraire le texte directement d'un pdf comme pour le modele word2vec avec les commandes suivantes: \n",
        "\n",
        "'import pdfplumber\n",
        "\n",
        "pdf = pdfplumber.open('lic_policy.pdf')\n",
        "\n",
        "page = pdf.pages[0]\n",
        "\n",
        "page1 = pdf.pages[1]\n",
        "\n",
        "pdf_txt = page.extract_text() + page1.extract_text()\n",
        "\n",
        "pdf.close()'"
      ],
      "metadata": {
        "id": "iMH1v9_oiKN3"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "pdf_txt= \"\"\" Un chatbot est une application qui peut imiter une vraie conversation avec un utilisateur dans sa langue naturelle. \n",
        "Les chatbots permettent la communication via texte ou audio sur des sites Web, des applications de messagerie, des applications mobiles ou par téléphone.\n",
        " Avec SendPulse, vous pouvez facilement créer un robot conversationnel sans connaissances en programmation et gratuitement.\n",
        " Les chatbots utilisent l'apprentissage machine pour identifier les modèles de communication. \n",
        " Au cours des interactions continues avec les humains, ils apprennent à imiter des conversations réelles et à réagir aux demandes verbales ou écrites, à leur tour, en fournissant un service particulier. \n",
        " Comme les chatbots utilisent l'IA, ils comprennent le langage, pas seulement les commandes. \n",
        " Ainsi, au fur et à mesure qu’ils ont plus de conversations avec les utilisateurs ils deviennent plus intelligents. \n",
        " Il est important de noter qu'en dehors des chatbots basés sur l'IA, il existe des chatbots qui utilisent des scripts à choix multiples; en substance, l'option X mène au chemin Y et ainsi de suite.\n",
        " \"\"\"\n",
        "import nltk\n",
        "nltk.download('punkt')\n",
        "tokens = nltk.sent_tokenize(pdf_txt)\n",
        "for t in tokens:\n",
        "    print(t, \"\\n\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Lw-5_1n0OMT6",
        "outputId": "bf96a127-6eeb-48bb-e93b-d40685db578f"
      },
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[nltk_data] Downloading package punkt to /root/nltk_data...\n",
            "[nltk_data]   Unzipping tokenizers/punkt.zip.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            " Un chatbot est une application qui peut imiter une vraie conversation avec un utilisateur dans sa langue naturelle. \n",
            "\n",
            "Les chatbots permettent la communication via texte ou audio sur des sites Web, des applications de messagerie, des applications mobiles ou par téléphone. \n",
            "\n",
            "Avec SendPulse, vous pouvez facilement créer un robot conversationnel sans connaissances en programmation et gratuitement. \n",
            "\n",
            "Les chatbots utilisent l'apprentissage machine pour identifier les modèles de communication. \n",
            "\n",
            "Au cours des interactions continues avec les humains, ils apprennent à imiter des conversations réelles et à réagir aux demandes verbales ou écrites, à leur tour, en fournissant un service particulier. \n",
            "\n",
            "Comme les chatbots utilisent l'IA, ils comprennent le langage, pas seulement les commandes. \n",
            "\n",
            "Ainsi, au fur et à mesure qu’ils ont plus de conversations avec les utilisateurs ils deviennent plus intelligents. \n",
            "\n",
            "Il est important de noter qu'en dehors des chatbots basés sur l'IA, il existe des chatbots qui utilisent des scripts à choix multiples; en substance, l'option X mène au chemin Y et ainsi de suite. \n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "question = \" Qu'uest ce qu'un chatbot ?\""
      ],
      "metadata": {
        "id": "owNQSXXoH78U"
      },
      "execution_count": 5,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "question1 = \" Comment s'effectue la communication avec un chatbot ?\""
      ],
      "metadata": {
        "id": "S_SbEyeB-gLS"
      },
      "execution_count": 6,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "question2 = \" Comment créer un chatbot facilement ?\""
      ],
      "metadata": {
        "id": "xu8ucLvlH7-r"
      },
      "execution_count": 7,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "question3 = \" Faut-il avoir des connaissances en programmation pour créer un chatbot ?\""
      ],
      "metadata": {
        "id": "qWMSuFEjH8BK"
      },
      "execution_count": 8,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "question4 = \" Avec qui intéragit un chatbot ?\""
      ],
      "metadata": {
        "id": "MeYgCTgrH8F0"
      },
      "execution_count": 9,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "question5 = \" Comment un chatbot devient plus inteligent ?\""
      ],
      "metadata": {
        "id": "3lNlbxX2H8Li"
      },
      "execution_count": 10,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "question6 = \" Tous les chatbots utilisent l'IA ?\""
      ],
      "metadata": {
        "id": "zeAqZClwH8Nz"
      },
      "execution_count": 11,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "question7 = \" Quels sont les différents types de chatbot ?\""
      ],
      "metadata": {
        "id": "BgfxXcSsH8pD"
      },
      "execution_count": 12,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Tokenisation du texte"
      ],
      "metadata": {
        "id": "qFWz20ULjcX4"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "input_ids = tokenizer.encode(question7, pdf_txt, max_length=512, truncation=True)\n",
        "print('The input has a total of {:} tokens.'.format(len(input_ids)))\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "zKzladEf-gNz",
        "outputId": "eac8131b-6ec1-4645-bb9c-49c9bc32cc37"
      },
      "execution_count": 72,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "The input has a total of 228 tokens.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Impression des jetons avec et de leurs identifiants pour voir exactement ce que fait le tokenizer"
      ],
      "metadata": {
        "id": "b1uSeVP7Jaqi"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "tokens = tokenizer.convert_ids_to_tokens(input_ids)\n",
        "for token, id in zip(tokens, input_ids):\n",
        "    if id == tokenizer.sep_token_id:\n",
        "        print('')\n",
        "    print('{:<12} {:>6,}'.format(token, id))\n",
        "\n",
        "    if id == tokenizer.sep_token_id:\n",
        "        print('')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "7Vzj7DY5-gPq",
        "outputId": "7565de96-4e70-4962-fa9b-4a965eec47c5"
      },
      "execution_count": 76,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "<s>               5\n",
            "▁quels        4,880\n",
            "▁sont            56\n",
            "▁les             19\n",
            "▁différents     579\n",
            "▁types        1,756\n",
            "▁de               8\n",
            "▁chat         1,234\n",
            "bot           8,674\n",
            "▁?              106\n",
            "\n",
            "</s>              6\n",
            "\n",
            "\n",
            "</s>              6\n",
            "\n",
            "▁un              23\n",
            "▁chat         1,234\n",
            "bot           8,674\n",
            "▁est             30\n",
            "▁une             28\n",
            "▁application  1,773\n",
            "▁qui             31\n",
            "▁peut           104\n",
            "▁im           4,129\n",
            "iter          8,332\n",
            "▁une             28\n",
            "▁vraie        2,278\n",
            "▁conversation  4,987\n",
            "▁avec            42\n",
            "▁un              23\n",
            "▁utilisateur  5,398\n",
            "▁dans            29\n",
            "▁sa              77\n",
            "▁langue       1,209\n",
            "▁naturelle    2,588\n",
            ".                 9\n",
            "▁les             19\n",
            "▁chat         1,234\n",
            "bot           8,674\n",
            "s                10\n",
            "▁permettent   1,270\n",
            "▁la              13\n",
            "▁communication  1,006\n",
            "▁via            996\n",
            "▁texte          930\n",
            "▁ou              47\n",
            "▁audio        4,465\n",
            "▁sur             32\n",
            "▁des             20\n",
            "▁sites          596\n",
            "▁web            939\n",
            ",                 7\n",
            "▁des             20\n",
            "▁applications  2,592\n",
            "▁de               8\n",
            "▁messagerie   8,804\n",
            ",                 7\n",
            "▁des             20\n",
            "▁applications  2,592\n",
            "▁mobiles      5,044\n",
            "▁ou              47\n",
            "▁par             37\n",
            "▁téléphone    1,116\n",
            ".                 9\n",
            "▁avec            42\n",
            "▁s               52\n",
            "end             904\n",
            "pulse        17,554\n",
            ",                 7\n",
            "▁vous            39\n",
            "▁pouvez         294\n",
            "▁facilement   1,036\n",
            "▁créer          739\n",
            "▁un              23\n",
            "▁robot        6,430\n",
            "▁conversation  4,987\n",
            "nel           2,378\n",
            "▁sans           112\n",
            "▁connaissances  2,107\n",
            "▁en              22\n",
            "▁programmation  4,732\n",
            "▁et              14\n",
            "▁gratuitement  1,903\n",
            ".                 9\n",
            "▁les             19\n",
            "▁chat         1,234\n",
            "bot           8,674\n",
            "s                10\n",
            "▁utilisent    5,496\n",
            "▁l               17\n",
            "'                11\n",
            "apprentissage  3,215\n",
            "▁machine      1,530\n",
            "▁pour            24\n",
            "▁identifier   6,739\n",
            "▁les             19\n",
            "▁modèles      1,501\n",
            "▁de               8\n",
            "▁communication  1,006\n",
            ".                 9\n",
            "▁au              36\n",
            "▁cours          307\n",
            "▁des             20\n",
            "▁interactions 13,087\n",
            "▁continue     1,439\n",
            "s                10\n",
            "▁avec            42\n",
            "▁les             19\n",
            "▁humains      2,520\n",
            ",                 7\n",
            "▁ils            220\n",
            "▁apprennent  18,984\n",
            "▁à               15\n",
            "▁im           4,129\n",
            "iter          8,332\n",
            "▁des             20\n",
            "▁conversations 14,232\n",
            "▁réelles     10,244\n",
            "▁et              14\n",
            "▁à               15\n",
            "▁réagir       6,152\n",
            "▁aux             68\n",
            "▁demandes     3,083\n",
            "▁verbale     17,963\n",
            "s                10\n",
            "▁ou              47\n",
            "▁écrites     15,266\n",
            ",                 7\n",
            "▁à               15\n",
            "▁leur            97\n",
            "▁tour           508\n",
            ",                 7\n",
            "▁en              22\n",
            "▁fournissant 21,270\n",
            "▁un              23\n",
            "▁service        366\n",
            "▁particulier    770\n",
            ".                 9\n",
            "▁comme           79\n",
            "▁les             19\n",
            "▁chat         1,234\n",
            "bot           8,674\n",
            "s                10\n",
            "▁utilisent    5,496\n",
            "▁l               17\n",
            "'                11\n",
            "ia            1,035\n",
            ",                 7\n",
            "▁ils            220\n",
            "▁comprennent  6,758\n",
            "▁le              16\n",
            "▁langage      3,015\n",
            ",                 7\n",
            "▁pas             34\n",
            "▁seulement      446\n",
            "▁les             19\n",
            "▁commandes    3,963\n",
            ".                 9\n",
            "▁ainsi          163\n",
            ",                 7\n",
            "▁au              36\n",
            "▁fur          4,148\n",
            "▁et              14\n",
            "▁à               15\n",
            "▁mesure         586\n",
            "▁qu              46\n",
            "’                12\n",
            "ils             240\n",
            "▁ont             96\n",
            "▁plus            40\n",
            "▁de               8\n",
            "▁conversations 14,232\n",
            "▁avec            42\n",
            "▁les             19\n",
            "▁utilisateurs  1,827\n",
            "▁ils            220\n",
            "▁deviennent   4,968\n",
            "▁plus            40\n",
            "▁intelligents 18,447\n",
            ".                 9\n",
            "▁il              51\n",
            "▁est             30\n",
            "▁important      693\n",
            "▁de               8\n",
            "▁noter        2,287\n",
            "▁qu              46\n",
            "'                11\n",
            "en               90\n",
            "▁dehors       2,058\n",
            "▁des             20\n",
            "▁chat         1,234\n",
            "bot           8,674\n",
            "s                10\n",
            "▁basés       17,966\n",
            "▁sur             32\n",
            "▁l               17\n",
            "'                11\n",
            "ia            1,035\n",
            ",                 7\n",
            "▁il              51\n",
            "▁existe         947\n",
            "▁des             20\n",
            "▁chat         1,234\n",
            "bot           8,674\n",
            "s                10\n",
            "▁qui             31\n",
            "▁utilisent    5,496\n",
            "▁des             20\n",
            "▁script      10,936\n",
            "s                10\n",
            "▁à               15\n",
            "▁choix          414\n",
            "▁multiples    2,523\n",
            ";               154\n",
            "▁en              22\n",
            "▁substance    9,152\n",
            ",                 7\n",
            "▁l               17\n",
            "'                11\n",
            "option        4,932\n",
            "▁x              758\n",
            "▁mène         5,242\n",
            "▁au              36\n",
            "▁chemin       1,111\n",
            "▁y              102\n",
            "▁et              14\n",
            "▁ainsi          163\n",
            "▁de               8\n",
            "▁suite          282\n",
            ".                 9\n",
            "\n",
            "</s>              6\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "La question et pdf_txt ( le texte) peuvent être concatener ensemble, mais BERT a toujours besoin d'un moyen de les distinguer. BERT a deux encastrements spéciaux \"Segment\", un pour le segment \"A\" et un pour le segment \"B\". Avant que les intégrations de mots n'entrent dans les couches BERT, l'intégration du segment A doit être ajoutée aux jetons de question, et l'intégration du segment B doit être ajoutée à chacun des jetons answer_text.\n",
        "Celles-ci sont gérées par la bibliothèque de transformateurs et tout ce que nous avons à faire est de spécifier '0' et '1' pour le jeton."
      ],
      "metadata": {
        "id": "PKM1QqEqkMnb"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "sep_index = input_ids.index(tokenizer.sep_token_id)\n",
        "num_seg_a = sep_index + 1\n",
        "num_seg_b = len(input_ids) - num_seg_a\n",
        "#Here We Construct the list of 0s and 1s.\n",
        "segment_ids = [0]*num_seg_a + [1]*num_seg_b\n",
        "# There should be a segment_id for every input token.\n",
        "assert len(segment_ids) == len(input_ids)"
      ],
      "metadata": {
        "id": "rXRziKnT_R63"
      },
      "execution_count": 77,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Ici, nous alimentons pdf_txt et la question dans le modèle"
      ],
      "metadata": {
        "id": "jwNaIzvHkh48"
      }
    },
    {
      "cell_type": "code",
      "source": [
        " \n",
        "start_scores, end_scores = model(torch.tensor([input_ids]))\n",
        "#start_scores, end_scores = model(torch.tensor([input_ids]), token_type_ids=torch.tensor([segment_ids]))"
      ],
      "metadata": {
        "id": "c8G6BYtQ_R9O"
      },
      "execution_count": 83,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Ici, nous trouvons les scores 'début' et 'fin' les plus élevés et combinons les jetons dans la réponse et imprimons la réponse"
      ],
      "metadata": {
        "id": "ZL7v2T5ekuNJ"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "answer_start = torch.argmax(start_scores)\n",
        "answer_end = torch.argmax(end_scores)\n",
        "\n",
        "answer = ' '.join(tokens[answer_start:answer_end+1])\n",
        "print ('Question \"' + question4 + '\"' )\n",
        "print('Answer: \"' + answer + '\"')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "orl2LjX-_R_v",
        "outputId": "b7bbc5b9-adb1-4345-b189-93cf9bc16760"
      },
      "execution_count": 84,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Question \" Avec qui intéragit un chatbot ?\"\n",
            "Answer: \"<s>\"\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Nous pouvons reconstruire tous les mots qui ont été décomposés en sous-mots."
      ],
      "metadata": {
        "id": "HMlmuXm-k39L"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "answer = tokens[answer_start]\n",
        "answer = tokens[answer_start]\n",
        "\n",
        "# Select the remaining answer tokens and join them with whitespace.\n",
        "for i in range(answer_start + 1, answer_end + 1):\n",
        "  # If it's a subword token, then recombine it with the previous token.\n",
        "    if tokens[i][0:2] == '##':\n",
        "        answer += tokens[i][2:]\n",
        "        # Otherwise, add a space then the token.\n",
        "    else:\n",
        "        answer += ' ' + tokens[i]\n",
        "print('Answer: \"' + answer + '\"')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Dakizn0cBWiP",
        "outputId": "06e779d9-e7b9-4c23-a554-70a1964a718a"
      },
      "execution_count": 85,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Answer: \"<s>\"\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Cette partie est une fonction regroupant les commandes précédentes"
      ],
      "metadata": {
        "id": "flrSsB41lDDY"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def answer_question(question, pdf_txt):\n",
        "\n",
        "    input_ids = tokenizer.encode(question, pdf_txt, max_length=512, truncation=True)\n",
        "\n",
        "    print('Query has {:,} tokens.\\n'.format(len(input_ids)))\n",
        "\n",
        "    sep_index = input_ids.index(tokenizer.sep_token_id)\n",
        "\n",
        "    num_seg_a = sep_index + 1\n",
        "\n",
        "    num_seg_b = len(input_ids) - num_seg_a\n",
        "\n",
        "    segment_ids = [0]*num_seg_a + [1]*num_seg_b\n",
        "\n",
        "    assert len(segment_ids) == len(input_ids)\n",
        "\n",
        "    start_scores, end_scores = model(torch.tensor([input_ids]))\n",
        "    # start_scores, end_scores = model(torch.tensor([input_ids]), token_type_ids=torch.tensor([segment_ids]))\n",
        "\n",
        "\n",
        "    all_tokens = tokenizer.convert_ids_to_tokens(input_ids)\n",
        "\n",
        "    #print(' '.join(all_tokens[torch.argmax(start_scores) : torch.argmax(end_scores)+1]))\n",
        "    #print(f'score: {torch.max(start_scores)}')\n",
        "    score = float(torch.max(start_scores))\n",
        "    answer_start = torch.argmax(start_scores)\n",
        "    answer_end = torch.argmax(end_scores)\n",
        "    tokens = tokenizer.convert_ids_to_tokens(input_ids)\n",
        "    answer = tokens[answer_start]\n",
        "\n",
        "    for i in range(answer_start + 1, answer_end + 1):\n",
        "\n",
        "        if tokens[i][0:2] == ' ':\n",
        "            answer += tokens[i][2:]\n",
        "\n",
        "        else:\n",
        "            answer += ' ' + tokens[i]\n",
        "    return question, answer, score\n",
        "    print('Answer: \"' + answer + '\"')"
      ],
      "metadata": {
        "id": "qyQJ5SrL_SEJ"
      },
      "execution_count": 91,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# On applique la fonction sur la question et le texte pour obtenir une réponse\n",
        "answer_question(question2, pdf_txt)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "quWSkKNX_byx",
        "outputId": "f9a2421a-6aeb-4771-e4eb-977804d26fbb"
      },
      "execution_count": 93,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Query has 226 tokens.\n",
            "\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(' Comment créer un chatbot facilement ?',\n",
              " '▁s end pulse , ▁vous ▁pouvez ▁facilement ▁créer ▁un ▁robot ▁conversation nel ▁sans ▁connaissances ▁en ▁programmation ▁et ▁gratuitement',\n",
              " 4.8556928634643555)"
            ]
          },
          "metadata": {},
          "execution_count": 93
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "* Ici, nous utilisons la méthode tokenizers encode_plus pour créer nos jetons à partir de la chaîne de texte\n",
        "* add_special_tokens=True ajoute des jetons BERT spéciaux comme [CLS], [SEP] et [PAD] à nos nouveaux encodages \"tokénisés\"\n",
        "* max_length=512 indique à l'encodeur la longueur cible de nos encodages\n",
        "* truncation=True garantit que nous coupons toutes les séquences qui sont plus longues que le\n",
        "max_length spécifié.\n",
        "* padding=\"max_length\" indique à l'encodeur de remplir toutes les séquences plus courtes que le max_length avec des jetons de remplissage."
      ],
      "metadata": {
        "id": "bJGcCShXlfw0"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "tokens = tokenizer.encode_plus(question, pdf_txt, add_special_tokens=True, max_length=512, truncation=True, padding=\"max_length\")\n",
        "tokens"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "HzYIVilC_b1h",
        "outputId": "53fe58d6-91ca-45eb-fcd3-923e12540e4f"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "{'input_ids': [5, 404, 52, 11, 10170, 13, 1006, 42, 23, 1234, 8674, 106, 6, 6, 23, 1234, 8674, 30, 28, 1773, 31, 104, 4129, 8332, 28, 2278, 4987, 42, 23, 5398, 29, 77, 1209, 2588, 9, 19, 1234, 8674, 10, 1270, 13, 1006, 996, 930, 47, 4465, 32, 20, 596, 939, 7, 20, 2592, 8, 8804, 7, 20, 2592, 5044, 47, 37, 1116, 9, 42, 52, 904, 17554, 7, 39, 294, 1036, 739, 23, 6430, 4987, 2378, 112, 2107, 22, 4732, 14, 1903, 9, 19, 1234, 8674, 10, 5496, 17, 11, 3215, 1530, 24, 6739, 19, 1501, 8, 1006, 9, 36, 307, 20, 13087, 1439, 10, 42, 19, 2520, 7, 220, 18984, 15, 4129, 8332, 20, 14232, 10244, 14, 15, 6152, 68, 3083, 17963, 10, 47, 15266, 7, 15, 97, 508, 7, 22, 21270, 23, 366, 770, 9, 79, 19, 1234, 8674, 10, 5496, 17, 11, 1035, 7, 220, 6758, 16, 3015, 7, 34, 446, 19, 3963, 9, 163, 7, 36, 4148, 14, 15, 586, 46, 12, 240, 96, 40, 8, 14232, 42, 19, 1827, 220, 4968, 40, 18447, 9, 51, 30, 693, 8, 2287, 46, 11, 90, 2058, 20, 1234, 8674, 10, 17966, 32, 17, 11, 1035, 7, 51, 947, 20, 1234, 8674, 10, 31, 5496, 20, 10936, 10, 15, 414, 2523, 154, 22, 9152, 7, 17, 11, 4932, 758, 5242, 36, 1111, 102, 14, 163, 8, 282, 9, 6, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1], 'attention_mask': [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]}"
            ]
          },
          "metadata": {},
          "execution_count": 17
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Il renvoie un dictionnaire contenant trois paires clé-valeur, input_ids,\n",
        "token_type_ids et attention_mask .\n",
        "Nous avons également ajouté return_tensors='pt' pour renvoyer les tenseurs PyTorch du\n",
        "tokenizer (plutôt que des listes Python)."
      ],
      "metadata": {
        "id": "oX3FZNVrlx5j"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "tokens = tokenizer.encode_plus(pdf_txt, add_special_tokens=False, return_tensors='pt')\n",
        "tokens"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "X3ae8IAkFVBF",
        "outputId": "ef135fc2-4058-41e0-e90b-70887bff7771"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "{'input_ids': tensor([[   23,  1234,  8674,    30,    28,  1773,    31,   104,  4129,  8332,\n",
              "            28,  2278,  4987,    42,    23,  5398,    29,    77,  1209,  2588,\n",
              "             9,    19,  1234,  8674,    10,  1270,    13,  1006,   996,   930,\n",
              "            47,  4465,    32,    20,   596,   939,     7,    20,  2592,     8,\n",
              "          8804,     7,    20,  2592,  5044,    47,    37,  1116,     9,    42,\n",
              "            52,   904, 17554,     7,    39,   294,  1036,   739,    23,  6430,\n",
              "          4987,  2378,   112,  2107,    22,  4732,    14,  1903,     9,    19,\n",
              "          1234,  8674,    10,  5496,    17,    11,  3215,  1530,    24,  6739,\n",
              "            19,  1501,     8,  1006,     9,    36,   307,    20, 13087,  1439,\n",
              "            10,    42,    19,  2520,     7,   220, 18984,    15,  4129,  8332,\n",
              "            20, 14232, 10244,    14,    15,  6152,    68,  3083, 17963,    10,\n",
              "            47, 15266,     7,    15,    97,   508,     7,    22, 21270,    23,\n",
              "           366,   770,     9,    79,    19,  1234,  8674,    10,  5496,    17,\n",
              "            11,  1035,     7,   220,  6758,    16,  3015,     7,    34,   446,\n",
              "            19,  3963,     9,   163,     7,    36,  4148,    14,    15,   586,\n",
              "            46,    12,   240,    96,    40,     8, 14232,    42,    19,  1827,\n",
              "           220,  4968,    40, 18447,     9,    51,    30,   693,     8,  2287,\n",
              "            46,    11,    90,  2058,    20,  1234,  8674,    10, 17966,    32,\n",
              "            17,    11,  1035,     7,    51,   947,    20,  1234,  8674,    10,\n",
              "            31,  5496,    20, 10936,    10,    15,   414,  2523,   154,    22,\n",
              "          9152,     7,    17,    11,  4932,   758,  5242,    36,  1111,   102,\n",
              "            14,   163,     8,   282,     9]]), 'attention_mask': tensor([[1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
              "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
              "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
              "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
              "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
              "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
              "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
              "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
              "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1]])}"
            ]
          },
          "metadata": {},
          "execution_count": 18
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "input_id_chunks = tokens['input_ids'][0].split(510)\n",
        "mask_chunks = tokens['attention_mask'][0].split(510)\n",
        "\n",
        "for tensor in input_id_chunks:\n",
        "  print(len(tensor))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "qGjPLBWz_b4S",
        "outputId": "beb17d4f-596a-4cb6-8d51-ca1a15537a63"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "215\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "a = torch.arange(10)\n",
        "a"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "jcFJOS2V_b6p",
        "outputId": "9825ec44-a3b1-4b86-e718-cb2e6b9fcbb9"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "tensor([0, 1, 2, 3, 4, 5, 6, 7, 8, 9])"
            ]
          },
          "metadata": {},
          "execution_count": 20
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "torch.cat(\n",
        "    [torch.Tensor([101]), a, torch.Tensor([102])]\n",
        ")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "44yegsjJ_b9J",
        "outputId": "191d8e14-507e-46ba-a232-fd32ac0a0efc"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "tensor([101.,   0.,   1.,   2.,   3.,   4.,   5.,   6.,   7.,   8.,   9., 102.])"
            ]
          },
          "metadata": {},
          "execution_count": 21
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "***Préparer les morceaux***\n",
        "\n",
        "Nous avons maintenant notre tenseur tokenisé ; nous devons le diviser en morceaux ne dépassant pas 510 jetons. Nous choisissons 510 plutôt que 512 pour laisser deux places libres pour ajouter nos jetons [CLS] et [SEP].\n",
        "\n",
        "***Diviser***\n",
        "\n",
        "\n",
        "Nous appliquons la méthode de fractionnement à la fois à nos ID d'entrée et aux tenseurs de masque d'attention (nous\n",
        "n'ont pas besoin des ID de type de jeton et peuvent les supprimer). Nous avons maintenant trois morceaux pour chaque ensemble de tenseurs. Notez que nous devrons ajouter un rembourrage au dernier morceau car il ne satisfera pas la taille de tenseur de 512 requise par BERT.\n",
        "\n",
        "\n",
        "***CLS et SEP***\n",
        "\n",
        "\n",
        "Ensuite, nous ajoutons les jetons de début de séquence [CLS] et de séparateur [SEP]. Pour cela, nous pouvons utiliser la fonction torch.cat, qui concatène une liste de tenseurs.\n",
        "Nos jetons sont déjà au format d'identification de jeton, nous pouvons donc nous référer aux jetons spéciaux\n",
        "tableau ci-dessus pour créer les versions d'ID de jeton de nos jetons [CLS] et [SEP].\n",
        "Parce que nous faisons cela pour plusieurs tenseurs, nous plaçons la fonction torch.cat dans\n",
        "une boucle for et effectuer la concaténation pour chacun de nos morceaux individuellement.\n",
        "De plus, nos blocs de masque d'attention sont concaténés avec des 1 au lieu de 101\n",
        "et 102. Nous faisons cela parce que le masque d'attention ne contient pas d'ID de jeton mais\n",
        "à la place un ensemble de 1 et de 0.\n",
        "Les zéros dans le masque d'attention représentent l'emplacement des jetons de remplissage (que nous allons\n",
        "add next), et comme [CLS] et [SEP] ne sont pas des jetons de remplissage, ils sont représentés\n",
        "avec 1s.\n",
        "\n",
        "***Rembourrage***\n",
        "\n",
        "\n",
        "Nous devons ajouter un rembourrage à nos morceaux de tenseur pour nous assurer qu'ils satisfont à la longueur de tenseur de 512 requise par BERT. Nos deux premiers morceaux ne nécessitent aucun rembourrage car ils satisfont déjà à cette exigence de longueur, mais les derniers morceaux le font.\n",
        "Pour vérifier si un morceau nécessite un remplissage, nous ajoutons une instruction if qui vérifie la longueur du tenseur. Si le tenseur est plus court que 512 jetons, nous ajoutons un rembourrage à l'aide de la fonction torch.cat. Nous devrions ajouter cette déclaration à la même boucle for où nous ajoutons nos jetons [CLS] et [SEP] - si vous avez besoin d'aide, j'ai inclus les scripts complets à la fin de l'article."
      ],
      "metadata": {
        "id": "-NLeJsganP-Z"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "chunksize = 512\n",
        "\n",
        "input_id_chunks = list(tokens['input_ids'][0].split(chunksize - 2))\n",
        "mask_chunks = list(tokens['attention_mask'][0].split(chunksize - 2))\n",
        "\n",
        "for i in range(len(input_id_chunks)):\n",
        "    input_id_chunks[i] = torch.cat([\n",
        "        torch.tensor([101]), input_id_chunks[i], torch.tensor([102])\n",
        "    ])\n",
        "    mask_chunks[i] = torch.cat([\n",
        "        torch.tensor([1]), mask_chunks[i], torch.tensor([1])\n",
        "    ])\n",
        "\n",
        "    pad_len = chunksize - input_id_chunks[i].shape[0]\n",
        "    if pad_len > 0:\n",
        "        input_id_chunks[i] = torch.cat([\n",
        "            input_id_chunks[i], torch.Tensor([0] * pad_len)\n",
        "        ])\n",
        "        mask_chunks[i] = torch.cat([\n",
        "            mask_chunks[i], torch.Tensor([0] * pad_len)\n",
        "        ])\n",
        "\n",
        "for chunk in input_id_chunks:\n",
        "    print(chunk)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "JSG7d6xs_cAJ",
        "outputId": "baaf1006-2bb9-4c20-f8bb-c67b365b21c5"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "tensor([1.0100e+02, 2.3000e+01, 1.2340e+03, 8.6740e+03, 3.0000e+01, 2.8000e+01,\n",
            "        1.7730e+03, 3.1000e+01, 1.0400e+02, 4.1290e+03, 8.3320e+03, 2.8000e+01,\n",
            "        2.2780e+03, 4.9870e+03, 4.2000e+01, 2.3000e+01, 5.3980e+03, 2.9000e+01,\n",
            "        7.7000e+01, 1.2090e+03, 2.5880e+03, 9.0000e+00, 1.9000e+01, 1.2340e+03,\n",
            "        8.6740e+03, 1.0000e+01, 1.2700e+03, 1.3000e+01, 1.0060e+03, 9.9600e+02,\n",
            "        9.3000e+02, 4.7000e+01, 4.4650e+03, 3.2000e+01, 2.0000e+01, 5.9600e+02,\n",
            "        9.3900e+02, 7.0000e+00, 2.0000e+01, 2.5920e+03, 8.0000e+00, 8.8040e+03,\n",
            "        7.0000e+00, 2.0000e+01, 2.5920e+03, 5.0440e+03, 4.7000e+01, 3.7000e+01,\n",
            "        1.1160e+03, 9.0000e+00, 4.2000e+01, 5.2000e+01, 9.0400e+02, 1.7554e+04,\n",
            "        7.0000e+00, 3.9000e+01, 2.9400e+02, 1.0360e+03, 7.3900e+02, 2.3000e+01,\n",
            "        6.4300e+03, 4.9870e+03, 2.3780e+03, 1.1200e+02, 2.1070e+03, 2.2000e+01,\n",
            "        4.7320e+03, 1.4000e+01, 1.9030e+03, 9.0000e+00, 1.9000e+01, 1.2340e+03,\n",
            "        8.6740e+03, 1.0000e+01, 5.4960e+03, 1.7000e+01, 1.1000e+01, 3.2150e+03,\n",
            "        1.5300e+03, 2.4000e+01, 6.7390e+03, 1.9000e+01, 1.5010e+03, 8.0000e+00,\n",
            "        1.0060e+03, 9.0000e+00, 3.6000e+01, 3.0700e+02, 2.0000e+01, 1.3087e+04,\n",
            "        1.4390e+03, 1.0000e+01, 4.2000e+01, 1.9000e+01, 2.5200e+03, 7.0000e+00,\n",
            "        2.2000e+02, 1.8984e+04, 1.5000e+01, 4.1290e+03, 8.3320e+03, 2.0000e+01,\n",
            "        1.4232e+04, 1.0244e+04, 1.4000e+01, 1.5000e+01, 6.1520e+03, 6.8000e+01,\n",
            "        3.0830e+03, 1.7963e+04, 1.0000e+01, 4.7000e+01, 1.5266e+04, 7.0000e+00,\n",
            "        1.5000e+01, 9.7000e+01, 5.0800e+02, 7.0000e+00, 2.2000e+01, 2.1270e+04,\n",
            "        2.3000e+01, 3.6600e+02, 7.7000e+02, 9.0000e+00, 7.9000e+01, 1.9000e+01,\n",
            "        1.2340e+03, 8.6740e+03, 1.0000e+01, 5.4960e+03, 1.7000e+01, 1.1000e+01,\n",
            "        1.0350e+03, 7.0000e+00, 2.2000e+02, 6.7580e+03, 1.6000e+01, 3.0150e+03,\n",
            "        7.0000e+00, 3.4000e+01, 4.4600e+02, 1.9000e+01, 3.9630e+03, 9.0000e+00,\n",
            "        1.6300e+02, 7.0000e+00, 3.6000e+01, 4.1480e+03, 1.4000e+01, 1.5000e+01,\n",
            "        5.8600e+02, 4.6000e+01, 1.2000e+01, 2.4000e+02, 9.6000e+01, 4.0000e+01,\n",
            "        8.0000e+00, 1.4232e+04, 4.2000e+01, 1.9000e+01, 1.8270e+03, 2.2000e+02,\n",
            "        4.9680e+03, 4.0000e+01, 1.8447e+04, 9.0000e+00, 5.1000e+01, 3.0000e+01,\n",
            "        6.9300e+02, 8.0000e+00, 2.2870e+03, 4.6000e+01, 1.1000e+01, 9.0000e+01,\n",
            "        2.0580e+03, 2.0000e+01, 1.2340e+03, 8.6740e+03, 1.0000e+01, 1.7966e+04,\n",
            "        3.2000e+01, 1.7000e+01, 1.1000e+01, 1.0350e+03, 7.0000e+00, 5.1000e+01,\n",
            "        9.4700e+02, 2.0000e+01, 1.2340e+03, 8.6740e+03, 1.0000e+01, 3.1000e+01,\n",
            "        5.4960e+03, 2.0000e+01, 1.0936e+04, 1.0000e+01, 1.5000e+01, 4.1400e+02,\n",
            "        2.5230e+03, 1.5400e+02, 2.2000e+01, 9.1520e+03, 7.0000e+00, 1.7000e+01,\n",
            "        1.1000e+01, 4.9320e+03, 7.5800e+02, 5.2420e+03, 3.6000e+01, 1.1110e+03,\n",
            "        1.0200e+02, 1.4000e+01, 1.6300e+02, 8.0000e+00, 2.8200e+02, 9.0000e+00,\n",
            "        1.0200e+02, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00,\n",
            "        0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00,\n",
            "        0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00,\n",
            "        0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00,\n",
            "        0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00,\n",
            "        0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00,\n",
            "        0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00,\n",
            "        0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00,\n",
            "        0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00,\n",
            "        0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00,\n",
            "        0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00,\n",
            "        0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00,\n",
            "        0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00,\n",
            "        0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00,\n",
            "        0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00,\n",
            "        0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00,\n",
            "        0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00,\n",
            "        0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00,\n",
            "        0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00,\n",
            "        0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00,\n",
            "        0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00,\n",
            "        0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00,\n",
            "        0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00,\n",
            "        0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00,\n",
            "        0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00,\n",
            "        0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00,\n",
            "        0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00,\n",
            "        0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00,\n",
            "        0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00,\n",
            "        0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00,\n",
            "        0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00,\n",
            "        0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00,\n",
            "        0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00,\n",
            "        0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00,\n",
            "        0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00,\n",
            "        0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00,\n",
            "        0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00,\n",
            "        0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00,\n",
            "        0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00,\n",
            "        0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00,\n",
            "        0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00,\n",
            "        0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00,\n",
            "        0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00,\n",
            "        0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00,\n",
            "        0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00,\n",
            "        0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00,\n",
            "        0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00,\n",
            "        0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00,\n",
            "        0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00,\n",
            "        0.0000e+00, 0.0000e+00])\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "for tensor in range(len(input_id_chunks)):\n",
        "  ans = answer_question(question, ' '.join(tokenizer.convert_ids_to_tokens(input_id_chunks[tensor])))\n",
        "  print(ans)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 380
        },
        "id": "lx5Ydiwz_cG5",
        "outputId": "73be82c0-5082-494a-a903-4c76da1b04c3"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Query has 512 tokens.\n",
            "\n"
          ]
        },
        {
          "output_type": "error",
          "ename": "IndexError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mIndexError\u001b[0m                                Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-23-e21fbf35de72>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mtensor\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mrange\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minput_id_chunks\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 2\u001b[0;31m   \u001b[0mans\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0manswer_question\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mquestion\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m' '\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mjoin\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtokenizer\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mconvert_ids_to_tokens\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minput_id_chunks\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mtensor\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      3\u001b[0m   \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mans\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m<ipython-input-15-45d13885f70d>\u001b[0m in \u001b[0;36manswer_question\u001b[0;34m(question, pdf_txt)\u001b[0m\n\u001b[1;32m     15\u001b[0m     \u001b[0;32massert\u001b[0m \u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msegment_ids\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minput_ids\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     16\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 17\u001b[0;31m     \u001b[0mstart_scores\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mend_scores\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtensor\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0minput_ids\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtoken_type_ids\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtensor\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0msegment_ids\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     18\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     19\u001b[0m     \u001b[0mall_tokens\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtokenizer\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mconvert_ids_to_tokens\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minput_ids\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_call_impl\u001b[0;34m(self, *input, **kwargs)\u001b[0m\n\u001b[1;32m   1128\u001b[0m         if not (self._backward_hooks or self._forward_hooks or self._forward_pre_hooks or _global_backward_hooks\n\u001b[1;32m   1129\u001b[0m                 or _global_forward_hooks or _global_forward_pre_hooks):\n\u001b[0;32m-> 1130\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mforward_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1131\u001b[0m         \u001b[0;31m# Do not call functions when jit is used\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1132\u001b[0m         \u001b[0mfull_backward_hooks\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnon_full_backward_hooks\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/transformers/modeling_roberta.py\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, input_ids, attention_mask, token_type_ids, position_ids, head_mask, inputs_embeds, start_positions, end_positions, output_attentions, output_hidden_states, return_dict)\u001b[0m\n\u001b[1;32m    763\u001b[0m             \u001b[0moutput_attentions\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0moutput_attentions\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    764\u001b[0m             \u001b[0moutput_hidden_states\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0moutput_hidden_states\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 765\u001b[0;31m             \u001b[0mreturn_dict\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mreturn_dict\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    766\u001b[0m         )\n\u001b[1;32m    767\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_call_impl\u001b[0;34m(self, *input, **kwargs)\u001b[0m\n\u001b[1;32m   1128\u001b[0m         if not (self._backward_hooks or self._forward_hooks or self._forward_pre_hooks or _global_backward_hooks\n\u001b[1;32m   1129\u001b[0m                 or _global_forward_hooks or _global_forward_pre_hooks):\n\u001b[0;32m-> 1130\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mforward_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1131\u001b[0m         \u001b[0;31m# Do not call functions when jit is used\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1132\u001b[0m         \u001b[0mfull_backward_hooks\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnon_full_backward_hooks\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/transformers/modeling_bert.py\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, input_ids, attention_mask, token_type_ids, position_ids, head_mask, inputs_embeds, encoder_hidden_states, encoder_attention_mask, output_attentions, output_hidden_states, return_dict)\u001b[0m\n\u001b[1;32m    823\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    824\u001b[0m         embedding_output = self.embeddings(\n\u001b[0;32m--> 825\u001b[0;31m             \u001b[0minput_ids\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0minput_ids\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mposition_ids\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mposition_ids\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtoken_type_ids\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mtoken_type_ids\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minputs_embeds\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0minputs_embeds\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    826\u001b[0m         )\n\u001b[1;32m    827\u001b[0m         encoder_outputs = self.encoder(\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_call_impl\u001b[0;34m(self, *input, **kwargs)\u001b[0m\n\u001b[1;32m   1128\u001b[0m         if not (self._backward_hooks or self._forward_hooks or self._forward_pre_hooks or _global_backward_hooks\n\u001b[1;32m   1129\u001b[0m                 or _global_forward_hooks or _global_forward_pre_hooks):\n\u001b[0;32m-> 1130\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mforward_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1131\u001b[0m         \u001b[0;31m# Do not call functions when jit is used\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1132\u001b[0m         \u001b[0mfull_backward_hooks\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnon_full_backward_hooks\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/transformers/modeling_roberta.py\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, input_ids, token_type_ids, position_ids, inputs_embeds)\u001b[0m\n\u001b[1;32m     80\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     81\u001b[0m         return super().forward(\n\u001b[0;32m---> 82\u001b[0;31m             \u001b[0minput_ids\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtoken_type_ids\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mtoken_type_ids\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mposition_ids\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mposition_ids\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minputs_embeds\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0minputs_embeds\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     83\u001b[0m         )\n\u001b[1;32m     84\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/transformers/modeling_bert.py\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, input_ids, token_type_ids, position_ids, inputs_embeds)\u001b[0m\n\u001b[1;32m    207\u001b[0m             \u001b[0minputs_embeds\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mword_embeddings\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minput_ids\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    208\u001b[0m         \u001b[0mposition_embeddings\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mposition_embeddings\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mposition_ids\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 209\u001b[0;31m         \u001b[0mtoken_type_embeddings\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtoken_type_embeddings\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtoken_type_ids\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    210\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    211\u001b[0m         \u001b[0membeddings\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0minputs_embeds\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0mposition_embeddings\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0mtoken_type_embeddings\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_call_impl\u001b[0;34m(self, *input, **kwargs)\u001b[0m\n\u001b[1;32m   1128\u001b[0m         if not (self._backward_hooks or self._forward_hooks or self._forward_pre_hooks or _global_backward_hooks\n\u001b[1;32m   1129\u001b[0m                 or _global_forward_hooks or _global_forward_pre_hooks):\n\u001b[0;32m-> 1130\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mforward_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1131\u001b[0m         \u001b[0;31m# Do not call functions when jit is used\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1132\u001b[0m         \u001b[0mfull_backward_hooks\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnon_full_backward_hooks\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/torch/nn/modules/sparse.py\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, input)\u001b[0m\n\u001b[1;32m    158\u001b[0m         return F.embedding(\n\u001b[1;32m    159\u001b[0m             \u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mweight\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpadding_idx\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmax_norm\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 160\u001b[0;31m             self.norm_type, self.scale_grad_by_freq, self.sparse)\n\u001b[0m\u001b[1;32m    161\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    162\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mextra_repr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m->\u001b[0m \u001b[0mstr\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/torch/nn/functional.py\u001b[0m in \u001b[0;36membedding\u001b[0;34m(input, weight, padding_idx, max_norm, norm_type, scale_grad_by_freq, sparse)\u001b[0m\n\u001b[1;32m   2197\u001b[0m         \u001b[0;31m# remove once script supports set_grad_enabled\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2198\u001b[0m         \u001b[0m_no_grad_embedding_renorm_\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mweight\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmax_norm\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnorm_type\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 2199\u001b[0;31m     \u001b[0;32mreturn\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0membedding\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mweight\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mpadding_idx\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mscale_grad_by_freq\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msparse\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   2200\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2201\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mIndexError\u001b[0m: index out of range in self"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "def expand_split_sentences(pdf_txt):\n",
        "  import nltk\n",
        "  nltk.download('punkt')\n",
        "  new_chunks = nltk.sent_tokenize(pdf_txt)\n",
        "  length = len(new_chunks)\n",
        "  #for i in range(length):\n",
        "    #tmp_token = tokenizer.encode(new_chunks[i])\n",
        "    #print('The input has a total of {:} tokens.'.format(len(tmp_token)))\n",
        "\n",
        "  new_df = [];\n",
        "  for i in range(length):\n",
        "    paragraph = \"\"\n",
        "    for j in range(i, length):\n",
        "      #tmp_str = paragraph + new_chunks[j]\n",
        "      tmp_token = tokenizer.encode(paragraph + new_chunks[j])\n",
        "      length_token = len(tmp_token)\n",
        "      if length_token < 510:\n",
        "        #print(length_token)\n",
        "        paragraph = paragraph + new_chunks[j]\n",
        "      else:\n",
        "        #print(length_token)\n",
        "        break;\n",
        "    #print(len(tokenizer.encode(paragraph)))\n",
        "    new_df.append(paragraph)\n",
        "  return new_df\n",
        "  #for i in new_df:\n",
        "    #print(i)"
      ],
      "metadata": {
        "id": "7ahE9X5AEydV"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "max_score = 0;\n",
        "final_answer = \"\"\n",
        "new_df = expand_split_sentences(pdf_txt)\n",
        "for new_context in new_df:\n",
        "  #new_paragrapgh = new_paragrapgh + answer_question(question, answer_text)\n",
        "  ans, score = answer_question(question, new_context)\n",
        "  if score > max_score:\n",
        "    max_score = score\n",
        "    final_answer = ans\n",
        "print(question)\n",
        "print(final_answer)\n",
        "print(max_score)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 450
        },
        "id": "zf-Jx4ttEyfs",
        "outputId": "d0b7aa1c-3b40-48d1-e3dd-4812aba6ce9c"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Query has 230 tokens.\n",
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[nltk_data] Downloading package punkt to /root/nltk_data...\n",
            "[nltk_data]   Package punkt is already up-to-date!\n"
          ]
        },
        {
          "output_type": "error",
          "ename": "IndexError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mIndexError\u001b[0m                                Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-25-1f3551961eaf>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mnew_context\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mnew_df\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m   \u001b[0;31m#new_paragrapgh = new_paragrapgh + answer_question(question, answer_text)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 6\u001b[0;31m   \u001b[0mans\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mscore\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0manswer_question\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mquestion\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnew_context\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      7\u001b[0m   \u001b[0;32mif\u001b[0m \u001b[0mscore\u001b[0m \u001b[0;34m>\u001b[0m \u001b[0mmax_score\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      8\u001b[0m     \u001b[0mmax_score\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mscore\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m<ipython-input-15-45d13885f70d>\u001b[0m in \u001b[0;36manswer_question\u001b[0;34m(question, pdf_txt)\u001b[0m\n\u001b[1;32m     15\u001b[0m     \u001b[0;32massert\u001b[0m \u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msegment_ids\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minput_ids\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     16\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 17\u001b[0;31m     \u001b[0mstart_scores\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mend_scores\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtensor\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0minput_ids\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtoken_type_ids\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtensor\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0msegment_ids\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     18\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     19\u001b[0m     \u001b[0mall_tokens\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtokenizer\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mconvert_ids_to_tokens\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minput_ids\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_call_impl\u001b[0;34m(self, *input, **kwargs)\u001b[0m\n\u001b[1;32m   1128\u001b[0m         if not (self._backward_hooks or self._forward_hooks or self._forward_pre_hooks or _global_backward_hooks\n\u001b[1;32m   1129\u001b[0m                 or _global_forward_hooks or _global_forward_pre_hooks):\n\u001b[0;32m-> 1130\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mforward_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1131\u001b[0m         \u001b[0;31m# Do not call functions when jit is used\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1132\u001b[0m         \u001b[0mfull_backward_hooks\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnon_full_backward_hooks\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/transformers/modeling_roberta.py\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, input_ids, attention_mask, token_type_ids, position_ids, head_mask, inputs_embeds, start_positions, end_positions, output_attentions, output_hidden_states, return_dict)\u001b[0m\n\u001b[1;32m    763\u001b[0m             \u001b[0moutput_attentions\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0moutput_attentions\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    764\u001b[0m             \u001b[0moutput_hidden_states\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0moutput_hidden_states\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 765\u001b[0;31m             \u001b[0mreturn_dict\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mreturn_dict\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    766\u001b[0m         )\n\u001b[1;32m    767\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_call_impl\u001b[0;34m(self, *input, **kwargs)\u001b[0m\n\u001b[1;32m   1128\u001b[0m         if not (self._backward_hooks or self._forward_hooks or self._forward_pre_hooks or _global_backward_hooks\n\u001b[1;32m   1129\u001b[0m                 or _global_forward_hooks or _global_forward_pre_hooks):\n\u001b[0;32m-> 1130\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mforward_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1131\u001b[0m         \u001b[0;31m# Do not call functions when jit is used\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1132\u001b[0m         \u001b[0mfull_backward_hooks\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnon_full_backward_hooks\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/transformers/modeling_bert.py\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, input_ids, attention_mask, token_type_ids, position_ids, head_mask, inputs_embeds, encoder_hidden_states, encoder_attention_mask, output_attentions, output_hidden_states, return_dict)\u001b[0m\n\u001b[1;32m    823\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    824\u001b[0m         embedding_output = self.embeddings(\n\u001b[0;32m--> 825\u001b[0;31m             \u001b[0minput_ids\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0minput_ids\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mposition_ids\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mposition_ids\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtoken_type_ids\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mtoken_type_ids\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minputs_embeds\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0minputs_embeds\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    826\u001b[0m         )\n\u001b[1;32m    827\u001b[0m         encoder_outputs = self.encoder(\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_call_impl\u001b[0;34m(self, *input, **kwargs)\u001b[0m\n\u001b[1;32m   1128\u001b[0m         if not (self._backward_hooks or self._forward_hooks or self._forward_pre_hooks or _global_backward_hooks\n\u001b[1;32m   1129\u001b[0m                 or _global_forward_hooks or _global_forward_pre_hooks):\n\u001b[0;32m-> 1130\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mforward_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1131\u001b[0m         \u001b[0;31m# Do not call functions when jit is used\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1132\u001b[0m         \u001b[0mfull_backward_hooks\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnon_full_backward_hooks\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/transformers/modeling_roberta.py\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, input_ids, token_type_ids, position_ids, inputs_embeds)\u001b[0m\n\u001b[1;32m     80\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     81\u001b[0m         return super().forward(\n\u001b[0;32m---> 82\u001b[0;31m             \u001b[0minput_ids\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtoken_type_ids\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mtoken_type_ids\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mposition_ids\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mposition_ids\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minputs_embeds\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0minputs_embeds\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     83\u001b[0m         )\n\u001b[1;32m     84\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/transformers/modeling_bert.py\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, input_ids, token_type_ids, position_ids, inputs_embeds)\u001b[0m\n\u001b[1;32m    207\u001b[0m             \u001b[0minputs_embeds\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mword_embeddings\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minput_ids\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    208\u001b[0m         \u001b[0mposition_embeddings\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mposition_embeddings\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mposition_ids\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 209\u001b[0;31m         \u001b[0mtoken_type_embeddings\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtoken_type_embeddings\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtoken_type_ids\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    210\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    211\u001b[0m         \u001b[0membeddings\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0minputs_embeds\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0mposition_embeddings\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0mtoken_type_embeddings\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_call_impl\u001b[0;34m(self, *input, **kwargs)\u001b[0m\n\u001b[1;32m   1128\u001b[0m         if not (self._backward_hooks or self._forward_hooks or self._forward_pre_hooks or _global_backward_hooks\n\u001b[1;32m   1129\u001b[0m                 or _global_forward_hooks or _global_forward_pre_hooks):\n\u001b[0;32m-> 1130\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mforward_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1131\u001b[0m         \u001b[0;31m# Do not call functions when jit is used\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1132\u001b[0m         \u001b[0mfull_backward_hooks\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnon_full_backward_hooks\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/torch/nn/modules/sparse.py\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, input)\u001b[0m\n\u001b[1;32m    158\u001b[0m         return F.embedding(\n\u001b[1;32m    159\u001b[0m             \u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mweight\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpadding_idx\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmax_norm\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 160\u001b[0;31m             self.norm_type, self.scale_grad_by_freq, self.sparse)\n\u001b[0m\u001b[1;32m    161\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    162\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mextra_repr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m->\u001b[0m \u001b[0mstr\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/torch/nn/functional.py\u001b[0m in \u001b[0;36membedding\u001b[0;34m(input, weight, padding_idx, max_norm, norm_type, scale_grad_by_freq, sparse)\u001b[0m\n\u001b[1;32m   2197\u001b[0m         \u001b[0;31m# remove once script supports set_grad_enabled\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2198\u001b[0m         \u001b[0m_no_grad_embedding_renorm_\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mweight\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmax_norm\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnorm_type\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 2199\u001b[0;31m     \u001b[0;32mreturn\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0membedding\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mweight\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mpadding_idx\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mscale_grad_by_freq\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msparse\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   2200\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2201\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mIndexError\u001b[0m: index out of range in self"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [],
      "metadata": {
        "id": "e6DuanlvmxWK"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Nous pouvons voir que nous obtenons un ensemble de trois valeurs d'activation pour chaque morceau.\n",
        "Ces valeurs d'activation ne sont pas encore nos probabilités de sortie. Pour les transformer en\n",
        "probabilités de sortie, nous devons appliquer une fonction softmax au tenseur de sortie.\n",
        "\n",
        "Enfin, nous prenons la moyenne des valeurs de chaque classe (ou colonne) pour obtenir notre probabilité finale de sentiment positif, négatif ou neutre."
      ],
      "metadata": {
        "id": "0V7UpVJ2muxM"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "input_ids = torch.stack(input_id_chunks)\n",
        "attention_mask = torch.stack(mask_chunks)\n",
        "\n",
        "input_dict = {\n",
        "    'input_ids': input_ids.long(),\n",
        "    'attention_mask': attention_mask.int()\n",
        "}\n",
        "input_dict"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "rowgM6TVEyic",
        "outputId": "f73c7be8-ba63-4290-8586-fb3e4330d11f"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "{'input_ids': tensor([[  101,  2166,  5427,  ...,  1012,  2107,   102],\n",
              "         [  101, 29361,  2024,  ...,  2064,  2022,   102],\n",
              "         [  101,  3876,  2006,  ...,     0,     0,     0]]),\n",
              " 'attention_mask': tensor([[1, 1, 1,  ..., 1, 1, 1],\n",
              "         [1, 1, 1,  ..., 1, 1, 1],\n",
              "         [1, 1, 1,  ..., 0, 0, 0]], dtype=torch.int32)}"
            ]
          },
          "metadata": {},
          "execution_count": 40
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "outputs = model(**input_dict)\n",
        "probs = torch.nn.functional.softmax(outputs[0], dim=-1)\n",
        "probs = probs.mean(dim=0)\n",
        "probs"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "qtlYsktoE8o2",
        "outputId": "934406b3-62c7-4cc8-a00f-5d657bda6bbf"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "tensor([4.2047e-01, 7.3233e-03, 3.8704e-04, 3.7146e-04, 2.4710e-04, 4.9905e-04,\n",
              "        9.1580e-05, 7.2339e-04, 2.8726e-04, 2.7150e-04, 2.2355e-04, 5.9827e-05,\n",
              "        1.0277e-03, 5.1559e-05, 4.3810e-05, 1.1908e-04, 2.0978e-04, 1.3863e-04,\n",
              "        4.2432e-05, 5.6722e-05, 7.6533e-05, 6.9248e-04, 9.3073e-05, 3.7591e-04,\n",
              "        4.3682e-05, 4.0332e-04, 6.2978e-05, 8.4359e-05, 1.1684e-04, 4.9767e-05,\n",
              "        2.4577e-04, 2.9513e-05, 1.8508e-04, 9.6008e-04, 1.3457e-04, 5.4936e-05,\n",
              "        5.5473e-05, 1.6459e-04, 6.7666e-05, 1.0982e-04, 6.5894e-05, 5.0604e-05,\n",
              "        8.9084e-05, 1.5366e-04, 4.3831e-05, 1.7032e-04, 6.9928e-04, 5.5394e-05,\n",
              "        2.6971e-04, 4.2740e-05, 2.9958e-05, 8.3827e-05, 7.3587e-05, 1.0709e-04,\n",
              "        5.4899e-04, 5.5681e-05, 3.9024e-05, 3.3720e-04, 4.9262e-05, 9.6260e-05,\n",
              "        5.3931e-05, 1.5222e-04, 7.0258e-04, 2.5524e-03, 1.5948e-04, 1.0690e-03,\n",
              "        6.7079e-05, 8.0789e-04, 2.0365e-03, 6.5701e-05, 1.2064e-04, 2.8996e-04,\n",
              "        2.1347e-04, 5.6888e-05, 2.1249e-03, 3.9499e-05, 2.1159e-04, 2.6569e-04,\n",
              "        6.2412e-05, 5.1129e-05, 8.9495e-05, 7.2415e-05, 3.5381e-03, 5.4556e-05,\n",
              "        7.1508e-04, 1.4188e-04, 2.4499e-04, 5.9457e-05, 1.1119e-03, 2.0382e-04,\n",
              "        1.4295e-04, 4.3345e-04, 1.3646e-04, 4.1674e-05, 2.0847e-04, 1.7065e-04,\n",
              "        3.8519e-04, 3.8708e-04, 4.1200e-05, 3.0841e-04, 1.2647e-04, 1.3637e-04,\n",
              "        4.6881e-05, 3.1991e-05, 3.2145e-05, 4.4246e-05, 8.7806e-05, 5.6480e-05,\n",
              "        5.8580e-05, 5.6653e-05, 4.8347e-05, 2.4965e-05, 4.6378e-05, 2.6379e-05,\n",
              "        4.8670e-05, 1.6737e-04, 6.4618e-05, 5.6495e-05, 8.1759e-05, 4.4466e-05,\n",
              "        1.0158e-04, 3.5585e-05, 6.0410e-05, 6.3875e-05, 1.7039e-04, 5.0404e-05,\n",
              "        5.7500e-05, 5.5004e-05, 4.6491e-05, 5.0295e-05, 4.5397e-05, 5.2832e-05,\n",
              "        5.3389e-05, 6.3324e-05, 1.3064e-04, 2.5749e-04, 5.2643e-05, 4.6944e-05,\n",
              "        3.7305e-05, 4.8249e-05, 8.0733e-05, 8.4464e-05, 1.0670e-04, 7.3485e-05,\n",
              "        7.4626e-05, 5.2369e-05, 6.9581e-05, 2.5934e-05, 3.6436e-05, 1.8811e-04,\n",
              "        8.0685e-05, 3.2122e-05, 5.3236e-05, 4.0746e-04, 9.3873e-05, 3.9662e-05,\n",
              "        8.7556e-05, 1.4731e-04, 1.3155e-04, 2.4929e-05, 7.9417e-05, 3.0528e-05,\n",
              "        1.0242e-04, 3.5068e-05, 3.4698e-05, 4.1113e-05, 4.6601e-05, 1.1962e-04,\n",
              "        3.4961e-05, 3.7392e-05, 7.1280e-05, 2.1064e-05, 4.6823e-05, 2.8664e-05,\n",
              "        4.4135e-05, 2.2795e-04, 6.4747e-05, 2.8058e-05, 5.6868e-05, 9.5724e-05,\n",
              "        1.1329e-04, 3.4201e-05, 5.0846e-05, 3.1480e-05, 6.0794e-05, 5.2622e-05,\n",
              "        2.9664e-04, 2.6548e-05, 3.1076e-05, 2.2069e-04, 1.8944e-04, 4.1666e-05,\n",
              "        9.3682e-05, 1.0285e-04, 6.4692e-05, 3.3199e-05, 3.2460e-04, 8.5656e-05,\n",
              "        7.1954e-05, 4.7625e-05, 1.1412e-04, 1.2776e-04, 1.0165e-04, 2.7259e-04,\n",
              "        3.9819e-05, 3.7262e-05, 2.3008e-04, 8.0705e-05, 7.4008e-05, 1.0812e-04,\n",
              "        8.5720e-05, 8.4158e-05, 3.3531e-05, 1.0134e-04, 3.8595e-05, 4.5253e-05,\n",
              "        6.6540e-05, 8.9126e-05, 7.6436e-05, 7.7764e-05, 8.5636e-05, 3.5595e-05,\n",
              "        3.2802e-05, 3.5160e-05, 5.9794e-05, 4.3163e-05, 5.5477e-05, 5.5824e-05,\n",
              "        1.3474e-04, 3.5574e-05, 4.1005e-05, 2.7552e-05, 3.3310e-05, 3.7466e-05,\n",
              "        3.1794e-05, 6.9628e-05, 3.5483e-05, 6.0901e-05, 1.4809e-04, 1.5280e-04,\n",
              "        2.0674e-04, 8.9104e-05, 3.1164e-05, 4.7400e-05, 4.0626e-05, 7.1526e-05,\n",
              "        3.5956e-05, 3.9222e-05, 3.7219e-05, 4.4639e-05, 1.0312e-04, 2.9464e-05,\n",
              "        2.4477e-05, 3.3950e-05, 5.8510e-05, 7.1361e-05, 3.4700e-05, 4.5197e-05,\n",
              "        4.2812e-05, 4.8044e-05, 3.1948e-05, 3.0816e-05, 6.2858e-05, 5.7715e-05,\n",
              "        3.5892e-05, 3.9153e-05, 3.8666e-05, 5.6248e-05, 2.2652e-05, 7.0105e-05,\n",
              "        4.9782e-05, 3.5454e-05, 4.0896e-05, 3.4124e-05, 4.9317e-05, 2.8924e-05,\n",
              "        4.0054e-05, 3.9652e-05, 5.1658e-05, 9.8789e-02, 3.5356e-05, 1.5939e-05,\n",
              "        1.7316e-05, 2.0357e-05, 2.4843e-05, 1.9501e-05, 3.3287e-05, 3.2738e-05,\n",
              "        1.4073e-05, 1.5898e-05, 1.8144e-05, 1.4344e-05, 1.5390e-05, 2.0967e-05,\n",
              "        1.8793e-05, 2.4851e-05, 1.5335e-05, 3.0455e-05, 2.7499e-05, 1.8701e-05,\n",
              "        2.5784e-05, 2.9815e-05, 4.0560e-05, 2.9167e-05, 2.1711e-05, 1.9326e-05,\n",
              "        2.2574e-05, 2.0133e-05, 2.3609e-05, 1.9194e-05, 1.6072e-05, 1.5034e-05,\n",
              "        3.8934e-05, 1.6530e-05, 2.1887e-05, 1.7048e-05, 1.8730e-05, 2.6361e-05,\n",
              "        3.6828e-05, 3.3074e-05, 1.9038e-05, 2.5489e-05, 2.4382e-05, 3.3837e-05,\n",
              "        2.4585e-05, 7.0282e-05, 6.9552e-05, 5.9061e-05, 5.0989e-05, 5.3752e-05,\n",
              "        1.5297e-04, 9.9908e-05, 1.9112e-04, 4.5872e-05, 3.1400e-05, 1.9073e-05,\n",
              "        4.9482e-05, 1.0397e-04, 6.5561e-05, 1.1692e-04, 6.9386e-05, 2.2301e-05,\n",
              "        3.3553e-05, 3.3179e-05, 2.2132e-05, 2.5484e-05, 2.5358e-05, 1.9016e-05,\n",
              "        2.2342e-05, 3.0359e-05, 2.5104e-05, 2.0813e-05, 2.2827e-05, 1.7814e-05,\n",
              "        2.5872e-05, 4.0808e-05, 2.3079e-05, 2.4501e-05, 2.0192e-05, 2.7207e-05,\n",
              "        3.6556e-05, 6.1634e-05, 3.0985e-05, 1.4299e-04, 3.3231e-05, 2.9805e-05,\n",
              "        4.4890e-05, 3.6918e-05, 2.5100e-05, 1.8482e-05, 2.7753e-05, 1.9064e-05,\n",
              "        2.5518e-05, 3.3453e-05, 4.1150e-05, 1.8053e-05, 2.1683e-05, 1.7240e-05,\n",
              "        2.1360e-05, 3.2736e-05, 2.0746e-05, 2.7276e-05, 1.8640e-05, 2.2516e-05,\n",
              "        1.9912e-05, 2.7437e-05, 1.6754e-05, 3.9655e-05, 4.4313e-05, 1.6155e-05,\n",
              "        3.4294e-05, 5.0868e-05, 3.5840e-05, 4.2855e-05, 1.3945e-04, 2.0258e-04,\n",
              "        2.4367e-05, 3.2675e-05, 2.2929e-05, 3.4300e-05, 4.2000e-05, 3.4378e-05,\n",
              "        2.3583e-05, 8.6818e-05, 2.5717e-05, 2.4171e-05, 2.9486e-05, 2.4192e-05,\n",
              "        5.4532e-05, 2.9652e-05, 2.3284e-05, 5.6041e-05, 2.6010e-05, 2.5898e-05,\n",
              "        2.5589e-05, 1.9638e-05, 2.5982e-05, 2.2606e-05, 6.2927e-05, 2.6647e-05,\n",
              "        3.1055e-05, 2.5189e-05, 2.0966e-05, 7.5393e-05, 1.8333e-05, 1.9678e-05,\n",
              "        2.8083e-05, 1.5749e-05, 2.1385e-05, 2.1441e-05, 2.4648e-05, 2.5035e-05,\n",
              "        1.9541e-05, 4.0760e-05, 2.2986e-05, 3.7738e-05, 3.1105e-05, 2.7221e-05,\n",
              "        3.3813e-05, 4.3472e-05, 2.7978e-05, 2.3420e-05, 3.4056e-05, 9.8847e-05,\n",
              "        2.5885e-05, 4.9962e-05, 7.6817e-05, 2.4763e-05, 2.6551e-05, 3.4203e-05,\n",
              "        3.8391e-05, 4.1616e-05, 6.4324e-05, 2.1028e-04, 3.3907e-05, 2.9787e-05,\n",
              "        2.4334e-05, 3.2796e-05, 4.8975e-05, 3.9476e-05, 9.2538e-05, 2.9322e-05,\n",
              "        3.0799e-05, 2.7479e-05, 2.6269e-05, 6.6660e-05, 3.5829e-05, 3.3094e-05,\n",
              "        3.8299e-05, 2.2342e-05, 1.7251e-05, 2.6254e-05, 2.7984e-05, 1.2164e-04,\n",
              "        1.9955e-05, 3.0520e-05, 2.3537e-05, 3.3842e-05, 2.5507e-05, 2.4733e-05,\n",
              "        2.1638e-05, 2.5656e-05, 7.0366e-05, 1.9037e-05, 2.3059e-05, 1.8690e-05,\n",
              "        3.8114e-05, 2.8532e-05, 2.7036e-05, 2.3507e-05, 2.6660e-05, 3.6071e-05,\n",
              "        2.6525e-05, 2.1497e-05, 1.9108e-05, 2.7563e-05, 2.2473e-05, 2.9002e-05,\n",
              "        2.2893e-05, 1.8821e-05, 2.0394e-05, 1.9089e-05, 2.3703e-05, 3.6839e-05,\n",
              "        1.9838e-05, 1.7759e-05, 1.9908e-05, 3.5956e-05, 2.4703e-05, 2.0852e-05,\n",
              "        5.0867e-04, 4.2030e-01], grad_fn=<MeanBackward1>)"
            ]
          },
          "metadata": {},
          "execution_count": 41
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "9XlD3zZUE8re"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "u81IKPIW_cJQ"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}